# 面试问题整理
## ZooKeeper
### CAP定理：

一个分布式系统不可能在满足分区容错性（P）的情况下同时满足一致性（C）和可用性（A）。在此ZooKeeper保证的是CP，ZooKeeper不能保证每次服务请求的可用性，在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。另外在进行leader选举时集群都是不可用，所以说，ZooKeeper不能保证服务可用性。

### BASE理论

BASE理论是基本可用，软状态，最终一致性三个短语的缩写。BASE理论是对CAP中一致性和可用性（CA）权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的，它大大降低了我们对系统的要求。
1. 基本可用：基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。比如正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒。
2. 软状态：软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。
3. 最终一致性：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

### ZooKeeper特点

1. 顺序一致性：同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。
2. 原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。
3. 单一系统映像：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。
4. 可靠性：一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。

### ZAB协议：

ZAB协议包括两种基本的模式：崩溃恢复和消息广播。当整个 Zookeeper 集群刚刚启动或者Leader服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader 服务器保持正常通信时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。当集群中超过半数机器与该 Leader 服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案（超过半数同意）来进行事务请求处理。

### 选举算法和流程：FastLeaderElection(默认提供的选举算法)

目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下：
1. 服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking。
2. 服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。
3. 服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为leader，服务器1,2成为follower。
4. 服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为follower。
5. 服务器5启动，后面的逻辑同服务器4成为follower。

### zk中的监控原理

zk类似于linux中的目录节点树方式的数据存储，即分层命名空间，zk并不是专门存储数据的，它的作用是主要是维护和监控存储数据的状态变化，通过监控这些数据状态的变化，从而可以达到基于数据的集群管理，zk中的节点的数据上限时1M。

client端会对某个znode建立一个watcher事件，当该znode发生变化时，这些client会收到zk的通知，然后client可以根据znode变化来做出业务上的改变等。

### zk实现分布式锁

zk实现分布式锁主要利用其临时顺序节点，实现分布式锁的步骤如下：

1. 创建一个目录mylock
2. 线程A想获取锁就在mylock目录下创建临时顺序节点
3. 获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁
4. 线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点
5. 线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁

## Redis

### 应用场景

1. 缓存
2. 共享Session
3. 消息队列系统
4. 分布式锁

### 单线程的Redis为什么快

1. 纯内存操作
2. 单线程操作，避免了频繁的上下文切换
3. 合理高效的数据结构
4. 采用了非阻塞I/O多路复用机制（有一个文件描述符同时监听多个文件描述符是否有数据到来）

### Redis 的数据结构及使用场景

1. String字符串:字符串类型是 Redis 最基础的数据结构，首先键都是字符串类型，而且 其他几种数据结构都是在字符串类型基础上构建的，我们常使用的 set key value 命令就是字符串。常用在缓存、计数、共享Session、限速等。set key value，append key value，strlen key
2. Hash哈希:在Redis中，哈希类型是指键值本身又是一个键值对结构，哈希可以用来存放用户信息，比如实现购物车。Hset/Hget key value，Hmset/Hmget 批量添加/得到，hdel key value
3. List列表（双向链表）:列表（list）类型是用来存储多个有序的字符串。可以做简单的消息队列的功能。 lpush/rpush key value 往左右插值（双向链表），lindex key index，
4. Set集合：集合（set）类型也是用来保存多个的字符串元素，但和列表类型不一 样的是，集合中不允许有重复元素，并且集合中的元素是无序的，不能通过索引下标获取元素。利用 Set 的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。 sadd key value，srem key value 移除，sinter key1 key2交集，sdiff key1 key2 差集，sunion key1 key2
5. ZSet有序集合（跳表实现）：Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。可以做排行榜应用，取 TOP N 操作。 zadd key score value score value 添加，zrangebyscore 排序
6. Geospatial：存储经纬度坐标，可以计算两个坐标之间的距离。如查看附件的人，底层是zset实现的。geoadd setname 经度 维度 key 添加，getpos name key， georadius key lon lat radius km 中心范围查询，
7. Hyperloglog：基数统计，不重复元素的统计。 PFadd PFcount等。可以查看网站访问量。PFadd 添加，PFcount，
8. BitMaps：位图。setbit key index value

### Zset的底层实现

+ Ziplist（压缩链表）：当保存的元素少于128个，或所有元素的大小都小于64字节。每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。
+ hash字典+skiplist（跳表）：
  + 字典的键保存元素的值，字典的值则保存元素的分值score；
  + 跳跃表节点的 object 属性保存元素的成员，跳跃表节点的 score 属性保存元素的分值。每个元素的值都是`[socre,value]`对。这两种数据结构会**通过指针来共享相同元素的成员和分值**，所以不会产生重复成员和分值，造成内存的浪费。

### Redis 的数据过期策略（内存淘汰）

Redis 中数据过期策略采用定期删除+惰性删除策略
* 定期删除策略：Redis 启用一个定时器定时监视所有的 key，判断key是否过期，过期的话就删除。这种策略可以保证过期的 key 最终都会被删除，但是也存在严重的缺点：每次都遍历内存中所有的数据，非常消耗 CPU 资源，并且当 key 已过期，但是定时器还处于未唤起状态，这段时间内 key 仍然可以用。
* 惰性删除策略：在获取 key 时，先判断 key 是否过期，如果过期则删除。这种方式存在一个缺点：如果这个 key 一直未被使用，那么它一直在内存中，其实它已经过期了，会浪费大量的空间。
* 这两种策略天然的互补，结合起来之后，定时删除策略就发生了一些改变，不在是每次扫描全部的 key 了，而是随机抽取一部分 key 进行检查，这样就降低了对 CPU 资源的损耗，惰性删除策略互补了为检查到的key，基本上满足了所有要求。但是有时候就是那么的巧，既没有被定时器抽取到，又没有被使用，这些数据又如何从内存中消失？没关系，还有内存淘汰机制，当内存不够用时，**内存淘汰机制**就会上场。淘汰策略分为：
    1. 当内存不足以容纳新写入数据时，新写入操作会报错。（Redis 默认策略）
    2. 当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。（LRU推荐使用）
    3. 当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。
    4. 当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。
    5. 当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。
    6. 当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。

### Redis如何实现分布式锁

分布式锁：

- 互斥性：任意时刻只能有一个客户端拥有锁，不能同时多个客户端获取
- 安全性：锁只能被持有该锁的用户删除，而不能被其他用户删除
- 死锁：获取锁的客户端因为某些原因而宕机，而未能释放锁，其他客户端无法获取此锁，需要有机制来避免该类问题的发生
- 容错：当部分节点宕机，客户端仍能获取锁或者释放锁

实现方法：**setnx key value px milliseconds**

+ setnx：不存在就设置，否则返回零，满足第一条
+ px：过期时间，满足第三四条，过期删除

### Redis的set和setnx

Redis中setnx不支持设置过期时间，做分布式锁时要想避免某一客户端中断导致死锁，需设置lock过期时间，在高并发时 setnx与 expire 不能实现原子操作，如果要用，得在程序代码上显示的加锁。使用SET代替SETNX ，相当于SETNX+EXPIRE实现了原子性，不必担心SETNX成功，EXPIRE失败的问题。

### Redis的LRU(最久未使用)具体实现：

传统的LRU是使用栈的形式，每次都将最新使用的移入栈顶，但是用栈的形式会导致执行select *的时候大量非热点数据占领头部数据，所以需要改进。Redis每次按key获取一个值的时候，都会更新value中的lru字段为当前秒级别的时间戳。Redis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的keylru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。

### Redis如何发现热点key

1. 凭借经验，进行预估：例如提前知道了某个活动的开启，那么就将此Key作为热点Key。
2. 服务端收集：在操作redis之前，加入一行代码进行数据统计。
3. 抓包进行评估：Redis使用TCP协议与客户端进行通信，通信协议采用的是RESP，所以自己写程序监听端口也能进行拦截包进行解析。
4. 在proxy层，对每一个 redis 请求进行收集上报。
5. Redis自带命令查询：Redis4.0.4版本提供了redis-cli –hotkeys就能找出热点Key。（如果要用Redis自带命令查询时，要注意需要先把内存逐出策略设置为allkeys-lfu或者volatile-lfu，否则会返回错误。进入Redis中使用config set maxmemory-policy allkeys-lfu即可。）

### Redis的热点key解决方案

1. 服务端缓存：即将热点数据缓存至服务端的内存中.(利用Redis自带的消息通知机制来保证Redis和服务端热点Key的数据一致性，对于热点Key客户端建立一个监听，当热点Key有更新操作的时候，服务端也随之更新。)
2. 备份热点Key：即将热点Key+随机数，随机分配至Redis其他节点中。这样访问热点key的时候就不会全部命中到一台机器上了。

### 如何解决 Redis 缓存雪崩问题

**指某个时间段内Redis缓存大面积失效**

1. 使用 Redis 高可用架构：使用 Redis 集群来保证 Redis 服务不会挂掉 （**Redis集群**）
2. 缓存时间不一致，给缓存的失效时间，加上一个随机值，避免集体失效
3. 限流降级策略：有一定的备案，比如个性推荐服务不可用了，换成热点数据推荐服务

### 如何解决 Redis 缓存穿透问题

缓存穿透：缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。

缓存击穿：**指某个热点key被频繁访问，一旦过期或者失效会导致频繁访问数据库，造成缓存穿透**

1. 在接口做校验
2. 存null值（缓存击穿加锁,或设置不过期）
3. 布隆过滤器拦截： 将所有可能的查询key 先映射到布隆过滤器中，查询时先判断key是否存在布隆过滤器中，存在才继续向下执行，如果不存在，则直接返回。**布隆过滤器将值进行多次哈希bit存储，布隆过滤器说某个元素在，可能会被误判。布隆过滤器说某个元素不在，那么一定不在**。

### Redis的持久化机制

Redis为了保证效率，数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。Redis的持久化策略有两种：

1. RDB：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存，保存策略。当Redis需要做持久化时，Redis会fork一个子进程，子进程将数据写到磁盘上一个临时RDB文件中。当子进程完成写临时文件后，将原来的RDB替换掉。**缺点是最后一次持久化的数据可能会丢失**
2. AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。

使用AOF做持久化，每一个写命令都通过write函数追加到appendonly.aof中。aof的默认策略是每秒钟fsync一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。
缺点是对于相同的数据集来说，AOF的文件体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。
Redis默认是快照RDB的持久化方式。对于主从同步来说，主从刚刚连接的时候，进行全量同步（RDB）；全同步结束后，进行增量同步(AOF)。

### 如果AOF文件过大怎么办？

执行BGREWRITEAOF命令对redis的AOF进行重写

```
redis-cli BGREWRITEAOF
```

相关解释：

Redis的AOF机制有点类似于Mysql binlog，是Redis的提供的一种持久化方式（另一种是RDB），它会将所有的写命令按照一定频率(no, always, every seconds)写入到日志文件中，当Redis停机重启后恢复数据库。

AOF重写：
(1) 随着AOF文件越来越大，里面会有大部分是重复命令或者可以合并的命令（100次incr = set key 100）
(2) 重写的好处：减少AOF日志尺寸，减少内存占用，加快数据库恢复时间。

执行一个 AOF文件重写操作，重写会创建一个当前 AOF 文件的体积优化版本。
即使 BGREWRITEAOF 执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 BGREWRITEAOF 成功之前不会被修改。
从 Redis 2.4 开始，AOF 重写由 Redis 自行触发， BGREWRITEAOF 仅仅用于手动触发重写操作。但网上有网友说已经3.2.5版本了，貌似redis还是没有自动触发BGREWRITEAOF
稳妥的方法还写一个脚本每天定时去执行

### Redis的事务

1. Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。
2. Redis事务没有隔离级别的概念，批量操作在发送 EXEC 命令前被放入队列缓存，并不会被实际执行，也就不存在事务内的查询要看到事务里的更新，事务外查询不能看到。
3. Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。

### Redis事务相关命令

1. watch key1 key2 ... : 监视一或多个key,如果在事务执行之前，被监视的key被其他命令改动，则事务被打断（类似**乐观锁**）
2. multi : 标记一个事务块的开始（queued）
3. exec : 执行所有事务块的命令（一旦执行exec后，之前加的监控锁都会被取消掉）
4. discard : 取消事务，放弃事务块中的所有命令
5. unwatch : 取消watch对所有key的监控

### Redis和 memcached 的区别

1. 存储方式上：memcache会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。redis有部分数据存在硬盘上，这样能保证数据的持久性。
2. 数据支持类型上：memcache对数据类型的支持简单，只支持简单的key-value，，而redis支持五种数据类型。
3. 用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
4. value的大小：redis可以达到1GB，而memcache只有1MB。

### Redis的几种集群模式

1. 主从复制
2. 哨兵模式
3. cluster模式

### Redis的主从复制模式

将一台Redis服务器的数据（主节点），复制到多个Redis服务器上（slave从节点）。主节点主要负责写，从节点主要负责读操作，数据的复制是单向的，从主节点复制到从节点

复制原理：

1. Slave启动成功连接到master后发送一个同步命令
2. Master接到命令后，完成一次全量复制
3. 全量复制：slave服务器在接收到数据库文件后，将其加载到内存中
4. 增量复制：master节点继续收集所有的修改命令一次传给slava，完成同步

主从切换：手动切换，麻烦，所以需要哨兵模式

### Redis的哨兵模式

哨兵是一个分布式系统,在主从复制的基础上你可以在一个架构中运行多个哨兵进程,这些进程使用流言协议来接收关于Master是否下线的信息,并使用投票协议来决定是否执行自动故障迁移,以及选择哪个Slave作为新的Master。

每个哨兵会向其它哨兵、master、slave定时发送消息,以确认对方是否活着,如果发现对方在指定时间(可配置)内未回应,则暂时认为对方已挂(所谓的”主观认为宕机”)。

若“哨兵群“中的多数sentinel,都报告某一master没响应,系统才认为该master"彻底死亡"(即:客观上的真正down机),通过一定的vote算法,从剩下的slave节点中,选一台提升为master,然后自动修改相关配置。

### Redis的rehash

Redis的rehash 操作并不是一次性、集中式完成的，而是分多次、渐进式地完成的，redis会维护维持一个索引计数器变量rehashidx来表示rehash的进度。

这种渐进式的 rehash 避免了集中式rehash带来的庞大计算量和内存操作，但是需要注意的是redis在进行rehash的时候，正常的访问请求可能需要做多要访问两次hashtable（ht[0]， ht[1]），例如键值被rehash到新ht1，则需要先访问ht0，如果ht0中找不到，则去ht1中找。

### Redis的hash表被扩展的条件

1. 哈希表中保存的key数量超过了哈希表的大小.
2. Redis服务器目前没有在执行BGSAVE命令（rdb）或BGREWRITEAOF命令，并且哈希表的负载因子大于等于1.
3. Redis服务器目前在执行BGSAVE命令（rdb）或BGREWRITEAOF命令，并且哈希表的负载因子大于等于5.(负载因子=哈希表已保存节点数量 / 哈希表大小，当哈希表的负载因子小于0.1时，对哈希表执行收缩操作。)

### Redis并发竞争key的解决方案

1. 分布式锁+时间戳
2. 利用消息队列

### Redis与Mysql双写一致性方案

先更新数据库，再删缓存。数据库的读操作的速度远快于写操作的，所以脏数据很难出现。可以对异步延时删除策略，保证读请求完成以后，再进行删除操作。

### Redis的管道pipeline

对于单线程阻塞式的Redis，Pipeline可以满足批量的操作，把多个命令连续的发送给Redis Server，然后一一解析响应结果。Pipelining可以提高批量处理性能，提升的原因主要是TCP连接中减少了“交互往返”的时间。pipeline 底层是通过把所有的操作封装成流，redis有定义自己的出入输出流。在 sync() 方法执行操作，每次请求放在队列里面，解析响应包。

## Mysql与Mongodb

### 数据库范式

+ 第一范式：属于第一范式关系的所有字段都不可再分，即数据项不可分。
+ 第二范式：确保表中的每列都和主键相关。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。
+ 第三范式：每一列数据都和主键直接相关，而不能间接相关。即表和表之间使用主键进行关联

### Mysql事务的基本要素ACID

1. 原子性：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行
2. 一致性：事务开始前和结束后，数据库的完整性约束没有被破坏。
3. 隔离性：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。
4. 持久性：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。

### Mysql数据类型

+ 数值型：int，bigint，float、double、DECIMAL
+ 日期和时间：DATE（YYYY-MM-DD）、TIME（HH:MM:SS）、YEAR、DATETIME（DATE+TIME）、TIMESTAMP
+ 字符串：char（定长字符串，有空格去掉）、varchar（变长字符串，不去掉空格）、TINYTEXT、BLOB（ 二进制形式的长文本数据）、TEXT

### char和varchar的区别

+  **char类型的长度是固定的，varchar的长度是可变的。**
+ char的存取速度还是要比varchar要快得多，方便程序的存储与查找；但是char也为此付出的是空间的代价，因为其长度固定，所以会占据多余的空间，可谓是以空间换取时间效率。varchar则刚好相反，以时间换空间。
+ 对 char 来说，最多能存放的字符个数 255，和编码无关。而 varchar 呢，最多能存放 65532 个字符。varchar的最大有效长度由最大行大小和使用的字符集确定。整体最大长度是 65,532字节。

### Mysql视图

视图就是一条SELECT语句执行后返回的结果集。所以我们在创建视图的时候，主要的工作就落在创建这条SQL查询语句上。

特性：视图是对若干张基本表的引用，一张虚表，查询语句执行的结果，不存储具体的数据（基本表数据发生了改变，视图也会跟着改变）；可以跟基本表一样，进行增删改查操作(ps:增删改操作有条件限制)；

### Mysql、Redis、Mongodb的区别

1、mysql关系型数据库、redis和mongodb是Nosql非关系型数据库；

2、关系型数据库因为注重事务，所以就要符合ACID特性，所谓的原子性、一致性、持久性、隔离型；

3、**Nosql非关系型数据库相对于CAP理论来讲，最多只能满足两个，其中mongodb和redis均是满足CP**；

4、当你的数据为结构化数据，符合关系型数据库的标准时，优先考虑使用mysql等关系型数据库，因为发展悠久，社区强大，数据量太大考虑优化、分库分表等策略；

5、当你的数据不符合关系型数据库的标准，考虑使用mongodb等非关系型数据库，数据量大时考虑分布式集群；

4、redis是完全基于内存的，存储数据量较mongodb少，所以不单独用来作为业务数据库存储，可以配合mysql、mongodb等解决有实时数据获取需求的快速处理；

### Mongodb有没有事务

Mongodb中没有事务的概念，但是满足CAP理论中的CP

CAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。

### Mongodb索引为什么是B树

MongoDB 是文档型的数据库，单一查询比较常见，**所有节点都有Data域，只要找到指定索引就可以进行访问，B树的单一数据查询平均性能比B+树要好，所以选用B树**

**Mysql作为一个关系型数据库，数据的关联性是非常强的，区间访问是常见的一种情况，B+树由于数据全部存储在叶子节点，并且通过指针串在一起，这样就很容易的进行区间遍历甚至全部遍历。**

总结：由于关系型数据库和非关系型数据的设计方式上的不同。导致在关系型数据中，遍历操作比较常见，因此采用B+树作为索引，比较合适。而在非关系型数据库中，单一查询比较常见，因此采用B树作为索引，比较合适。

### Mysql的存储引擎

1. InnoDB存储引擎：**InnoDB存储引擎支持事务**，其设计目标主要面向在线事务处理（OLTP）的应用。其特点是行锁设计，支持外键，并支持非锁定锁，即默认读取操作不会产生锁。从Mysql5.5.8版本开始，InnoDB存储引擎是默认的存储引擎。
2. MyISAM存储引擎：**MyISAM存储引擎不支持事务**、表锁设计，支持全文索引，主要面向一些OLAP数据库应用。InnoDB的数据文件本身就是主索引文件，而MyISAM的主索引和数据是分开的。
3. NDB存储引擎：NDB存储引擎是一个集群存储引擎，其结构是share nothing的集群架构，能提供更高的可用性。NDB的特点是数据全部放在内存中（从MySQL 5.1版本开始，可以将非索引数据放在磁盘上），因此主键查找的速度极快，并且通过添加NDB数据存储节点可以线性地提高数据库性能，是高可用、高性能的集群系统。NDB存储引擎的连接操作是在MySQL数据库层完成的，而不是在存储引擎层完成的。这意味着，复杂的连接操作需要巨大的网络开销，因此查询速度很慢。如果解决了这个问题，NDB存储引擎的市场应该是非常巨大的。
4. Memory存储引擎：Memory存储引擎（之前称HEAP存储引擎）将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据都将消失。它非常适合用于存储临时数据的临时表，以及数据仓库中的纬度表。Memory存储引擎默认使用哈希索引，而不是我们熟悉的B+树索引。虽然Memory存储引擎速度非常快，但在使用上还是有一定的限制。比如，只支持表锁，并发性能较差，并且不支持TEXT和BLOB列类型。最重要的是，存储变长字段时是按照定常字段的方式进行的，因此会浪费内存。
5. Archive存储引擎：Archive存储引擎只支持INSERT和SELECT操作，从MySQL 5.1开始支持索引。Archive存储引擎使用zlib算法将数据行（row）进行压缩后存储，压缩比一般可达1∶10。正如其名字所示，Archive存储引擎非常适合存储归档数据，如日志信息。Archive存储引擎使用行锁来实现高并发的插入操作，但是其本身并不是事务安全的存储引擎，其设计目标主要是提供高速的插入和压缩功能。
6. Maria存储引擎：Maria存储引擎是新开发的引擎，设计目标主要是用来取代原有的MyISAM存储引擎，从而成为MySQL的默认存储引擎。它可以看做是MyISAM的后续版本。Maria存储引擎的特点是：支持缓存数据和索引文件，应用了行锁设计，提供了MVCC功能，**支持事务和非事务安全的选项**，以及更好的BLOB字符类型的处理性能。

### 事务的并发问题

1. 脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据
2. 不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。
3. 幻读：A事务读取了B事务已经提交的新增数据。注意和不可重复读的区别，这里是新增，不可重复读是更改（或删除）。select某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读。

### MySQL事务隔离级别

| 事务隔离级别                    | 脏读 | 不可重复读 | 幻读 |
| :------------------------------ | ---- | ---------- | ---- |
| 读未提交（MVCC实现）            | 是   | 是         | 是   |
| 不可重复读                      | 否   | 是         | 是   |
| 可重复读（Mysql默认，MVCC实现） | 否   | 否         | 是   |
| 串行化                          | 否   | 否         | 否   |

### Mysql的逻辑结构

* 最上层的服务类似其他CS结构，比如连接处理，授权处理。
* 第二层是Mysql的服务层，包括SQL的解析分析优化，存储过程触发器视图等也在这一层实现。
* 最后一层是存储引擎的实现，类似于Java接口的实现，Mysql的执行器在执行SQL的时候只会关注API的调用，完全屏蔽了不同引擎实现间的差异。比如Select语句，先会判断当前用户是否拥有权限，其次到缓存（内存）查询是否有相应的结果集，如果没有再执行解析sql，检查SQL 语句语法是否正确，再优化生成执行计划，调用API执行。

### MVCC,redolog,undolog,binlog

* undoLog 也就是我们常说的回滚日志文件 主要用于事务中执行失败，进行回滚，以及MVCC中对于数据历史版本的查看。由引擎层的InnoDB引擎实现,是逻辑日志,记录数据修改被修改前的值,比如"把id='B' 修改为id = 'B2' ，那么undo日志就会用来存放id ='B'的记录”。当一条数据需要更新前,会先把修改前的记录存储在undolog中,如果这个修改出现异常,,则会使用undo日志来实现回滚操作,保证事务的一致性。当事务提交之后，undo log并不能立马被删除,而是会被放到待清理链表中,待判断没有事物用到该版本的信息时才可以清理相应undolog。它保存了事务发生之前的数据的一个版本，用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。
* redoLog 是重做日志文件是记录数据修改之后的值，用于持久化到磁盘中。redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。由引擎层的InnoDB引擎实现,是物理日志,记录的是物理数据页修改的信息,比如“某个数据页上内容发生了哪些改动”。当一条数据需要更新时,InnoDB会先将数据更新，然后记录redoLog 在内存中，然后找个时间将redoLog的操作执行到磁盘上的文件上。不管是否提交成功我都记录，你要是回滚了，那我连回滚的修改也记录。它确保了事务的持久性。每个InnoDB存储引擎至少有1个重做日志文件组（group），每个文件组下至少有2个重做日志文件，如默认的ib_logfile0和ib_logfile1。为了得到更高的可靠性，用户可以设置多个的镜像日志组（mirrored log groups），将不同的文件组放在不同的磁盘上，以此提高重做日志的高可用性。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。InnoDB存储引擎先写重做日志文件1，当达到文件的最后时，会切换至重做日志文件2，再当重做日志文件2也被写满时，会再切换到重做日志文件1中。
* binlog：逻辑日志，记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志。
* **MVCC多版本并发控制**：是MySQL中基于**乐观锁理论**实现隔离级别的方式，**用于读已提交和可重复读取隔离级别的实现**。在MySQL中，会在表中每一条数据后面添加两个字段：最近修改该行数据的事务ID，指向该行（undolog表中）回滚段的指针。Read View判断行的可见性，创建一个新事务时，copy一份当前系统中的活跃事务列表。意思是，当前不应该被本事务看到的其他事务id列表。已提交读隔离级别下的事务在每次查询的开始都会生成一个独立的ReadView,而可重复读隔离级别则在第一次读的时候生成一个ReadView，之后的读都复用之前的ReadView。

### 如何保证事务的原子性、持久性和一致性

利用undo log保障原子性。该log保存了事务发生之前的数据的一个版本，可以用于回滚，从而保证事务原子性。

利用redo log保证事务的持久性，该log关注于事务的恢复.在重启mysql服务的时候，根据redo log进行重做，从而使事务有持久性。

利用undo log+redo log保障一致性。事务中的执行需要redo log，如果执行失败，需要undo log 回滚。

### binlog和redolog的区别

1. redolog是在InnoDB存储引擎层产生，而binlog是MySQL数据库的上层服务层产生的。
2. 两种日志记录的内容形式不同。MySQL的binlog是逻辑日志，其记录是对应的SQL语句，对应的事务。而innodb存储引擎层面的重做日志是物理日志，是关于每个页（Page）的更改的物理情况。
3. 两种日志与记录写入磁盘的时间点不同，binlog日志只在事务提交完成后进行一次写入。而innodb存储引擎的重做日志在事务进行中不断地被写入，并日志不是随事务提交的顺序进行写入的。
4. binlog不是循环使用，在写满或者重启之后，会生成新的binlog文件，redolog是循环使用。
5. binlog可以作为恢复数据使用，主从复制搭建，redolog作为异常宕机或者介质故障后的数据恢复使用。

### Mysql读写分离以及主从同步

1. 原理：主库将变更写binlog日志，然后从库连接到主库后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个中继日志中，接着从库中有一个sql线程会从中继日志读取binlog，然后执行binlog日志中的内容，也就是在自己本地再执行一遍sql，这样就可以保证自己跟主库的数据一致。
2. 问题：这里有很重要一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行操作，在从库上会串行化执行，由于从库从主库拷贝日志以及串行化执行sql特点，在高并发情况下，从库数据一定比主库慢一点，是有延时的，所以经常出现，刚写入主库的数据可能读不到了，要过几十毫秒，甚至几百毫秒才能读取到。还有一个问题，如果突然主库宕机了，然后恰巧数据还没有同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。所以mysql实际上有两个机制，一个是半同步复制，用来解决主库数据丢失问题，一个是并行复制，用来解决主从同步延时问题。
3. 半同步复制：semi-sync复制，指的就是主库写入binlog日志后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的relay log之后，接着会返回一个ack给主库，主库接收到至少一个从库ack之后才会认为写完成。
4. 并发复制：指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这样库级别的并行。（将主库分库也可缓解延迟问题）
                                                                                                                                                  
### Next-Key Lock

InnoDB 采用 Next-Key Lock 解决幻读问题。在`insert into test(xid) values (1), (3), (5), (8), (11);`后，由于xid上是有索引的，该算法总是会去锁住索引记录。现在，该索引可能被锁住的范围如下：(-∞, 1], (1, 3], (3, 5], (5, 8], (8, 11], (11, +∞)。Session A（`select * from test where id = 8 for update`）执行后会锁住的范围：(5, 8], (8, 11]。除了锁住8所在的范围，还会锁住下一个范围，所谓Next-Key。

### InnoDB的关键特性

1. 插入缓冲：对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入；若不在，则先放入到一个Insert Buffer对象中。然后再以一定的频率和情况进行Insert Buffer和辅助索引页子节点的merge（合并）操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对于非聚集索引插入的性能。
2. 两次写：两次写带给InnoDB存储引擎的是数据页的可靠性，有经验的DBA也许会想，如果发生写失效，可以通过重做日志进行恢复。这是一个办法。但是必须清楚地认识到，如果这个页本身已经发生了损坏（物理到page页的物理日志成功页内逻辑日志失败），再对其进行重做是没有意义的。这就是说，在应用（apply）重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做。在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的doublewrite buffer，之后通过doublewrite buffer再分两次，每次1MB顺序地写入共享表空间的物理磁盘上，这就是doublewrite。
3. 自适应哈希索引：InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引。
4. 异步IO：为了提高磁盘操作性能，当前的数据库系统都采用异步IO（AIO）的方式来处理磁盘操作。AIO的另一个优势是可以进行IO Merge操作，也就是将多个IO合并为1个IO，这样可以提高IOPS的性能。
5. 刷新邻接页：当刷新一个脏页时，InnoDB存储引擎会检测该页所在区（extent）的所有页，如果是脏页，那么一起进行刷新。这样做的好处显而易见，通过AIO可以将多个IO写入操作合并为一个IO操作，故该工作机制在传统机械磁盘下有着显著的优势。

### Mysql如何保证一致性和持久性

MySQL为了保证ACID中的一致性和持久性，使用了WAL(Write-Ahead Logging,先写日志再写磁盘)。Redo log就是一种WAL的应用。当数据库忽然掉电，再重新启动时，MySQL可以通过Redo log还原数据。也就是说，每次事务提交时，不用同步刷新磁盘数据文件，只需要同步刷新Redo log就足够了。

### InnoDB的行锁模式

* 共享锁(S)：用法lock in share mode，又称读锁，允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。
* 排他锁(X)：用法for update，又称写锁，允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。在没有索引的情况下，InnoDB只能使用表锁。

### 什么是索引，优缺点

索引：一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。

优点：加快查询速度；通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性

缺点：占用额外的存储空间；更新数据的时候也需要更新索引，所以比较慢

### Mysql有哪些索引？

+ 数据结构分：hash索引（单点查询，效率高），B+树索引
+ 物理存储分：聚集索引和非聚集索引
+ 逻辑角度分：普通索引、唯一索引（不允许列有null和重复）、复合索引（多列索引）

### 为什么InnoDB表必须建主键？

B+树的节点可以存储key、地址、行数据(仅叶子节点)，key 就是不重复的值且可以比较(确保树进行分裂时，可以确定是左孩子还是右孩子)。

我们知道主键的特定就是`主键的值不可重复，也不可为空`，正好符合B+树key的要求

### 为什么推荐整形的自增主键？

聚簇索引的数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。

聚簇索引的顺序和磁盘中数据的存储顺序是一致的，如果主键不是自增id，那么可以想 象，它会干些什么，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但，如果是自增的，那就简单了，它只需要一 页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。

整形字段的对比效率高于其他数据结构，比如字符串，所有推荐整型 

### 聚集索引和非聚集索引

+ 聚簇索引：将索引和整条记录存放在一起，找到索引就找到了记录；（InnoDB）

+ 非聚簇索引：只存储索引字段和记录所在的位置，通过索引找到记录所在的位置，然后再根据记录所在位置去获取记录。（MyASM）
+ 优缺点：
  + 聚簇索引的查找记录要比非聚簇索引块，因为聚簇索引查找到索引就查找到了数据位置，而非聚簇索引查找到索引之后，根据记录的数据地址，再去查找数据；
  + 一个数据表只能有一个聚簇索引，但可以有多个非聚簇索引；
  + 聚簇索引和非聚簇索引都可以加快查询速度，但同时也都对写入速度会有影响；聚簇索引对写入的速度影响更大一些

### 为什么选择B+树作为索引结构

* **Hash索引**：Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。所以，哈希索引只适用于等值查询的场景。而B+ 树是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描
* 二叉查找树：解决了排序的基本问题，但是由于无法保证平衡，可能退化为链表。
* 平衡二叉树：通过旋转解决了平衡的问题，但是旋转操作效率太低。
* 红黑树：通过舍弃严格的平衡和引入红黑节点，解决了	AVL旋转效率过低的问题，但是在磁盘等场景下，树仍然太高，IO次数太多。
* **B+树**：在B树的基础上，将非叶节点改造为不存储数据纯索引节点，进一步降低了树的高度；此外将叶节点使用指针连接成链表，范围查询更加高效。

### B+树的叶子节点都可以存哪些东西

可能存储的是整行数据，也有可能是主键的值。B+树的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引。而其他索引B+树的叶子节点存储了主键的值，在通过主键索引树找到数据。（如果不这样，数据冗余）

### 覆盖索引

指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。

### 复合索引的最左前缀

MySQL中的索引可以以一定顺序引用多列，这种索引叫作联合索引。如User表的name和city加联合索引就是(name,city)，**而最左前缀原则指的是，如果查询的时候查询条件精确匹配索引的左边连续一列或几列，必须要从第一列开始，则此列就可以被用到**。如下：

**原理**：索引采用B+的结构进行存储，搜索需要从根节点出发，上层节点对应靠左的值，搜索需要从根节点出发。也就是最左列是有序的，第二列在第一列的基础上才有序，如果直接访问第二列是乱序的。

```
select * from user where name=xx and city=xx ; ／／可以命中索引
select * from user where name=xx ; // 可以命中索引
select * from user where city=xx ; // 无法命中索引
```

这里需要注意的是，查询的时候如果两个条件都用上了，但是顺序不同，如 `city= xx and name ＝xx`，那么现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。

由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面。ORDER BY子句也遵循此规则。

### 查询在什么时候不走（预期中的）索引

1. 模糊查询 %like
2. 索引列参与计算,使用了函数
3. 非最左前缀顺序
4. where对null判断 
5. where不等于
6. or操作有至少一个字段没有索引
7. 需要回表的查询结果集过大（超过配置的范围）

### 索引字段的选取

 日常在建数据表的时候，通常会在WHERE，GROUP BY，ORDER BY等常用的字段上建立索引，当有多个字段时候，有一项原则就是该字段的去重后的值个数越多，索引建立的必要性越强。

### explain命令概要

1. id:select选择标识符
2. select_type:表示查询的类型。
3. table:输出结果集的表
4. partitions:匹配的分区
5. type:表示表的连接类型
6. **possible_keys:表示查询时，可能使用的索引**
7. **key:表示实际使用的索引**
8. key_len:索引字段的长度
9. ref:列与索引的比较
10. rows:扫描出的行数(估算的行数)
11. filtered:按表条件过滤的行百分比
12. Extra:执行情况的描述和说明

### explain 中的 select_type（查询的类型）

1. SIMPLE(简单SELECT，不使用UNION或子查询等)
2. PRIMARY(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY)
3. UNION(UNION中的第二个或后面的SELECT语句)
4. DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询)
5. UNION RESULT(UNION的结果，union语句中第二个select开始后面所有select)
6. SUBQUERY(子查询中的第一个SELECT，结果不依赖于外部查询)
7. DEPENDENT SUBQUERY(子查询中的第一个SELECT，依赖于外部查询)
8. DERIVED(派生表的SELECT, FROM子句的子查询)
9. UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行)

### explain 中的 type（表的连接类型）

1. system：最快，主键或唯一索引查找常量值，只有一条记录，很少能出现
2. const：PK或者unique上的等值查询
3. eq_ref：PK或者unique上的join查询，等值匹配，对于前表的每一行(row)，后表只有一行命中
4. ref：非唯一索引，等值匹配，可能有多行命中
5. range：索引上的范围扫描，例如：between/in
6. index：索引上的全集扫描，例如：InnoDB的count
7. ALL：最慢，全表扫描(full table scan)

### explain 中的 Extra（执行情况的描述和说明）

1. Using where:不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤
2. Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by
3. Using filesort：当Query中包含 order by 操作，而且无法利用索引完成的排序操作称为“文件排序”
4. Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。
5. Impossible where：这个值强调了where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。
6. Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行
7. No tables used：Query语句中使用from dual 或不含任何from子句

### 数据库/慢查询优化方法

1. 创建并使用正确的索引：判断慢查询是否走索引，explain关键字

2. 优化数据库结构：  合理的数据库结构不仅可以使数据库占用更小的磁盘空间，而且能够使查询速度更快。数据库结构的设计，需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。

   + 将字段很多的表分解成多个表：对于字段比较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。

   + 增加中间表：对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，把需要经常联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询，以此来提高查询效率。

3. 分解关联查询： 将一个大的查询分解为多个小查询

4. 优化Limit分页： 一个非常令人头疼问题就是当偏移量非常大的时候，例如可能是limit 10000,20这样的查询，这是mysql需要查询10020条然后只返回最后20条，前面的10000条记录都将被舍弃，这样的代价很高。

   ​     优化此类查询的一个最简单的方法是尽可能的使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。对于偏移量很大的时候这样做的效率会得到很大提升。

5. 只返回需要的字段

6. 减少交互次数（批量提交）

7. 设置合理的Fetch Size（数据每次返回给客户端的条数）

### 数据库分库分表方式

为什么要分库分表： 1）请求数太高，逼近数据库可承载活跃连接数的阈值。  2）数据查询慢  3）数据量大，即使使用索引也需要大量的磁盘IO

+ 垂直分表（结构不同，数据不同）：当一张表由于字段过多导致查询速度过慢或者导致大量数据冗余，此时就可以考虑垂直分表；在冷字段表中多加一个列作为热字段表的映射，保证在需要用到冷数据时也能找到。
+ 水平分表（结构相同，数据不同）：当一张表由于表数据行过多造成的查询效率下降，此时我们就可以考虑水平分表。

无论是垂直分表还是水平分表，他们都是建立在单库压力不高，但是单表性能不够的时候进行的，因为它们都属于库内分表，如果是数据库整体压力很大导致的查询效率低下，那么再怎么做分表也是无济于事，所以分表操作只建立在单库压力不高但是单表查询效率低下的情况下适用。

+ 垂直分库（结构不同，数据不同）：当我单库在高并发情况下遇到瓶颈时，假设其他高可用架构方案（硬件分区、主备读写分离、主主双写双读）也无法解决此压力的时候才需要考虑垂直分库。
+ 水平分库（结构相同）：虽然我们通过垂直分库的手段能够去提升MySQL整体的负荷能力，但是如果类似于分布式微服务当中的单节点并发数过高还是能把数据库打宕机，所以此时我们就可以考虑使用水平分库来提升单节点的抗并发能力。

### SQL执行顺序

SQL的执行顺序：from---where--group by---having---select---order by



## JVM

### 运行时数据区域

1. 程序计数器：程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。**是线程私有”的内存**。

2. Java虚拟机栈：**与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的**，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：**每个方法在执行的同时都会创建一个栈帧 ，用于存储局部变量表（包括对象的引用）、操作数栈、动态链接、方法出口等信息**。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。

   + 方法在栈中的调用过程：

3. 本地方法栈：本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，**而本地方法栈则为虚拟机使用到的Native方法服务。**

4. Java堆：对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。**此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。**

5. 方法区：方法区用于存储已被虚拟机加载的类信息、常量、静态变量，如static修饰的变量加载类的时候就被加载到方法区中。运行时常量池是方法区的一部分，class文件除了有类的字段、接口、方法等描述信息之外，还有常量池用于存放编译期间生成的各种字面量和符号引用。在老版jdk，方法区也被称为永久代。在1.8之后，由于永久代内存经常不够用或发生内存泄露，爆出异常java.lang.OutOfMemoryError，所以在1.8之后废弃永久代，引入元空间的概念。元空间是方法区的在HotSpot jvm 中的实现，元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。理论上取决于32位/64位系统可虚拟的内存大小。可见也不是无限制的，需要配置参数。

   

   <img src="C:\Users\王盛\AppData\Roaming\Typora\typora-user-images\image-20210406111048904.png" alt="image-20210406111048904" style="zoom:70%;" />


### 线程栈的大小，会爆栈吗？

栈内存为线程私有的空间，每个线程都会创建私有的栈内存。栈空间内存设置过大，创建线程数量较多时会出现栈内存溢出StackOverflowError。同时，栈内存也决定方法调用的深度，栈内存过小则会导致方法调用的深度较小，如递归调用的次数较少。

-Xss：如-Xss128k （修改栈大小的命令）

### 分代回收

HotSpot JVM把年轻代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to）。一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理),这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。

因为年轻代中的对象基本都是朝生夕死的，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。

在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。

### 动态年龄计算

Hotspot在遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值。

JVM引入动态年龄计算，主要基于如下两点考虑：

1. 如果固定按照MaxTenuringThreshold设定的阈值作为晋升条件： a）MaxTenuringThreshold设置的过大，原本应该晋升的对象一直停留在Survivor区，直到Survivor区溢出，一旦溢出发生，Eden+Svuvivor中对象将不再依据年龄全部提升到老年代，这样对象老化的机制就失效了。 b）MaxTenuringThreshold设置的过小，“过早晋升”即对象不能在新生代充分被回收，大量短期对象被晋升到老年代，老年代空间迅速增长，引起频繁的Major GC。分代回收失去了意义，严重影响GC性能。
2. 相同应用在不同时间的表现不同：特殊任务的执行或者流量成分的变化，都会导致对象的生命周期分布发生波动，那么固定的阈值设定，因为无法动态适应变化，会造成和上面相同的问题。


### 常见的垃圾回收机制

1. 引用计数法：引用计数法是一种简单但速度很慢的垃圾回收技术。每个对象都含有一个引用计数器,当有引用连接至对象时,引用计数加1。当引用离开作用域或被置为null时,引用计数减1。虽然管理引用计数的开销不大,但这项开销在整个程序生命周期中将持续发生。垃圾回收器会在含有全部对象的列表上遍历,当发现某个对象引用计数为0时,就释放其占用的空间。
2. 可达性分析算法：这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。

### CMS的执行过程

1. 初始标记(STW initial mark)：这个过程从垃圾回收的"根对象"开始，只扫描到能够和"根对象"直接关联的对象，并作标记。所以这个过程虽然暂停了整个JVM，但是很快就完成了。
2. 并发标记(Concurrent marking)：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。
3. 并发预清理(Concurrent precleaning)：并发预清理阶段仍然是并发的。在这个阶段，虚拟机查找在执行并发标记阶段新进入老年代的对象(可能会有一些对象从新生代晋升到老年代， 或者有一些对象被分配到老年代)。通过重新扫描，减少下一个阶段"重新标记"的工作，因为下一个阶段会Stop The World。
4. 重新标记(STW remark)：这个阶段会暂停虚拟机，收集器线程扫描在CMS堆中剩余的对象。扫描从"跟对象"开始向下追溯，并处理对象关联。
5. 并发清理(Concurrent sweeping)：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。
6. 并发重置(Concurrent reset)：这个阶段，重置CMS收集器的数据结构状态，等待下一次垃圾回收。

### G1的执行过程

1. 标记阶段：首先是初始标记(Initial-Mark),这个阶段也是停顿的(stop-the-word)，并且会稍带触发一次yong GC。
2. 并发标记：这个过程在整个堆中进行，并且和应用程序并发运行。并发标记过程可能被yong GC中断。在并发标记阶段，如果发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，每个区域的对象活性(区域中存活对象的比例)被计算。
3. 再标记：这个阶段是用来补充收集并发标记阶段产新的新垃圾。与之不同的是，G1中采用了更快的算法:SATB。
4. 清理阶段：选择活性低的区域(同时考虑停顿时间)，等待下次yong GC一起收集，这个过程也会有停顿(STW)。
5. 回收/完成：新的yong GC清理被计算好的区域。但是有一些区域还是可能存在垃圾对象，可能是这些区域中对象活性较高，回收不划算，也肯能是为了迎合用户设置的时间，不得不舍弃一些区域的收集。

### G1和CMS的比较

1. CMS收集器是获取最短回收停顿时间为目标的收集器，因为CMS工作时，GC工作线程与用户线程可以并发执行，以此来达到降低停顿时间的目的（只有初始标记和重新标记会STW）。但是CMS收集器对CPU资源非常敏感。在并发阶段，虽然不会导致用户线程停顿，但是会占用CPU资源而导致引用程序变慢，总吞吐量下降。
2. CMS仅作用于老年代，是基于标记清除算法，所以清理的过程中会有大量的空间碎片。
3. CMS收集器无法处理浮动垃圾，由于CMS并发清理阶段用户线程还在运行，伴随程序的运行自热会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在本次收集中处理它们，只好留待下一次GC时将其清理掉。
4. G1是一款面向服务端应用的垃圾收集器，适用于多核处理器、大内存容量的服务端系统。G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短STW的停顿时间，它满足短时间停顿的同时达到一个高的吞吐量。
5. 从JDK 9开始，G1成为默认的垃圾回收器。当应用有以下任何一种特性时非常适合用G1：Full GC持续时间太长或者太频繁；对象的创建速率和存活率变动很大；应用不希望停顿时间长(长于0.5s甚至1s)。
6. G1将空间划分成很多块（Region），然后他们各自进行回收。堆比较大的时候可以采用，采用复制算法，碎片化问题不严重。整体上看属于标记整理算法,局部(region之间)属于复制算法。**最多2048块，每块在0-32M之间，为2的n次方**
7. G1 需要记忆集来记录新生代和老年代之间的引用关系，这种数据结构在 G1 中需要占用大量的内存，可能达到整个堆内存容量的 20% 甚至更多。而且 G1 中维护记忆集的成本较高，带来了更高的执行负载，影响效率。所以 CMS 在小内存应用上的表现要优于 G1，而大内存应用上 G1 更有优势，大小内存的界限是6GB到8GB。（Card Table（CMS中）的结构是一个连续的byte[]数组，扫描Card Table的时间比扫描整个老年代的代价要小很多！G1也参照了这个思路，不过采用了一种新的数据结构 Remembered Set 简称Rset。RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。每个Region都有一个对应的Rset。）

### 哪些对象可以作为GC Roots

1. 虚拟机栈（栈帧中的本地变量表）中引用的对象。
2. 方法区中类静态属性引用的对象。
3. 方法区中常量引用的对象。
4. 本地方法栈中JNI（即一般说的Native方法）引用的对象。

### GC中Stop the world（STW）

在执行垃圾收集算法时，Java应用程序的其他所有除了垃圾收集收集器线程之外的线程都被挂起。此时，系统只能允许GC线程进行运行，其他线程则会全部暂停，等待GC线程执行完毕后才能再次运行。这些工作都是由虚拟机在后台自动发起和自动完成的，是在用户不可见的情况下把用户正常工作的线程全部停下来，这对于很多的应用程序，尤其是那些对于实时性要求很高的程序来说是难以接受的。

但不是说GC必须STW,你也可以选择降低运行速度但是可以并发执行的收集算法，这取决于你的业务。

### 垃圾回收算法

1. 停止-复制：先暂停程序的运行,然后将所有存活的对象从当前堆复制到另一个堆,没有被复制的对象全部都是垃圾。当对象被复制到新堆时,它们是一个挨着一个的,所以新堆保持紧凑排列,然后就可以按前述方法简单,直接的分配了。缺点是一浪费空间,两个堆之间要来回倒腾,二是当程序进入稳定态时,可能只会产生极少的垃圾,甚至不产生垃圾,尽管如此,复制式回收器仍会将所有内存自一处复制到另一处。
2. 标记-清除：同样是从堆栈和静态存储区出发,遍历所有的引用,进而找出所有存活的对象。每当它找到一个存活的对象,就会给对象一个标记,这个过程中不会回收任何对象。只有全部标记工作完成的时候,清理动作才会开始。在清理过程中,没有标记的对象会被释放,不会发生任何复制动作。所以剩下的堆空间是不连续的,垃圾回收器如果要希望得到连续空间的话,就得重新整理剩下的对象。
3. 标记-整理：它的第一个阶段与标记/清除算法是一模一样的，均是遍历GC Roots，然后将存活的对象标记。移动所有存活的对象，且按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收。因此，第二阶段才称为整理阶段。
4. 分代收集算法：把Java堆分为新生代和老年代，然后根据各个年代的特点采用最合适的收集算法。新生代中，对象的存活率比较低，所以选用复制算法，老年代中对象存活率高且没有额外空间对它进行分配担保，所以使用“标记-清除”或“标记-整理”算法进行回收。

### Minor GC和Full GC触发条件

* Minor GC触发条件：当Eden区满时，触发Minor GC。
* Full GC触发条件：
    1. 调用System.gc时，系统建议执行Full GC，但是不必然执行
    2. 老年代空间不足
    3. 方法区空间不足
    4. 通过Minor GC后进入老年代的平均大小大于老年代的可用内存
    5. 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小
    
### 对象什么时候进入老年代

1. 大对象直接进入老年代。 虚拟机提供了一个阈值参数，令大于这个设置值的对象直接在老年代中分配。如果大对象进入新生代，新生代采用的复制算法收集内存，会导致在Eden区和两个Survivor区之间发生大量的内存复制，应该避免这种情况。
2. 长期存活的对象进入老年代。 虚拟机给每个对象定义了一个年龄计数器，对象在Eden区出生，经过一次Minor GC后仍然存活，并且能被Survivor区容纳的话，将被移动到Survivor区中，此时对象年龄设为1。然后对象在Survivor区中每熬过一次 Minor GC，年龄就增加1，当年龄超过设定的阈值时，就会被移动到老年代中。
3. 动态对象年龄判定： 如果在 Survivor 空间中所有相同年龄的对象，大小总和大于 Survivor 空间的一半，那么年龄大于或等于该年龄的对象就直接进入老年代，无须等到阈值中要求的年龄。
4. 空间分配担保： 如果老年代中最大可用的连续空间大于新生代所有对象的总空间，那么 Minor GC 是安全的。如果老年代中最大可用的连续空间大于历代晋升到老年代的对象的平均大小，就进行一次有风险的 Minor GC，如果小于平均值，就进行 Full GC 来让老年代腾出更多的空间。因为新生代使用的是复制算法，为了内存利用率，只使用其中一个 Survivor 空间来做轮换备份，因此如果大量对象在 Minor GC 后仍然存活，导致 Survivor 空间不够用，就会通过分配担保机制，将多出来的对象提前转到老年代，但老年代要进行担保的前提是自己本身还有容纳这些对象的剩余空间，由于无法提前知道会有多少对象存活下来，所以取之前每次晋升到老年代的对象的平均大小作为经验值，与老年代的剩余空间做比较。

### TLAB

在Java中，**典型的对象不再堆上分配的情况有两种**：TLAB和栈上分配（通过逃逸分析）。JVM在内存新生代Eden Space中开辟了一小块线程私有的区域，称作TLAB（Thread-local allocation buffer）。默认设定为占用Eden Space的1%。在Java程序中很多对象都是小对象且用过即丢，它们不存在线程共享也适合被快速GC，所以对于小对象通常JVM会优先分配在TLAB上，并且TLAB上的分配由于是线程私有所以没有锁开销。因此在实践中分配多个小对象的效率通常比分配一个大对象的效率要高。也就是说，Java中每个线程都会有自己的缓冲区称作TLAB（Thread-local allocation buffer），每个TLAB都只有一个线程可以操作，TLAB结合bump-the-pointer技术可以实现快速的对象分配，而不需要任何的锁进行同步，也就是说，在对象分配的时候不用锁住整个堆，而只需要在自己的缓冲区分配即可。

### Java对象分配的过程

1. 编译器通过逃逸分析，确定对象是在栈上分配还是在堆上分配。如果是在堆上分配，则进入2.
2. 如果tlab_top + size <= tlab_end，则在在TLAB上直接分配对象并增加tlab_top 的值，如果现有的TLAB不足以存放当前对象则3.
3. 重新申请一个TLAB，并再次尝试存放当前对象。如果放不下，则4。
4. 在Eden区加锁（这个区是多线程共享的），如果eden_top + size <= eden_end则将对象存放在Eden区，增加eden_top 的值，如果Eden区不足以存放，则5。
5. 执行一次Young GC（minor collection）
6. 经过Young GC之后，如果Eden区任然不足以存放当前对象，则直接分配到老年代。

### 对象内存分配的两种方法

1. 指针碰撞(Serial、ParNew等带Compact过程的收集器) ：假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump the Pointer）。 
2. 空闲列表(CMS这种基于Mark-Sweep算法的收集器) ：如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。 

### JVM类加载过程

类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载7个阶段。
1. 加载：通过一个类的全限定名来获取定义此类的二进制字节流，将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构，在内存中生成一个代表这个类的Class对象，作为方法去这个类的各种数据的访问入口
2. 验证：验证是连接阶段的第一步，这一阶段的目的是确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟自身的安全。
3. 准备：准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法去中进行分配。这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。
4. 解析：解析阶段是虚拟机将常量池内的符号（Class文件内的符号）引用替换为直接引用（指针）的过程。
5. 初始化：初始化阶段是类加载过程的最后一步，开始执行类中定义的Java程序代码（字节码）。

### Class 和 Object 类哪个先加载？什么时候加载的？

+ java.lang.Object是一个Java类，但并不是java.lang.Class的一个实例。后者只是一个用于描述Java类与接口的、用于支持反射操作的类型
+ java.lang.Class是java.lang.Object的派生类，前者继承自后者。

问题：在一个已经启动完毕、可以使用的Java对象系统里，必须要有一个java.lang.Class实例对应java.lang.Object这个类；而java.lang.Class是java.lang.Object的派生类，按“一般思维”前者应该要在后者完成初始化之后才可以初始化。

答案：这些相互依赖的核心类型完全可以在“混沌”中一口气都初始化好，然后对象系统的状态才叫做完成了“bootstrap”，后面就可以按照Java对象系统的一般规则去运行。JVM、JavaScript、Python、Ruby等的运行时都有这样的bootstrap过程。

在“混沌”（boostrap过程）里，JVM可以为对象系统中最重要的一些核心类型先分配好内存空间，让它们进入[ **已分配空间**]但[ **尚未完全初始化**]状态。此时这些对象虽然已经分配了空间，但因为状态还不完整所以尚不可使用。
然后，通过这些分配好的空间把这些核心类型之间的引用关系串好。到此为止所有动作都由JVM完成，尚未执行任何Java字节码。
然后这些核心类型就进入了[ **完全初始化**]状态，对象系统就可以开始自我运行下去，也就是可以开始执行Java字节码来进一步完成Java系统的初始化了。

### 双亲委派模型

双亲委派的意思是如果一个类加载器需要加载类，那么首先它会把这个类请求委派给父类加载器去完成，每一层都是如此。一直递归到顶层，当父加载器无法完成这个请求时，子类才会尝试去加载。

**作用：安全性（防止修改JDK源码），防止已被加载的类重复加载**

**1、启动类加载器， 根装载器，用户不可访问，Bootstrap ClassLoader，加载JAVA_HOME\lib，或者被-Xbootclasspath参数限定的类**
**2、扩展类加载器，Extension ClassLoader，加载\lib\ext，或者被java.ext.dirs系统变量指定的类**
**3、应用程序类加载器，Application ClassLoader，加载ClassPath中的类库**
**4、自定义类加载器，通过继承ClassLoader实现，一般是加载我们的自定义类** 

### 双亲委派模型的"破坏"

一个典型的例子便是资源管理服务JNDI服务（如JDBC），JNDI现在已经是Java的标准服务，它的代码由启动类加载器去加载(在JDK 1.3时放进去的rt.jar)，但JNDI的目的就是对资源进行集中管理和查找，它需要调用由独立厂商实现并部署在应用程序的ClassPath下的JNDI接口提供者(SPI,Service Provider Interface)的代码，但启动类加载器不可能“认识”这些代码那该怎么办?

为了解决这个问题，Java设计团队只好引入了一个不太优雅的设计:线程上下文类加载器(Thread Context ClassLoader)。这个类加载器可以通过java.lang.Thread类的 setContextClassLoaser()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承 一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。

有了线程上下文类加载器，就可以做一些“舞弊”的事情了，JNDI服务使用这个线程上下 文类加载器去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载的动 作，这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，实际上已经 违背了双亲委派模型的一般性原则，但这也是无可奈何的事情。Java中所有涉及SPI的加载动 作基本上都采用这种方式，例如JNDI、JDBC、JCE、JAXB和JBI等。

### JVM锁优化和膨胀过程

1. 自旋锁：自旋锁其实就是在拿锁时发现已经有线程拿了锁，自己如果去拿会阻塞自己，这个时候会选择进行一次忙循环尝试。也就是不停循环看是否能等到上个线程自己释放锁。自适应自旋锁指的是例如第一次设置最多自旋10次，结果在自旋的过程中成功获得了锁，那么下一次就可以设置成最多自旋20次。
2. 锁粗化：虚拟机通过适当扩大加锁的范围以避免频繁的拿锁释放锁的过程。
3. 锁消除：通过逃逸分析发现其实根本就没有别的线程产生竞争的可能（别的线程没有临界量的引用），或者同步块内进行的是原子操作，而“自作多情”地给自己加上了锁。有可能虚拟机会直接去掉这个锁。
4. 偏向锁：在大多数的情况下，锁不仅不存在多线程的竞争，而且总是由同一个线程获得。因此为了让线程获得锁的代价更低引入了偏向锁的概念。偏向锁的意思是如果一个线程获得了一个偏向锁，如果在接下来的一段时间中没有其他线程来竞争锁，那么持有偏向锁的线程再次进入或者退出同一个同步代码块，不需要再次进行抢占锁和释放锁的操作。
5. 轻量级锁：当存在超过一个线程在竞争同一个同步代码块时，会发生偏向锁的撤销。当前线程会尝试使用CAS来获取锁，当自旋超过指定次数(可以自定义)时仍然无法获得锁，此时锁会膨胀升级为重量级锁。
6. 重量级锁：重量级锁依赖对象内部的monitor锁来实现，而monitor又依赖操作系统的MutexLock（互斥锁）。当系统检查到是重量级锁之后，会把等待想要获取锁的线程阻塞，被阻塞的线程不会消耗CPU，但是阻塞或者唤醒一个线程，都需要通过操作系统来实现。

### 什么情况下需要开始类加载过程的第一个阶段加载

1. 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。
2. 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。
3. 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。
4. 当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个类），虚拟机会先初始化这个主类。

### i++操作的字节码指令

1. 将int类型常量加载到操作数栈顶
2. 将int类型数值从操作数栈顶取出，并存储到到局部变量表的第1个Slot中
3. 将int类型变量从局部变量表的第1个Slot中取出，并放到操作数栈顶
4. 将局部变量表的第1个Slot中的int类型变量加1
5. 表示将int类型数值从操作数栈顶取出，并存储到到局部变量表的第1个Slot中，即i中

### JVM性能监控

1. JDK的命令行工具

    * jps(虚拟机进程状况工具)：jps可以列出正在运行的虚拟机进程，并显示虚拟机执行主类(Main Class,main()函数所在的类)名称 以及这些进程的本地虚拟机唯一ID(Local Virtual Machine Identifier,LVMID)。
    * jstat(虚拟机统计信息监视工具)：jstat是用于监视虚拟机各种运行状态信息的命令行工 具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。
    * jinfo(Java配置信息工具)：jinfo的作用是实时地查看和调整虚拟机各项参数。
    * jmap(Java内存映像工具)：命令用于生成堆转储快照(一般称为heapdump或dump文 件)。如果不使用jmap命令，要想获取Java堆转储快照，还有一些比较“暴力”的手段:譬如 在第2章中用过的-XX:+HeapDumpOnOutOfMemoryError参数，可以让虚拟机在OOM异常出 现之后自动生成dump文件。jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、Java堆和永 久代的详细信息，如空间使用率、当前用的是哪种收集器等。
    * jhat(虚拟机堆转储快照分析工具)：jhat命令与jmap搭配使用，来分析jmap生成的堆 转储快照。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在 浏览器中查看。
    * jstack(Java堆栈跟踪工具)：jstack命令用于生成虚拟机当前时刻的线程快照。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈 的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循 环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。线程出现停顿 的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些 什么事情，或者等待着什么资源。

2. JDK的可视化工具

    * JConsole
    * VisualVM
    
### JVM常见参数

1. -Xms20M：表示设置JVM启动内存的最小值为20M，必须以M为单位
2. -Xmx20M：表示设置JVM启动内存的最大值为20M，必须以M为单位。将-Xmx和-Xms设置为一样可以避免JVM内存自动扩展。大的项目-Xmx和-Xms一般都要设置到10G、20G甚至还要高
3. -verbose:gc：表示输出虚拟机中GC的详细情况
4. -Xss128k：表示可以设置虚拟机栈的大小为128k
5. -Xoss128k：表示设置本地方法栈的大小为128k。不过HotSpot并不区分虚拟机栈和本地方法栈，因此对于HotSpot来说这个参数是无效的
6. -XX:PermSize=10M：表示JVM初始分配的永久代（方法区）的容量，必须以M为单位
7. -XX:MaxPermSize=10M：表示JVM允许分配的永久代（方法区）的最大容量，必须以M为单位，大部分情况下这个参数默认为64M
8. -Xnoclassgc：表示关闭JVM对类的垃圾回收
9. -XX:+TraceClassLoading表示查看类的加载信息
10. -XX:+TraceClassUnLoading：表示查看类的卸载信息
11. -XX:NewRatio=4：表示设置年轻代（包括Eden和两个Survivor区）/老年代 的大小比值为1：4，这意味着年轻代占整个堆的1/5
12. -XX:SurvivorRatio=8：表示设置2个Survivor区：1个Eden区的大小比值为2:8，这意味着Survivor区占整个年轻代的1/5，这个参数默认为8
13. -Xmn20M：表示设置年轻代的大小为20M
14. -XX:+HeapDumpOnOutOfMemoryError：表示可以让虚拟机在出现内存溢出异常时Dump出当前的堆内存转储快照
15. -XX:+UseG1GC：表示让JVM使用G1垃圾收集器
16. -XX:+PrintGCDetails：表示在控制台上打印出GC具体细节
17. -XX:+PrintGC：表示在控制台上打印出GC信息
18. -XX:PretenureSizeThreshold=3145728：表示对象大于3145728（3M）时直接进入老年代分配，这里只能以字节作为单位
19. -XX:MaxTenuringThreshold=1：表示对象年龄大于1，自动进入老年代,如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代的存活时间，增加在年轻代被回收的概率。
20. -XX:CompileThreshold=1000：表示一个方法被调用1000次之后，会被认为是热点代码，并触发即时编译
21. -XX:+PrintHeapAtGC：表示可以看到每次GC前后堆内存布局
22. -XX:+PrintTLAB：表示可以看到TLAB的使用情况
23. -XX:+UseSpining：开启自旋锁
24. -XX:PreBlockSpin：更改自旋锁的自旋次数，使用这个参数必须先开启自旋锁
25. -XX:+UseSerialGC：表示使用jvm的串行垃圾回收机制，该机制适用于单核cpu的环境下
26. -XX:+UseParallelGC：表示使用jvm的并行垃圾回收机制，该机制适合用于多cpu机制，同时对响应时间无强硬要求的环境下，使用-XX:ParallelGCThreads=<N>设置并行垃圾回收的线程数，此值可以设置与机器处理器数量相等。
27. -XX:+UseParallelOldGC：表示年老代使用并行的垃圾回收机制
28. -XX:+UseConcMarkSweepGC：表示使用并发模式的垃圾回收机制，该模式适用于对响应时间要求高，具有多cpu的环境下
29. -XX:MaxGCPauseMillis=100：设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。
30. -XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低响应时间或者收集频率等，此值建议使用并行收集器时，一直打开

### JVM调优目标-何时需要做jvm调优

1. heap 内存（老年代）持续上涨达到设置的最大内存值；
2. Full GC 次数频繁；
3. GC 停顿时间过长（超过1秒）；
4. 应用出现OutOfMemory 等内存异常；
5. 应用中有使用本地缓存且占用大量内存空间；
6. 系统吞吐量与响应性能不高或下降。

### JVM调优实战

1. Major GC和Minor GC频繁

    首先优化Minor GC频繁问题。通常情况下，由于新生代空间较小，Eden区很快被填满，就会导致频繁Minor GC，因此可以通过增大新生代空间来降低Minor GC的频率。例如在相同的内存分配率的前提下，新生代中的Eden区增加一倍，Minor GC的次数就会减少一半。
    
    扩容Eden区虽然可以减少Minor GC的次数，但会增加单次Minor GC时间么？扩容后，Minor GC时增加了T1（扫描时间），但省去T2（复制对象）的时间，更重要的是对于虚拟机来说，复制对象的成本要远高于扫描成本，所以，单次Minor GC时间更多取决于GC后存活对象的数量，而非Eden区的大小。因此如果堆中短期对象很多，那么扩容新生代，单次Minor GC时间不会显著增加。
    
2. 请求高峰期发生GC，导致服务可用性下降

    由于跨代引用的存在，CMS在Remark阶段必须扫描整个堆，同时为了避免扫描时新生代有很多对象，增加了可中断的预清理阶段用来等待Minor GC的发生。只是该阶段有时间限制，如果超时等不到Minor GC，Remark时新生代仍然有很多对象，我们的调优策略是，通过参数强制Remark前进行一次Minor GC，从而降低Remark阶段的时间。
    另外，类似的JVM是如何避免Minor GC时扫描全堆的？ 经过统计信息显示，老年代持有新生代对象引用的情况不足1%，根据这一特性JVM引入了卡表（card table）来实现这一目的。卡表的具体策略是将老年代的空间分成大小为512B的若干张卡（card）。卡表本身是单字节数组，数组中的每个元素对应着一张卡，当发生老年代引用新生代时，虚拟机将该卡对应的卡表元素设置为适当的值。如上图所示，卡表3被标记为脏（卡表还有另外的作用，标识并发标记阶段哪些块被修改过），之后Minor GC时通过扫描卡表就可以很快的识别哪些卡中存在老年代指向新生代的引用。这样虚拟机通过空间换时间的方式，避免了全堆扫描。

3. STW过长的GC

    对于性能要求很高的服务，建议将MaxPermSize和MinPermSize设置成一致（JDK8开始，Perm区完全消失，转而使用元空间。而元空间是直接存在内存中，不在JVM中），Xms和Xmx也设置为相同，这样可以减少内存自动扩容和收缩带来的性能损失。虚拟机启动的时候就会把参数中所设定的内存全部化为私有，即使扩容前有一部分内存不会被用户代码用到，这部分内存在虚拟机中被标识为虚拟内存，也不会交给其他进程使用。

4. 外部命令导致系统缓慢

    一个数字校园应用系统，发现请求响应时间比较慢，通过操作系统的mpstat工具发现CPU使用率很高，并且系统占用绝大多数的CPU资 源的程序并不是应用系统本身。每个用户请求的处理都需要执行一个外部shell脚本来获得系统的一些信息，执行这个shell脚本是通过Java的 Runtime.getRuntime().exec()方法来调用的。这种调用方式可以达到目的，但是它在Java 虚拟机中是非常消耗资源的操作，即使外部命令本身能很快执行完毕，频繁调用时创建进程 的开销也非常可观。Java虚拟机执行这个命令的过程是:首先克隆一个和当前虚拟机拥有一样环境变量的进程，再用这个新的进程去执行外部命令，最后再退出这个进程。如果频繁执行这个操作，系统的消耗会很大，不仅是CPU，内存负担也很重。用户根据建议去掉这个Shell脚本执行的语句，改为使用Java的API去获取这些信息后，系统很快恢复了正常。
    
5. 由Windows虚拟内存导致的长时间停顿

    一个带心跳检测功能的GUI桌面程序，每15秒会发送一次心跳检测信号，如果对方30秒以内都没有信号返回，那就认为和对方程序的连接已经断开。程序上线后发现心跳 检测有误报的概率，查询日志发现误报的原因是程序会偶尔出现间隔约一分钟左右的时间完 全无日志输出，处于停顿状态。
    
    因为是桌面程序，所需的内存并不大(-Xmx256m)，所以开始并没有想到是GC导致的 程序停顿，但是加入参数-XX:+PrintGCApplicationStoppedTime-XX:+PrintGCDateStamps- Xloggc:gclog.log后，从GC日志文件中确认了停顿确实是由GC导致的，大部分GC时间都控 制在100毫秒以内，但偶尔就会出现一次接近1分钟的GC。

    从GC日志中找到长时间停顿的具体日志信息(添加了-XX:+PrintReferenceGC参数)， 找到的日志片段如下所示。从日志中可以看出，真正执行GC动作的时间不是很长，但从准 备开始GC，到真正开始GC之间所消耗的时间却占了绝大部分。
    
    除GC日志之外，还观察到这个GUI程序内存变化的一个特点，当它最小化的时候，资源 管理中显示的占用内存大幅度减小，但是虚拟内存则没有变化，因此怀疑程序在最小化时它的工作内存被自动交换到磁盘的页面文件之中了，这样发生GC时就有可能因为恢复页面文件的操作而导致不正常的GC停顿。在Java的GUI程序中要避免这种现象，可以 加入参数“-Dsun.awt.keepWorkingSetOnMinimize=true”来解决。

## Java基础

### Java基础

#### Java三大特性

1. 封装：是面向对象方法的重要原则，就是把对象的属性和操作（或服务）结合为一个独立的整体，并尽可能隐藏对象的内部实现细节。
2. 继承：继承是从已有的类中派生出新的类，新的类能吸收已有类的数据属性和方法，并能扩展新的能力。 Java类只能单继承，接口可以多继承。
3. 多态：可以说是“一个接口，多种实现”或者说是父类的引用变量可以指向子类的实例，被引用对象的类型决定调用谁的方法，但这个方法必须在父类中定义

#### private、protected、default、public

public：可以被所有其他类所访问

private：只能被自己访问和修改

protected：自身、子类及同一个包中类可以访问

default：同一包中的类可以访问，声明时没有加修饰符，认为是friendly。

#### java重写和重载的区别

重载：是在类中可以创建多个方法，它们具有相同的名字，但具有不同的参数和不同的定义。调用方法时通过传递给它们的不同参数个数和参数类型来决定具体使用哪个方法, 这就是多态性。

重写：子类重写父类某个方法。对父类的函数进行重新定义。如果在子类中定义某方法与其父类有相同的名称和参数

#### 类、抽象类、接口

+ 类

+ 抽象类：在Java中被abstract关键字修饰的类称为抽象类，被abstract关键字修饰的方法称为抽象方法，**抽象方法只有方法的声明，没有方法体**

  + 抽象类不能被实例化只能被继承extends；
  + 包含抽象方法的一定是抽象类，但是抽象类不一定含有抽象方法；
  + 抽象类中的抽象方法的修饰符只能为**public或者protected**，默认为public；
  + 一个子类继承一个抽象类，则子类**必须实现父类抽象方法，否则子类也必须定义为抽象类**；
  + 抽象类可以包含属性、方法、构造方法，但是构造方法不能用于实例化，主要用途是被子类调用。

+ 接口：用interface关键字修饰

  + 接口可以包含变量、方法；变量被隐士指定为public static final
  + 一个类可以实现多个接口；

+ 接口与抽象类的区别：

  + **相同点**

    （1）都不能被实例化 （2）接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化。

  + **不同点**

    （1）接口只有定义，不能有方法的实现，java 1.8中可以定义default方法体，而抽象类可以有定义与实现，方法可在抽象类中实现。

    （2）实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。

    （3）接口强调特定功能的实现，而抽象类强调所属关系。

    （4）接口成员变量默认为public static final，必须赋初值，不能被修改；抽象类中成员变量默认default，可在子类中被重新定义，也可被重新赋值；

#### 引用机制与垃圾回收

+ 强引用：是指创建一个对象并把这个对象赋给一个引用变量。强引用有引用变量指向时永远不会被垃圾回收，JVM宁愿抛出OutOfMemory错误也不会回收这种对象。
+ 软引用：如果一个对象具有软引用，内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存,比如网页缓存、图片缓存等。SoftReference类。
+ 弱引用：弱引用也是用来描述非必需对象的，当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。在java中，用java.lang.ref.WeakReference类来表示。
+ 虚引用：在java中用java.lang.ref.PhantomReference类表示。如果一个对象与虚引用关联，则跟没有引用与之关联一样，在任何时候都可能被垃圾回收器回收。虚引用必须和引用队列关联使用

#### StringBuilder 和 StringBuffer的区别

+ 线程安全：StringBuffer线程安全，所有方法都是用的synchronized修饰，StringBuilder线程不安全
+ 缓冲区：StringBuffer 每次获取 toString 都会直接使用缓存区的 toStringCache 值来构造一个字符串，而 StringBuilder 则每次都需要复制一次字符数组，再构造一个字符串。
+ 性能：既然 StringBuffer 是线程安全的，它的所有公开方法都是同步的，StringBuilder 是没有对方法加锁同步的，所以毫无疑问，StringBuilder 的性能要远大于 StringBuffer。
+ 总结：单线程用StringBuilder，多线程用StringBuffer

#### String为什么要用final修饰

1. 为了安全和效率，final修饰的char数组不能继承，不能更改，需要初始化。
2. 线程安全，不需要同步操作提高了效率。
3. HashCode不可变性，键值往往都是字符串

#### Java中集合与是否线程安全

1. 线程不安全：HashMap、ArrayList、HashSet
2. 线程安全：HashTable、Vector
3. 线程不安全解决方法：
   1. HashMap：使用ConcurrentHashMap
   2. ArrayList：
      1. 使用Vector替代，List<String> a = new Vector();    **vector里面的add方法有synchronized关键字**，但性能会下降
      2. 使用Collections.synchronizedList(new ArrayList<>())，使用Collections工具类转换
      3. 使用CopyOnWriteArrayList()   多线程可以用这个， 原理：**通过添加锁，在写入的时候先复制一遍Arrays.copyof，向复制的里面添加元素，然后将原List的引用指向新的List，这样的好处是读的时候不需要加锁，（读写分离）**
   3. HashSet
      1. CopyOnWriteArraySet，读写分离，写时复制

#### ArrayList

产生原因：ArrayList里面的add方法，扩容和添加元素

```java
public boolean add(E e) {    
    // 确定ArrayList的容量大小    
    ensureCapacity(size + 1);  // Increments modCount!!    
    // 添加e到ArrayList中    
    elementData[size++] = e;    
    return true;    
}
```

解决方法：

1. 使用Vector替代，List<String> a = new Vector();    **vector里面的add方法有synchronized关键字**，但性能会下降
2. 使用Collections.synchronizedList(new ArrayList<>())，使用Collections工具类转换
3. 使用CopyOnWriteArrayList()   多线程可以用这个， 原理：**通过添加锁，在写入的时候先复制一遍Arrays.copyof，向复制的里面添加元素，然后将原List的引用指向新的List，这样的好处是读的时候不需要加锁，（读写分离）**

```java
public boolean add(E e) {
    synchronized (lock) {
        Object[] elements = getArray();
        int len = elements.length;
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        newElements[len] = e;
        setArray(newElements);
        return true;
    }
}
```

####  HashSet

HaseSet底层：内部采用了HashMap作为数据存储，**HashSet其实就是在操作HashMap的key**，value为一个静态常量的对象

```java
public boolean add(E e) {
    return map.put(e, PRESENT)==null;
}
private static final Object PRESENT = new Object();
```

解决方法：CopyOnWriteArraySet，读写分离，写时复制

#### HashMap和ConcurrentHashMap

由于HashMap是线程不同步的，虽然处理数据的效率高，但是在多线程的情况下存在着安全问题，因此设计了**CurrentHashMap**来解决多线程安全问题。

HashMap在put的时候，插入的元素超过了容量（初始容量16，最大容量2^30）（由负载因子决定）的范围就会触**发扩容操作**，就是rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。

HashMap的环：若当前线程此时获得ertry节点，但是被线程中断无法继续执行，此时线程二进入transfer函数，并把函数顺利执行，此时新表中的某个位置有了节点，之后线程一获得执行权继续执行，因为并发transfer，所以两者都是扩容的同一个链表，当线程一执行到e.next = new table[i] 的时候，由于线程二之前数据迁移的原因导致此时new table[i] 上就有ertry存在，所以线程一执行的时候，会将next节点，设置为自己，导致自己互相使用next引用对方，因此产生链表，导致死循环。

在JDK1.7版本中，ConcurrentHashMap维护了一个Segment数组，Segment这个类继承了重入锁ReentrantLock，并且该类里面维护了一个 HashEntry<K,V>[] table数组，在写操作put，remove，扩容的时候，会对Segment加锁，所以仅仅影响这个Segment，不同的Segment还是可以并发的，所以解决了线程的安全问题，同时又采用了分段锁也提升了并发的效率。

**在JDK1.8版本中，ConcurrentHashMap摒弃了Segment的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作，整个看起来就像是优化过且线程安全的HashMap。**

#### HashMap扩容机制

扩容时机：当HashMap中元素的个数超过**容量（初始容量为16） * 负载因子 (0.75)**的时候就会触发扩容操作。

扩容操作：

+ 扩容：创建一个新的Entry数组，长度为原数组的两倍。

+ JDK1.7中会ReHash：遍历原数组，将所有的节点重新Hash到新数组。若没有元素，直接存放在数组中即可；若存在元素，则遍历链表或红黑树，查找已存在为key的元素：若存在，即更新该Node的value值；不存在，插入元素；

+ JDK1.8中使用与&操作：```(e.hash & oldCap) == 0``` 判断哈希值与上原数组长度，如果为0，则位置不变，如果不为0，放在新索引（原索引 + oldCap）处的建立新链表

  ```java
  if ((e.hash & oldCap) == 0) {
      //放在原索引处的建立新链表
      if (loTail == null) loHead = e;
      else loTail.next = e;
      loTail = e;
  } else {
      //放在新索引（原索引 + oldCap）处的建立新链表
      if (hiTail == null) hiHead = e;
      else hiTail.next = e;
      hiTail = e;
  }
  ```

  

#### HashMap的Hash值是怎么计算的

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
// 返回数组下标，通过哈希值
static int indexFor(int h, int length) {
    return h & (length-1);
}
```

+ 通过hashCode()函数计算哈希值
+ 再与哈希值右移16位的值做异或计算
+ 原因：作为扰动函数，hashcode的哈希值范围太大（**-2147483648**到**2147483648**）。   **混合原始哈希码的高位和低位，以此来加大低位的随机性**

#### HashMap源码分析

**HashMap底层：Node类型的数组+Node类型的链表+红黑树**

为什么要用红黑树：比链表要快，而且是平衡的，综合效率最高，时间复杂度为logn

源码分析：当一个值中要存储到Map的时候会根据Key的值来计算出他的hash，通过哈希来确认到数组的位置，如果发生哈希碰撞就以链表的形式存储，但是这样如果链表过长（超过8），HashMap会把这个链表转换成红黑树来存储。当移除remove元素的时候，如果红黑树的节点小于6，就会变为链表。

**在JDK1.7，链表使用的是头插法，放在头部位置。JDK1.8之后变为尾插法**

<img src="http://5b0988e595225.cdn.sohucs.com/images/20190716/9bb15b36ca67499fa0970a497a20c149.jpeg" alt="img" style="zoom:50%;" />

```java
public HashMap(int initialCapacity, float loadFactor)  // 容量+负载因子
```

```java
public V get(Object key) {
    Node<K,V> e;
    // 通过key的hash值找到对应的链表
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
 final Node<K,V> getNode(int hash, Object key) {
     // Node类型数组 和 Node类型链表
     Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
     if ((tab = table) != null && (n = tab.length) > 0 &&
         (first = tab[(n - 1) & hash]) != null) {
         // 在数组中根据hash查找到value，没有发生碰撞
         if (first.hash == hash && // always check first node
             ((k = first.key) == key || (key != null && key.equals(k))))
             return first;
         // 发生了碰撞之后
         if ((e = first.next) != null) {
             if (first instanceof TreeNode)
                 return ((TreeNode<K,V>)first).getTreeNode(hash, key);
             do {
                 if (e.hash == hash &&
                     ((k = e.key) == key || (key != null && key.equals(k))))
                     return e;
             } while ((e = e.next) != null);
         }
     }
     return null;
 }
// 使用了红黑树
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
    TreeNode<K,V> parent;  // red-black tree links
    TreeNode<K,V> left;
    TreeNode<K,V> right;
    TreeNode<K,V> prev;    // needed to unlink next upon deletion
    boolean red;
    TreeNode(int hash, K key, V val, Node<K,V> next) {
        super(hash, key, val, next);
}
```

<img src="https://img-blog.csdnimg.cn/20190613232358564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyOTU2MDQ4,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:90%;" />

#### HashMap如果我想要让自己的Object作为K应该怎么办

1. 重写hashCode()；如果不重写，会调用Object类中的hashCode函数，计算方法是根据对象的地址进行计算的。两个相同对象的hash值会不同，因此需要重写，保证让他们相同。
2. 重写equals()方法，Object.equals()是判断对象地址是否相等，所以需要重写，为了向`HashMap`表明当前对象和`key`上所保存的对象是相等的，这样我们才真正地获得了这个`key`所对应的这个键值对

#### HashMap和HashTable的区别

+ HashMap线程不安全，HashTable线程安全（有syncronized关键字）
+ **HashMap可以存null键和null值，HashTable不可以**
  + HashSet的value存的是一个static finial PRESENT = newObject()。而HashSet的remove是使用HashMap实现,则是map.remove而map的移除会返回value,如果底层value都是存null,显然将无法分辨是否移除成功。

#### ArrayList和LinkedList的区别

1. 数据结构：ArrayList是长度可变的数组（扩容的话是创建一个确定大小的数组，将数据复制过去），LinkedList是双向链表。（这样访问下标会快一点，get方法实现）
2. 效率不同：ArrayList随机访问效率更高，而插入和删除效率低。LinkedList相反

#### Object类中有哪些方法

+ getClass()：获取对象对应的Class对象;
+ hashCode()： 获取对象的hash码，计算方法是根据对象的地址进行计算的；
+ equals()：判断对象的值是否相等，原始equals()方法是判断对象地址是否相等，要重写该方法；
+ clone()：克隆方法，调用对象的该方法只是浅复制，即只会复制字面量。也即基本类型会被复制对应的值，引用类型也会被复制对应的值（只不过是地址的值，复制出来的对象引用的跟原来对象引用的是同一个对象，也就是为什么叫做“浅复制”的原因）。
+ toString()：打印该对象的方法。原始方法是打印该对象hashCode的十六进制；
+ notify()：唤醒等待在对象waitSet上的第一个线程；
+ notifyAll()：唤醒等待在该对象waitSet上的所有线程；
+ wait()：释放该对象的锁，并将当前线程放入该对象的waitSet中；
+ wait(long timeoutMillis)：设置一个最长等待时间，若等待这么常时间该线程仍然未被唤醒，那么该线程就会被自动唤醒；
+ finalize()：垃圾回收时可以重写该方法，但是因为该方法容易导致内存泄漏，因此在JDK9之后就被遗弃了。

#### 简述Java序列化与反序列化的实现

序列化：将java对象转化为字节序列，由此可以通过网络对象进行传输。

反序列化：将字节序列转化为java对象。

具体实现：实现Serializable接口，或实现Externalizable接口中的writeExternal()与readExternal()方法。

#### java中有了基本类型为什么还要有包装类型?

我们知道Java是一个面相对象的编程语言，基本类型并不具有对象的性质，为了让基本类型也具有对象的特征，就出现了包装类型（如我们在使用集合类型Collection时就一定要使用包装类型而非基本类型），它相当于将基本类型“包装起来”，使得它具有了对象的性质，并且为其添加了属性和方法，丰富了基本类型的操作。

另外，当需要往ArrayList，HashMap中放东西时，像int，double这种基本类型是放不进去的，因为容器都是装object的，这是就需要这些基本类型的包装器类了。

区别：

1. 声明方式不同：基本类型不使用new关键字，而包装类型需要使用new关键字来在堆中分配存储空间；

2. 存储方式及位置不同：基本类型是直接将变量值存储在栈中，而包装类型是将对象放在堆中，然后通过引用来使用；

3. 初始值不同：基本类型的初始值如int为0，boolean为false，而包装类型的初始值为null；

4. 使用方式不同：基本类型直接赋值直接使用就好，而包装类型在集合如Collection、Map时会使用到。

#### java装箱和拆箱原理

+ 自动装箱：编译器调用valueOf将原始类型值转换成对象

+ 自动拆箱：编译器通过调用类似intValue(),doubleValue()这类的方法将对象转换成原始类型值。

  <img src="https://img-blog.csdnimg.cn/2019100210164913.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMDMwMDM5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

```java
public static Integer valueOf(int i) {
    if (i >= IntegerCache.low && i <= IntegerCache.high)
        return IntegerCache.cache[i + (-IntegerCache.low)];
    return new Integer(i);
}
// -128,127
// 使用cache里面的，不再创建
```

#### 简述==与equals方法的区别

对于==，在基本数据类型比较时，比较的是对应的值，对引用数据类型比较时，比较的是其内存的存放地址。

对于equals方法，在该方法未被重写时，其效果和==一致，但用户可以根据对应需求对判断逻辑进行改写，比如直接比较对象某个属性值是否相同，相同则返回true，不同则返回false。需保证equals方法相同对应的对象hashCode也相同。

#### Static的作用是什么？

static的主要作用有两个：

1. 为某种特定数据类型或对象分配与创建对象个数无关的单一的存储空间。
2. 使得某个方法或属性与类而不是对象关联在一起，即在不创建对象的情况下可通过类直接调用方法或使用类的属性。

具体而言static又可分为4种使用方式：

1. 修饰成员变量。用static关键字修饰的静态变量在内存中只有一个副本。只要静态变量所在的类被加载，这个静态变量就会被分配空间，可以使用''类.静态变量''和''对象.静态变量''的方法使用。
2. 修饰成员方法。static修饰的方法无需创建对象就可以被调用。static方法中不能使用this和super关键字，不能调用非static方法，只能访问所属类的静态成员变量和静态成员方法。
3. 修饰代码块。JVM在加载类的时候会执行static代码块。static代码块常用于初始化静态变量。static代码块只会被执行一次。
4. 修饰内部类。static内部类可以不依赖外部类实例对象而被实例化。静态内部类不能与外部类有相同的名字，不能访问普通成员变量，只能访问外部类中的静态成员和静态成员方法。

#### Java代码块执行顺序

1. 父类静态代码块（只执行一次）
2. 子类静态代码块（只执行一次）
3. 父类构造代码块
4. 父类构造函数
5. 子类构造代码块
6. 子类构造函数
7. 普通代码块

#### Java异常分类

<img src="https://img-blog.csdnimg.cn/20200114104945961.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvc2hpeHV5ZQ==,size_16,color_FFFFFF,t_70" alt="img" style="zoom: 10%;" />

java异常Throwable是异常的根，包括Error和Exception

+ Error：当程序发生不可控的错误时，通常做法是通知用户并中止程序的执行。与异常不同的是Error及其子类的对象不应被抛出。Error是throwable的子类，代表编译时间和系统错误，用于指示合理的应用程序不应该试图捕获的严重问题。Error由Java虚拟机生成并抛出，包括动态链接失败，虚拟机错误等。程序对其不做处理。
+ Exception：包括Checked和Runtime异常
  + Checked： I/O 错误导致的 IOException、SQLException。一般是外部错误，这种异常都发生在编译阶段，Java 编译器会强制程序去捕获此类异常，即会出现要求你把这段可能出现异常的程序进行 try catch。
  + RuntimeException：NullPointerException 、 ClassCastException ；是那些可能在 Java 虚拟机正常运行期间抛出的异常的超类。 如果出现 RuntimeException，那么一定是程序员代码书写导致的错误.

#### Try Catch finally执行顺序

1、不管有木有出现异常，finally块中代码都会执行；
2、当try和catch中有return时，finally仍然会执行；
3、finally是在return后面的表达式运算后执行的（此时并没有返回运算后的值，而是先把要返回的值保存起来，管finally中的代码怎么样，返回的值都不会改变，任然是之前保存的值），所以函数返回值是在finally执行前确定的；
4、finally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值。

#### Java反射机制

（1）Java反射机制的核心是在**程序运行时动态加载类并获取类的详细信息**，从而操作类或对象的属性和方法。本质是JVM得到class对象之后，再通过class对象进行反编译，从而获取对象的各种信息。

（2）Java属于先编译再运行的语言，程序中对象的类型在编译期就确定下来了，而当程序在运行时可能需要动态加载某些类，这些类因为之前用不到，所以没有被加载到JVM。**通过反射，可以在运行时动态地创建对象并调用其属性，不需要提前在编译期知道运行的对象是谁。**

用途：

1、反编译：.class-->.java

2、通过反射机制访问java对象的属性，方法，构造方法等

3、当我们在使用IDE,比如Ecplise时，当我们输入一个对象或者类，并想调用他的属性和方法是，一按点号，编译器就会自动列出他的属性或者方法，这里就是用到反射。

4、反射最重要的用途就是开发各种通用框架。比如很多框架（Spring）都是配置化的（比如通过XML文件配置Bean），为了保证框架的通用性，他们可能需要根据配置文件加载不同的类或者对象，调用不同的方法，这个时候就必须使用到反射了，运行时动态加载需要的加载的对象。

常用类：

+ Java.lang.Class;
+ Java.lang.reflect.Constructor;
+ Java.lang.reflect.Field;
+ Java.lang.reflect.Method;
+ Java.lang.reflect.Modifier;

基本使用：

+ 获得class：Object.getClass()，数据类型（对象）的静态class属性 Student.class，通过class类的静态方法 Class.forName(String ClassName)
+ 判断是否为某个类的示例   public native boolean isInstance(Object obj);
+ 创建实例：
  + 使用Class对象的newInstance()方法来创建Class对象对应类的实例。
  + 先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建对象，这种方法可以用指定的构造器构造类的实例。

#### java动态代理实现

运用场景：Spring AOP，RPC，Spring 注解对象获取。

+ JDK动态代理：利用反射机制在运行时创建代理类的，只能为接口创建动态代理。主要包括目标接口，目标类(实现了目标接口),扩展处理器InvocationHandler类。

  ```java
  //目标接口，对应ITraget
  public interface Subject {
      void hello(String str);
  }
  
  //目标类，对应Target
  public class RealSubject implements Subject{
      public void hello(String str) {
          System.out.println("hello" + str);
      }
  }
  
  //InvocationHandler增强处理器接口实现类
  //方法调用句柄invoke方法内部就是代理类的扩展点
  public class DynamicProxy implements InvocationHandler{
  
      private Object target;//反射代理目标类(被代理，解耦的目标类)
      
      //可以通过构造器动态设置被代理目标类，以便于调用指定方法
      public DynamicProxy(Object subject){
          this.target = subject;
      }
      
      //代理过程中的扩展点
      public Object invoke(Object proxy, Method method, Object[] args)
              throws Throwable {
          System.out.println("brfore call specific method >>" + method.getName());
          Object result = method.invoke(target, args);//MethodAccessor.invoke()
          System.out.println("after call specific method>>" + method.getName());
          return result;
      }
  }
  
  public class Client {
      public static void main(String[] args) {
          //设置生成代理类文件到本地
          System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles","true"); 
          Subject subject2 = (Subject)Proxy.newProxyInstance(Client.class.getClassLoader(),
                               new Class[]{Subject.class}, new DynamicProxy(new RealSubject()));
          //调用代理类方法
          subject2.hello("proxy");
      }
  }
  ```

+ cglib动态代理：利用ASM开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。

#### Java泛型

泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。意味着编写的代码可以被不同类型的对象所重用。主要包括泛型类、泛型接口、泛型方法。好处：

- 类型安全 
  - 泛型的主要目标是提高 Java 程序的类型安全
  - 编译时期就可以检查出因 Java 类型不正确导致的 ClassCastException 异常
  - 符合越早出错代价越小原则
- 消除强制类型转换 
  - 泛型的一个附带好处是，使用时直接得到目标类型，消除许多强制类型转换
  - 所得即所需，这使得代码更加可读，并且减少了出错机会
- 潜在的性能收益 
  - 由于泛型的实现方式，支持泛型（几乎）不需要 JVM 或类文件更改
  - 所有工作都在编译器中完成
  - 编译器生成的代码跟不使用泛型（和强制类型转换）时所写的代码几乎一致，只是更能确保类型安全而已

#### Java泛型类、接口、方法

```java
// 举个例子为什么要用泛型
List arrayList = new ArrayList();
arrayList.add("aaaa");
arrayList.add(100);

for(int i = 0; i< arrayList.size();i++){
    String item = (String)arrayList.get(i);
    Log.d("泛型测试","item = " + item);
}
// 会直接报错， java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String
// 泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型

// 泛型类，可以使用任意类进行初始化，包括Intger、String
/*
class 类名称 <泛型标识：可以随便写任意标识号，标识指定的泛型的类型>{
  private 泛型标识 var; 
*/
public class Generic<T>{ 
    //key这个成员变量的类型为T,T的类型由外部指定  
    private T key;

    public Generic(T key) { //泛型构造方法形参key的类型也为T，T的类型由外部指定
        this.key = key;
    }

    public T getKey(){ //泛型方法getKey的返回值类型为T，T的类型由外部指定
        return key;
    }
}

// 泛型接口
public interface Generator<T> {
    public T next();
}
// 未传入泛型实参
class FruitGenerator<T> implements Generator<T>{
    @Override
    public T next() {
        return null;
    }
}
// 传入泛型实参
public class FruitGenerator implements Generator<String> {
    private String[] fruits = new String[]{"Apple", "Banana", "Pear"};
    @Override
    public String next() {
        Random rand = new Random();
        return fruits[rand.nextInt(3)];
    }
}
// 泛型方法
public <T> T genericMethod(Class<T> tClass)throws InstantiationException ,
  IllegalAccessException{
        T instance = tClass.newInstance();
        return instance;
}
```

#### 泛型的通配符

<?>表示无限制通配符

<? extends E> 关键字声明了类型的上界，表示参数化的类型可能是所指定的类型，或者是此类型的子类 

<? super E> 关键字声明了类型的下界，表示参数化的类型可能是指定的类型，或者是此类型的父类

#### 泛型的类型擦除

在 Java 中，泛型是 Java 编译器的概念，用泛型编写的 Java 程序和普通的 Java 程序基本相同，只是多了一些参数化的类型同时少了一些类型转换。

实际上泛型程序也是首先被转化成一般的、不带泛型的 Java 程序后再进行处理的，编译器自动完成了从 Generic Java 到普通 Java 的翻译，Java 虚拟机运行时对泛型基本一无所知。

当编译器对带有泛型的java代码进行编译时，**它会去执行类型检查和类型推断，然后生成普通的不带泛型的字节码，这种普通的字节码可以被一般的 Java 虚拟机接收并执行，这在就叫做 类型擦除（type erasure）**。

#### Java形参可变长参数

Object... params：使用…将参数声明成可变长参数。可变长参数必须是最后一个参数。可变参数同时可以跟固定的参数混合使用，但是一个方法的参数中不能同时拥有2种类型的可变参数。

```java
private static int sumUp(int... values) {   
    int sum = 0;   
    for (int i = 0; i < values.length; i++) {   
        sum += values[i];   
    }   
    return sum;   
}  
```

### Java高并发

#### JMM

Java内存模型（java Memory Model）：描述了一组规则，定义了程序中各个变量的访问方式，**以实现让java程序在各种平台下都能达到一致的并发效果。**

Java内存模型规定**所有的变量都存储在主内存**中，包括实例变量，静态变量，但是不包括局部变量和方法参数。每个线程都有自己的工作内存，**线程的工作内存保存了该线程用到的变量和主内存的副本拷贝，线程对变量的操作都在工作内存中进行，不能直接读写主内存中的变量**。

当线程改变工作内存某个变量值的时候，会写回主内存中的值，主内存通过**volatile关键字**通知其他含有该变量的线程。

整个Java内存模型实际上是围绕着三个特征建立起来的。分别是：**原子性，可见性，有序性**。这三个特征可谓是整个Java并发的基础。

![img](https://pic3.zhimg.com/80/v2-f36f366c07a6188ea3fdefc794ba021a_720w.jpg)

#### Happen-Before原则

 JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证（**如果A线程的写操作a与B线程的读操作b之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作将对b操作可见**）。

#### volatile

volatile在多处理器开发中保证了共享变量的“ 可见性”。可见性的意思是当一个线程修改一个共享变量时（写回主内存），另外一个线程能读到这个修改的值。(共享内存，私有内存)

**底层原理：**volatile变量修饰的共享变量进行写操作时会多出一行含有Lock前缀指令的汇编指令，这个指令会引发下面两件事

1. 将当前处理器缓存行的数据写回到系统内存。
2. 这个写回到内存的操作会使在其他CPU里缓存了该内存地址的数据无效。

**能否保证原子性？**

首先需要了解的是，Java中只有对基本类型变量的赋值和读取是原子操作，如i = 1的赋值操作，但是像j = i或者i++这样的操作都不是原子操作，因为他们都进行了多次原子操作，比如先读取i的值，再将i的值赋值给j，两个原子操作加起来就不是原子操作了。

所以，如果一个变量被volatile修饰了，那么肯定可以保证每次读取这个变量值的时候得到的值是最新的，但是一旦需要对变量进行自增这样的非原子操作，就不会保证这个变量的原子性了。

#### Synchronized（线程同步）

synchronized关键字是java提供的锁机制，主要解决线程的同步问题，那么它可以修饰方法和同步代码块。synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的**互斥锁（Mutex Lock）**来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。这种依赖于操作系统互斥锁（Mutex Lock）所实现的锁我们称之为“重量级锁”。

#### Synchronized和Lock的区别

1. （关键字）首先synchronized是java内置关键字在jvm层面；（java类）Lock是个java类。
2. （不能获取锁状态）synchronized无法判断是否获取锁的状态；（可以获得锁状态）Lock可以判断是否获取到锁，并且可以主动尝试去获取锁。
3. （会自动释放锁）synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)；（不会自动释放锁，可能导致死锁）Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁。**（死锁问题）**
4. （线程不可中断）用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去；（线程可中断）而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了。
5. （非公平锁）synchronized的锁可重入（线程可以进入任何一个它已经拥有的锁所同步着的代码块）、不可中断、非公平；（都可以）而Lock锁可重入、可判断、可公平（两者皆可）
6. （效率高）Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。

#### Synchronized和ReentryLock的区别

1. 实现的原理不同
   synchronized是关键字，属于JVM层面，是基于Monitor对象实现的同步，每次对锁的获取与释放会带来用户态和内核态之间的切换，非常影响性能，在并发量较高的时候，synchronized性能不高。JDK1.6之后有优化。
   ReentryLock，Lock锁是基于API层面的互斥锁，lock()与unlock()方法配合try/finnally语句块来完成。

2. 使用方法

   synchronized不需要用户自己去手动的加锁和释放锁，同步代码块采用monitor enter和monitor exit指令来实现，而同步方法则使用ACC_SYNCHRONIZED标记符隐式的实现。
   ReentrantLock则需要用户去手动加锁和释放锁，释放锁一般放在finally语句块里面，避免异常导致的死锁，所以需要lock()和unlock()方法配合try/finally语句块来完成。

3. 等待是否可中断
   synchronized不可中断，除非抛出异常或者正常运行完成。
   ReentrantLock可中断，1.设置超时方法 tryLock(long timeout,TimeUnit unit)；2.lockInterruptibly()放代码块中，调用interrupt()方法可中断。
4. 是否实现公平
   synchronized是非公平锁，没有实现公平。
   ReentrantLock默认非公平锁，构造方法可以传入boolean值，true为公平锁，false为非公平锁。

#### 什么是锁可重入？

指的是以线程为单位，当一个线程获取对象锁之后，这个线程可以再次获取本对象上的锁，而其他的线程是不可以的。

实现原理实现是通过为每个锁关联一个请求计数器和一个占有它的线程。当计数为0时，认为锁是未被占有的；线程请求一个未被占有的锁时，JVM将记录锁的占有者，并且将请求计数器置为1 。

如果同一个线程再次请求这个锁，计数器将递增；每次占用线程退出同步块，计数器值将递减。直到计数器为0,锁被释放。

#### Atomic类的CAS操作，及缺点

CAS是英文单词CompareAndSwap的缩写，中文意思是：比较并替换。CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。如 Intel 处理器，比较并交换通过指令的 cmpxchg 系列实现。（类似于乐观锁，比较version如果相同就更换）

缺点：

1. 循环时间开销很大
2. 只能保证一个共享变量的原子操作
3. 引来ABA问题

#### CAS操作ABA问题：

如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。Java并发包为了解决这个问题，**提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性**。（乐观锁）

#### AQS理论的数据结构

**AQS：AbstractQuenedSynchronizer抽象的队列式同步器。是除了java自带的synchronized关键字之外的锁机制。**

AQS内部有3个对象，一个是state（用于计数器，类似gc的回收计数器），一个是线程标记（当前线程是谁加锁的），一个是阻塞队列。

AQS是自旋锁，在等待唤醒的时候，经常会使用自旋的方式，不停地尝试获取锁，直到被其他线程获取成功。

AQS有两个队列，同步对列和条件队列。同步队列依赖一个双向链表来完成同步状态的管理，当前线程获取同步状态失败后，同步器会将线程构建成一个节点，并将其加入同步队列中。通过signal或signalAll将条件队列中的节点转移到同步队列。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20181128142923147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L211bGluc2VuNzc=,size_16,color_FFFFFF,t_70)



#### Java并发包常见的类JUC

1. ConcurrentHashMap
2. CopyOnWriteArrayList、CopyOnWriteArraySet：线程安全的ArrayList和ArraySet
3. ArrayBlockingQueue
4. Atomic：原子类，指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰
   + AtomicInteger、AtomicBoolean



### Java线程

#### Thread类中run()方法和start()方法的区别

+ 用start方法来启动线程，真正实现了多线程运行，这时无需等待run方法体代码执行完毕而直接继续执行下面的代码。通过调用Thread类的start()方法来启动一个线程，**这时此线程处于就绪（可运行）状态**，并没有运行，一旦得到spu时间片，就开始执行run()方法，这里方法run()称为线程体，它包含了要执行的这个线程的内容，Run方法运行结束，此线程随即终止。
+ run()方法只是类的一个普通方法而已，如果直接调用Run方法，程序中依然只有主线程这一个线程，其程序执行路径还是只有一条，还是要顺序执行，还是要等待run方法体执行完毕后才可继续执行下面的代码，这样就没有达到写线程的目的。

```java
public static void main(String[] args) {
    threadA a = new threadA();
    a.start();
}
public class threadA extends Thread {
    public void run() {
        System.out.println(Thread.currentThread().getName());
    }
}
// run()  输出:main
// start()  输出：thread-0
```

#### 如何指定多个线程的执行顺序

1. 设定一个 orderNum，每个线程执行结束之后，更新 orderNum，指明下一个要执行的线程。并且唤醒所有的等待线程。
2. 在每一个线程的开始，要 while 判断 orderNum 是否等于自己的要求值，不是，则 wait，是则执行本线程。

#### Java多线程实现的方式

1. 基础Thread类实现

2. 实现Runnable接口方式实现多线程

3. 使用Callable、FutureTask实现有返回结果的多线程

   ```java
   public class test implements Callable {
       public static void main(String[] args) {
           FutureTask task = new FutureTask(new test());
           new Thread(task).run();
           try {
               System.out.println(task.get());
           } catch (InterruptedException e) {
               e.printStackTrace();
           } catch (ExecutionException e) {
               e.printStackTrace();
           }
       }
   
       @Override
       public Object call() throws Exception {
           System.out.println("线程方法");
           Thread.sleep(1000);
           return "112233";
       }
   }
   ```

4. 通过线程池

#### Callable、Runable和FutureTask的区别：

+ Runable只有一个run()函数，用于将耗时操作写在其中，**该函数没有返回值**。然后使用某个线程去执行该runnable即可实现多线程，**Thread类在调用start()函数后就是执行的是Runnable的run()函数**
+ Callable中有一个call()函数，**但是call()函数有返回值**，而Runnable的run()函数不能将结果返回给客户程序
+ FutureTask是Future接口的一个唯一实现类。Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果等操作。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果
  FutureTask实现了Runnable，因此它既可以通过Thread包装来直接执行，也可以提交给ExecuteService来执行。
  FutureTask实现了Futrue可以直接通过get()函数获取执行结果，该函数会阻塞，直到结果返回。

#### wait和sleep的区别：

1、sleep方法是Thread类的静态方法；wait方法是Object类的成员方法

2、sleep方法使当前线程暂停执行指定的时间，让出cpu给其他线程，但是它的监控状态依然保持着，当指定的时间到了又会自动恢复运行状态。在调用sleep方法后，**线程不会释放对象锁**；而当调用wait方法时，**线程会放弃对象锁**，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池处于准备状态。

 3、sleep方法有可能会抛出异常，所以需要进行异常处理；wait方法不需要处理

 4、sleep方法可以在任何地方使用；wait方法只能在同步方法和同步代码块中使用

#### 为什么要使用线程池

1. 减少创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。
2. 可以根据系统的承受能力，调整线程池中工作线程的数目，放置因为消耗过多的内存，而把服务器累趴下。

#### 核心线程池ThreadPoolExecutor内部参数

1. corePoolSize：指定了线程池中的线程数量
2. maximumPoolSize：指定了线程池中的最大线程数量
3. keepAliveTime：线程池维护线程所允许的空闲时间
4. unit: keepAliveTime 的单位。
5. workQueue：任务队列，被提交但尚未被执行的任务。
6. threadFactory：线程工厂，用于创建线程，一般用默认的即可。
7. handler：拒绝策略。当任务太多来不及处理，如何拒绝任务。

#### 常用的线程池

+ newCachedThreadPool：缓存线程池；适用于执行大量（并发）短期异步的任务；注意，任务量的负载要轻；比如同时给很多人发送从磁盘读取的消息通知。
+ newFixedThreadPool：定长线程池；适用于执行负载重，cpu使用频率高的任务；这个主要是为了防止太多线程进行大量的线程频繁切换，得不偿失；比如同时很多人进行商品秒杀。
+ newSingleThreadExecutor：单线程线程池； 这个一般用来执行需要按照指定顺序的任务。
+ newScheduledThreadPool：周期定长线程池； 一般是周期性的任务，不过这个可以使用其他的替代；

#### 线程池的执行流程

1. 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务
2. 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列
3. 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务
4. 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException

#### 线程池都有哪几种工作队列

1. ArrayBlockingQueue：底层是数组，有界队列，如果我们要使用生产者-消费者模式，这是非常好的选择。
2. LinkedBlockingQueue：底层是链表，可以当做无界和有界队列来使用，所以大家不要以为它就是无界队列。
3. SynchronousQueue：本身不带有空间来存储任何元素，使用上可以选择公平模式和非公平模式。
4. PriorityBlockingQueue：无界队列，基于数组，数据结构为二叉堆，数组第一个也是树的根节点总是最小值。

举例 ArrayBlockingQueue 实现并发同步的原理：原理就是读操作和写操作都需要获取到 AQS 独占锁才能进行操作。如果队列为空，这个时候读操作的线程进入到读线程队列排队，等待写线程写入新的元素，然后唤醒读线程队列的第一个等待线程。如果队列已满，这个时候写操作的线程进入到写线程队列排队，等待读线程将队列元素移除腾出空间，然后唤醒写线程队列的第一个等待线程。

#### 线程池的拒绝策略

1. ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。
2. ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。
3. ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务
4. ThreadPoolExecutor.CallerRunsPolicy：由调用线程（提交任务的线程）处理该任务

#### 线程池的线程数量怎么确定

1. 一般来说，如果是CPU密集型应用，则线程池大小设置为N+1。 （指内存性能比CPU要好，CPU经常处理高负载的情况）
2. 一般来说，如果是IO密集型应用，则线程池大小设置为2N+1。 （指CPU比内存要好，经常需要等待IO加载）
3. 在IO优化中，线程等待时间所占比例越高，需要越多线程，线程CPU时间所占比例越高，需要越少线程。这样的估算公式可能更适合：最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目
4. 如何确定是CPU还是IO密集型：看cpu和内存的状态

#### 如何实现一个带优先级的线程池

利用priority参数，继承 ThreadPoolExecutor 使用 PriorityBlockingQueue 优先级队列。

#### ThreadLocal的原理和实现

多线程访问同一个共享变量的时候容易出现并发问题，特别是多个线程对一个变量进行写入的时候，为了保证线程安全，一般使用者在访问共享变量的时候需要进行额外的同步措施才能保证线程安全性。**ThreadLocal是除了加锁这种同步方式之外的一种保证一种规避多线程访问出现线程不安全的方法**，当我们在创建一个变量后，如果每个线程对其进行访问的时候访问的都是线程自己的变量这样就不会存在线程不安全问题。

ThreadLoal 变量，线程局部变量，同一个 ThreadLocal 所包含的对象，在不同的 Thread 中有不同的副本。ThreadLocal 变量通常被private static修饰。当一个线程结束时，它所使用的所有 ThreadLocal 相对的实例副本都可被回收。

原理：

一个线程内可以存在多个 ThreadLocal 对象，所以其实是**ThreadLocal 内部维护了一个 Map** ，这个 Map 不是直接使用的 HashMap ，而是 ThreadLocal 实现的一个叫做 ThreadLocalMap 的静态内部类。而我们使用的 get()、set() 方法其实都是调用了这个ThreadLocalMap类对应的 get()、set() 方法。

**这个储值的Map并非ThreadLocal的成员变量，而是java.lang.Thread 类的成员变量。ThreadLocalMap实例是作为java.lang.Thread的成员变量存储的，每个线程有唯一的一个threadLocalMap。这个map以ThreadLocal对象为key，”线程局部变量”为值，所以一个线程下可以保存多个”线程局部变量”**。

对ThreadLocal的操作，实际委托给当前Thread，每个Thread都会有自己独立的ThreadLocalMap实例，存储的仓库是Entry[] table；Entry的key为ThreadLocal，value为存储内容；因此在并发环境下，对ThreadLocal的set或get，不会有任何问题。由于Tomcat线程池的原因，我最初使用的”线程局部变量”保存的值，在下一次请求依然存在（同一个线程处理），这样每次请求都是在本线程中取值。所以在线程池的情况下，处理完成后主动调用该业务treadLocal的remove()方法，将”线程局部变量”清空，避免本线程下次处理的时候依然存在旧数据。

#### ThreadLocal为什么要使用弱引用和内存泄露问题

在ThreadLocal中内存泄漏是指ThreadLocalMap中的Entry中的key为null，而value不为null。因为key为null导致value一直访问不到，而根据可达性分析导致在垃圾回收的时候进行可达性分析的时候,value可达从而不会被回收掉，但是该value永远不能被访问到，这样就存在了内存泄漏。

如果 key 是强引用，那么发生 GC 时 ThreadLocalMap 还持有 ThreadLocal 的强引用，会导致 ThreadLocal 不会被回收，从而导致内存泄漏。弱引用 ThreadLocal 不会内存泄漏，对应的 value 在下一次 ThreadLocalMap 调用 set、get、remove 方法时被清除，这算是最优的解决方案。

Map中的key为一个threadlocal实例.如果使用强引用，当ThreadLocal对象（假设为ThreadLocal@123456）的引用被回收了，ThreadLocalMap本身依然还持有ThreadLocal@123456的强引用，如果没有手动删除这个key，则ThreadLocal@123456不会被回收，所以只要当前线程不消亡，ThreadLocalMap引用的那些对象就不会被回收，可以认为这导致Entry内存泄漏。

如果使用弱引用，那指向ThreadLocal@123456对象的引用就两个：ThreadLocal强引用和ThreadLocalMap中Entry的弱引用。一旦ThreadLocal强引用被回收，则指向ThreadLocal@123456的就只有弱引用了，在下次gc的时候，这个ThreadLocal@123456就会被回收。

虽然上述的弱引用解决了key，也就是线程的ThreadLocal能及时被回收，但是value却依然存在内存泄漏的问题。当把threadlocal实例置为null以后,没有任何强引用指向threadlocal实例,所以threadlocal将会被gc回收.map里面的value却没有被回收.而这块value永远不会被访问到了. 所以存在着内存泄露,因为存在一条从current thread连接过来的强引用.只有当前thread结束以后, current thread就不会存在栈中,强引用断开, Current Thread, Map, value将全部被GC回收.所以当线程的某个localThread使用完了，马上调用threadlocal的remove方法,就不会发生这种情况了。

另外其实只要这个线程对象及时被gc回收，这个内存泄露问题影响不大，但在threadLocal设为null到线程结束中间这段时间不会被回收的，就发生了我们认为的内存泄露。最要命的是线程对象不被回收的情况，这就发生了真正意义上的内存泄露。比如使用线程池的时候，线程结束是不会销毁的，会再次使用，就可能出现内存泄露。

#### 内存泄露和内存溢出

+ 内存泄露：申请的内存空间没有被正确释放，导致后续程序里这块内存被永远占用（不可达），而且指向这块内存空间的指针不再存在时，这块内存也就永远不可达了，内存空间就这么一点点被蚕食
  + 出现场景：1）静态集合类   2）单例模式 3）ThreadLocal

内存溢出：存储的数据超出了指定空间的大小，这时数据就会越界，举例来说，常见的溢出，是指在栈空间里，分配了超过数组长度的数据。

### Boolean占几个字节

未精确定义字节。Java语言表达式所操作的boolean值，在编译之后都使用Java虚拟机中的int数据类型来代替，而boolean数组将会被编码成Java虚拟机的byte数组，每个元素boolean元素占8位。

### （Java网络IO模型）阻塞非阻塞与同步异步的区别

1. 同步和异步关注的是消息通信机制
   1. 所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。
   2. 而异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。
2. 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态。
   1. 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
   2. 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。
3. BIO：同步阻塞模型
4. NIO：同步非阻塞模型，IO多路复用
5. AIO：异步非阻塞模型

具体实现如epoll，select见linux中的IO多路复用。

**BIO 和 NIO 作为 Server 端，当建立了 10 个连接时，分别产生多少个线程？**

因为传统的 IO 也就是 BIO 是同步线程堵塞的，所以每个连接都要分配一个专用线程来处理请求，这样 10 个连接就会创建 10 个线程去处理。而 NIO 是一种同步非阻塞的 I/O 模型，它的核心技术是多路复用，可以使用一个链接上的不同通道来处理不同的请求，所以即使有 10 个连接，对于 NIO 来说，开启 1 个线程就够了。

### Java SPI

由于双亲委派模型损失了一丢丢灵活性。就比如java.sql.Driver这个东西。JDK只能提供一个规范接口，而不能提供实现。提供实现的是实际的数据库提供商。提供商的库总不能放JDK目录里吧。Java从1.6搞出了SPI就是为了优雅的解决这类问题——JDK提供接口，供应商提供服务。编程人员编码时面向接口编程，然后JDK能够自动找到合适的实现。



## Spring、SpirngMVC、SpringBoot框架

### 什么是Spring？

Spring是一种轻量级开发框架，旨在提高开发人员的开发效率以及系统的可维护性。我们说的Spring框架是很多模块的集合，包括核心容器，数据访问集成，web，AOP等等。

### RestController和Controller的区别？

+ 单独使用Controller时，适用于前后端不分离的应用，Controller返回一个model and view。

+ RestController将返回数据写入ResponseBody中，Controller+ResponseBody注解一起用和RestController是一样的功能。

### Spring AOP和IOC

+ Aop：面向切面编程，**用于将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑，抽取并封装为一个可重用的模块，这个模块被命名为“切面”（Aspect）**，减少系统中的重复代码，降低了模块间的耦合度，提高系统的可维护性。可用于权限认证、日志、事务处理。AOP代理主要分为静态代理和动态代理。静态代理的代表为AspectJ；动态代理则以Spring AOP为代表。
+ IOC：控制反转，是一种设计思想，将类与类的依赖关系写在配置文件中，程序在运行时根据配置文件动态加载依赖的类，降低的类与类之间的耦合度。通常，我们实例化一个对象时，都是使用类的构造方法来new一个对象，这个过程是由我们自己来控制的，而控制反转就把new对象的工交给了Spring容器。
  + 它的原理是在applicationContext.xml加入bean标签,在bean标签中通过class属性说明具体类名、通过property标签说明该类的属性名、通过constructor-args说明构造子类参数。
  + **注入方法：setter注入、基于注解注入、构造方法注入**

### AOP实现原理（动态代理）

AOP的实现最核心的就是利用JDK的动态代理或者cglib实现，项目启动时通过反射获取相关的信息，在创建代理对象时，如果被代理对象实现了接口，就是用JDK动态代理，如果没有实现接口，就使用cglib创建被代理对象的子类来实现代理。

+ 静态代理AspectJ：编译时操作字节码增强，运行时更快

+ 动态代理Spring AOP：运行时动态增强
  + JDK动态代理：利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。
  + CGlib动态代理：利用ASM（开源的Java字节码编辑库，操作字节码）开源包，将代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。
  + 区别：JDK代理只能对实现接口的类生成代理；CGlib是针对类实现代理，对指定的类生成一个子类，并覆盖其中的方法，这种通过继承类的实现方式，不能代理final修饰的类。

### Bean的作用域

spring容器需要管理对象的生命周期，spring通过scope作用域的概念给使用者对对象生命周期的更精细的控制。

- singleton：单例，会一直存活直到容器关闭，spring默认的对象作用域是单例的
- prototype：多实例，每次请求都会创建一个新的对象，交给使用方以后，spring就不负责管理对象的生命周期了
- request：每次请求都创建一个实例，请求完毕后销毁对象
- session：每个session创建一个实例，session失效后销毁对象实例

### 单例Bean的线程安全问题

对单例bean的**非静态成员变量**的读写会有线程安全问题。 **因为成员变量是存放在堆内存中，而堆内存又是线程共享的，这就造成了线程安全问题**

如果每个线程对成员变量的修改业务上没有关联，可以通过使用ThreadLocal来保存每个线程单独的变量拷贝副本来实现线程安全。

### @Component和@Bean的区别

- 作用对象不同：component作用于类，bean作用于方法。
- bean注解适用于引用第三方类库的bean时使用，因为没办法使用component注解用于第三方类库的源码

### 类声明为Bean的注解

- Component：通用注解
- Service：Service层的注解
- Controller：控制层的注解
- Repository：DAO层的注解

### Bean的生命周期

1. 实例化 Instantiation：
2. 属性赋值 Populate
   1. 调用 `BeanNameAware` 的 `setBeanName(String name)` 设置 bean 的 id；
   2. 调用 `BeanFactoryAware` 的 `setBeanFactory(BeanFactory beanFactory)` 设置 `BeanFactory` Bean工厂；
   3. 同上：`ApplicationContextAware``setApplicationContext(ApplicationContext applicationContext)`；
3. 初始化 Initialization
   1. 如果实现 `BeanPostProcessor`，则 调用 postProcessBeforeInitialization() 初始化前的后置处理方法
   2. 如果实现了 `InitializingBean` 接口，则使用 `afterPropertiesSet()` 来初始化属性
   3. 如果实现 `BeanPostProcessor`，则 调用 postProcessAfterInitialization() 初始化后的后置处理方法
4. 销毁 Destruction

### Spring用到了什么设计模式

工厂模式：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。BeanFactory就是简单工厂模式的体现，用来创建对象的实例；

单例模式：保证一个类仅有一个实例，并提供一个访问它的全局访问点。Bean默认为单例模式，scope=singleton

代理模式：为其他对象提供一种代理以控制对这个对象的访问。Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术；

模板方法：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。

观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现–ApplicationListener。

适配器模式：将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。

​	可以看到处理器（宽泛的概念Controller，以及HttpRequestHandler，Servlet，等等）的类型不同，有多重实现方式，那么调用方式就不是确定的，如果需要直接调用Controller方法，需要调用的时候就得不断使用if else来进行判断是哪一种子类然后执行。这样违背了开闭原则。所以用适配器模式封装成HandlerAdapter对象，方便统一调用。

### SpringMVC工作原理

- 前端控制器DispatcherServlet接收用户的请求后，根据请求向处理器映射器HandlerMapping查询具体处理器
- 处理器映射器HandlerMapping返回对应的处理器链返回给dispatherServlet
- dispatcherServlet会将请求发送给具体的处理器Handler，并等待处理
- 处理器Handler处理完毕后，会返回逻辑视图名View和模型Model给前端控制器DispatcherServlet
- 前端控制器根据逻辑视图名向视图解析器View resolver解析具体的视图
- 最后视图负责根据模型数据渲染页面，并返回给客户端

参考文章：[自己写个Spring MVC](https://zhuanlan.zhihu.com/p/139751932) （源码级别）

### SpringMVC注解

- RestController：指定控制器
- RequestMapping，负责编写具体的url，指定post方法，并指定返回内容类型
- RequestBody：接收通过body传递过来的JSONObject数据参数
- ControllerAdvice和ExceptionHandler：负责controller的全局异常处理

### Spring事务相关

Spring事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，spring是无法提供事务功能的。Spring只提供统一事务管理接口，具体实现都是由各数据库自己实现，数据库事务的提交和回滚是通过binlog或者undo log实现的。Spring会在事务开始时，根据当前环境中设置的隔离级别，调整数据库隔离级别，由此保持一致。

（1）**Spring管理事务的方式**：

spring支持**编程式事务管理**和**声明式事务管理两种方式**：

+ 编程式事务管理：使用TransactionTemplate。
+ 声明式事务管理：建立在AOP之上的。其本质是通过AOP功能，对方法前后进行拦截，将事务处理的功能编织到拦截的方法中，也就是在目标方法开始之前启动一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务。可以基于配置文件或者注解实现。
+ 区别：
  + 声明式事务最大的优点就是不需要在业务逻辑代码中掺杂事务管理的代码，只需在配置文件中做相关的事务规则声明或通过@Transactional注解的方式，便可以将事务规则应用到业务逻辑中，减少业务代码的污染。
  + 唯一不足地方是，最细粒度只能作用到方法级别，无法做到像编程式事务那样可以作用到代码块级别。

（2）**Spring中的事务传播机制**：事务的传播机制指的是，如果事务方法互相调用，事务应该如何传播

1. required（required默认，常用）：支持使用当前事务，如果当前事务不存在，创建一个新事务。eg:方法B用REQUIRED修饰，方法A调用方法B，如果方法A当前没有事务，方法B就新建一个事务（若还有C则B和C在各自的事务中独立执行），如果方法A有事务，方法B就加入到这个事务中，当成一个事务。
2. SUPPORTS：supports支持使用当前事务，如果当前事务不存在，则不使用事务。
3. MANDATORY：mandatory强制，支持使用当前事务，如果当前事务不存在，则抛出Exception。
4. REQUIRES_NEW（常用）：requires_new创建一个新事务，如果当前事务存在，把当前事务挂起。eg:方法B用REQUIRES_NEW修饰，方法A调用方法B，不管方法A上有没有事务方法B都新建一个事务，在该事务执行。
5. NOT_SUPPORTED：not_supprted无事务执行，如果当前事务存在，把当前事务挂起。
6. NEVER：never无事务执行，如果当前有事务则抛出Exception。
7. NESTED：nested嵌套事务，如果当前事务存在，那么在嵌套的事务中执行。如果当前事务不存在，则表现跟REQUIRED一样。

（3）**Spring中的隔离级别（和数据库一样，多一个使用数据库默认）：**在transactional注解中设置isolation属性即可

+  ISOLATION_DEFAULT：这是个 PlatfromTransactionManager 默认的隔离级别，使用数据库默认的事务隔离级别。

+  ISOLATION_READ_UNCOMMITTED：读未提交，允许事务在执行过程中，读取其他事务未提交的数据。

+  ISOLATION_READ_COMMITTED：读已提交，允许事务在执行过程中，读取其他事务已经提交的数据。

+  ISOLATION_REPEATABLE_READ：可重复读，在同一个事务内，任意时刻的查询结果都是一致的。

+  ISOLATION_SERIALIZABLE：串行化，所有事务逐个依次执行。

### @Transactional和错误使用

| 属性名           | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| name             | 当在配置文件中有多个 TransactionManager , 可以用该属性指定选择哪个事务管理器。 |
| propagation      | 事务的传播行为，默认值为 REQUIRED。                          |
| isolation        | 事务的隔离度，默认值采用 DEFAULT。                           |
| timeout          | 事务的超时时间，默认值为-1。如果超过该时间限制但事务还没有完成，则自动回滚事务。 |
| read-only        | 指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。 |
| rollback-for     | 用于指定能够触发事务回滚的异常类型，如果有多个异常类型需要指定，各类型之间可以通过逗号分隔。 |
| no-rollback- for | 抛出 no-rollback-for 指定的异常类型，不回滚事务。            |

错误使用失效场景：

1. @Transactional 在private上：当标记在protected、private、package-visible方法上时，不会产生错误，但也不会表现出为它指定的事务配置。可以认为它作为一个普通的方法参与到一个public方法的事务中。
2. 同一个类中方法调用this引用，导致@Transactional失效：由于使用Spring AOP代理造成的，因为只有当事务方法被当前类以外的代码调用时，才会由Spring生成的代理对象来管理。
3. @Transactional 的事务传播方式配置错误。
4. @Transactional 注解属性 rollbackFor 设置错误：Spring默认抛出了未检查unchecked异常（继承自 RuntimeException 的异常）或者 Error才回滚事务；其他异常不会触发回滚事务。
5. 异常被 catch 捕获导致@Transactional失效。
6. 数据库引擎不支持事务。

### Spring循环依赖问题

循环依赖问题：其实就是循环引用，也就是两个或则两个以上的bean互相持有对方，最终形成闭环。比如A依赖于B，B依赖于C，C又依赖于A

循环依赖问题在Spring中主要有两种情况：

- （1）通过构造方法进行依赖注入时产生的循环依赖问题：进行类实例化的时候会报错，不能解决

  ```java
  @Service
  public class Student {
      @Autowired
      private Teacher teacher;
  
      public Student (Teacher teacher) {
          System.out.println("Student init1:" + teacher);
      }
  }
  @Service
  public class Teacher {
      @Autowired
      private Student student;
  
      public Teacher (Student student) {
          System.out.println("Teacher init1:" + student);
      }
  }
  ```

- （2）通过setter方法进行依赖注入且是在多例（原型）模式下产生的循环依赖问题：不能解决

- （3）通过setter方法进行依赖注入且是在单例模式下产生的循环依赖问题：能解决。

  ```java
  @Service
  public class Student {
      @Autowired
      private Teacher teacher;
  }
  @Service
  public class Teacher {
      @Autowired
      private Student student;
  }
  ```

Spring使用了三级缓存解决了循环依赖的问题。在populateBean()给属性赋值阶段里面Spring会解析你的属性，并且赋值，当发现，A对象里面依赖了B，此时又会走getBean方法，但这个时候，你去缓存中是可以拿的到的。因为我们在对createBeanInstance对象创建完成以后已经放入了缓存当中，所以创建B的时候发现依赖A，直接就从缓存中去拿，此时B创建完，A也创建完，一共执行了4次。至此Bean的创建完成，最后将创建好的Bean放入单例缓存池中。

### 三级缓存

1. 第一级缓存：单例缓存池singletonObjects。

2. 第二级缓存：早期提前暴露的对象缓存earlySingletonObjects。（属性还没有值对象也没有被初始化）

3. 第三级缓存：singletonFactories单例对象工厂缓存。

   ![img](https://pic1.zhimg.com/80/v2-1e7bd042df73e47bb951e70b298c96ca_720w.jpg?source=1940ef5c)

三级缓存详解：[根据 Spring 源码写一个带有三级缓存的 IOC](https://zhuanlan.zhihu.com/p/144627581)

### 为什么不用二级缓存？

 当某个对象依赖于其他两个对象时，使用二级缓存可能有问题

```java
@Service
public class TestService1 {
    @Autowired
    private TestService2 testService2;
    @Autowired
    private TestService3 testService3;
    public void test1() {
    }
}

@Service
public class TestService2 {
    @Autowired
    private TestService1 testService1;
    public void test2() {
    }
}

@Service
public class TestService3 {
    @Autowired
    private TestService1 testService1;
    public void test3() {
    }
}
```

TestService1创建实例和TestService1注入到TestService3都需要从第三级缓存中获取实例，而第三级缓存里保存的并非真正的实例对象，而是`ObjectFactory`对象。说白了，两次从三级缓存中获取都是`ObjectFactory`对象，而通过它创建的实例对象每次可能都不一样的。

为了解决这个问题，spring引入的第二级缓存。上面图1其实TestService1对象的实例已经被添加到第二级缓存中了，而在TestService1注入到TestService3时，只用从第二级缓存中获取该对象即可。

### BeanFactory和ApplicationContext的区别

1. BeanFactory是Spring里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能。
2. ApplicationContext应用上下文，继承BeanFactory接口，它是Spring的一各更高级的容器，提供了更多的有用的功能。如国际化，访问资源，载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，消息发送、响应机制，AOP等。
3. BeanFactory在启动的时候不会去实例化Bean，中有从容器中拿Bean的时候才会去实例化。ApplicationContext在启动的时候就把所有的Bean全部实例化了。它还可以为Bean配置lazy-init=true来让Bean延迟实例化

### Spring的后置处理器

1. BeanPostProcessor：Bean的后置处理器，主要在bean初始化前后工作。（before和after两个回调中间只处理了init-method）
2. InstantiationAwareBeanPostProcessor：继承于BeanPostProcessor，主要在实例化bean前后工作（TargetSource的AOP创建代理对象就是通过该接口实现）
3. BeanFactoryPostProcessor：Bean工厂的后置处理器，在bean定义(bean definitions)加载完成后，bean尚未初始化前执行。
4. BeanDefinitionRegistryPostProcessor：继承于BeanFactoryPostProcessor。其自定义的方法postProcessBeanDefinitionRegistry会在bean定义(bean definitions)将要加载，bean尚未初始化前真执行，即在BeanFactoryPostProcessor的postProcessBeanFactory方法前被调用。

https://zhuanlan.zhihu.com/p/139751932)

### 什么是SpringBoot？

Springboot简化了使用Spring的难度，使开发者能快速上手，具体表现在：

- 节省了繁重的配置
- 提供了各种starter启动器

### SpringBoot启动流程

1. 创建了一个Springpplication实例
   + 推断WebApplicationType，主要思想就是在当前的classpath下搜索特定的类
   + 搜索META-INF\spring.factories文件配置的ApplicationContextInitializer的实现类
   + 搜索META-INF\spring.factories文件配置的ApplicationListenerr的实现类
   + 推断MainApplication的Class
2. 执行run方法
   + 创建一个StopWatch并执行start方法，这个类主要记录任务的执行时间
   + 配置Headless属性，Headless模式是在缺少显示屏、键盘或者鼠标时候的系统配置
   + 在文件META-INF\spring.factories中获取SpringApplicationRunListener接口的实现类EventPublishingRunListener，主要发布SpringApplicationEvent（*创建所有 Spring 运行监听器并发布应用启动事件*）
   + 把输入参数转成DefaultApplicationArguments类
   + 创建Environment并设置比如环境信息，系统熟悉，输入参数和profile信息
   + 打印Banner信息
   + 创建Application的上下文，根据WebApplicationTyp来创建Context类，如果非web项目则创建AnnotationConfigApplicationContext，在构造方法中初始化AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner
   + 在文件META-INF\spring.factories中获取SpringBootExceptionReporter接口的实现类FailureAnalyzers（*实例化异常报告器*）
   + 准备application的上下文
   + 件刷新上下文（**后文会单独分析refresh方法**），在这里真正加载bean到容器中。如果是web容器，会在onRefresh方法中创建一个Server并启动。
3. 回到run方法，最后的逻辑就是发布启动完成的事件，并调用监听者的方法。

### Spring Boot核心注解

+ SpringbootApplicaition是Springboot的启动类注解，也是核心注解，它是由下面三个注解组成的：
  + ComponentScan：组件扫描，将组件注册到容器中
  + EnableAutoConfiguration：打开自动配置，根据类路径中jar包是否存在来决定是否开启某个默认配置，用exclude可以关闭某个默认配置
  + SpringBootConfiguration： 相当于Configuration，是一个配置类，会被ComponentScan注解扫描到
+ @Configuration：配置类
+ @ComponentScan：自动扫描包路径下的 @Component 注解进行注册 bean 实例到 context 中

### SpringBoot自动配置原理

- Springboot启动的时候会通过@EnableAutoConfiguration注解开启自动配置，并找到META-INF/spring.factories中的所有自动配置类，并对其进行加载。
- 自动配置类都是以AutoConfiguration结尾的，里面包含一个关键性注解EnableConfigurationProperties，这个注解可以把配置了ConfigurationProperties注解的类注入到容器中，这个类可以接收application.properties中配置的配置信息。

### Spring Boot starter是什么？

starter的作用简单来说有下面两个：

- 方便引入相关依赖
- 自动配置各模块需要的属性，这里的原理和第四个问题，自动配置原理那个问题是一样的



## Spring Cloud微服务（项目）

### 什么是微服务

微服务架构就是将单一程序开发成一个微服务，每个微服务运行在自己的进程中，并使用**轻量级的机制通信**，通常是HTTP RESTFUL API。这些服务围绕业务能力来划分，并通过自动化部署机制来独立部署。这些服务可以使用不同的编程语言，不同数据库，以保证最低限度的集中式管理。 

总结起来微服务就是将一个单体架构的应用按业务划分为一个个的独立运行的程序即服务，它们之间通过HTTP协议进行通信（也可以采用消息队列来通信，如RoocketMQ，Kafaka等），可以采用不同的编程语言，使用不同的存储技术，自动化部署（如Jenkins）减少人为控制，降低出错概率。服务数量越多，管理起来越复杂，因此采用集中化管理。例如Eureka，Zookeeper等都是比较常见的服务集中化管理框架。

### Nacos底层原理

<img src="https://img-blog.csdnimg.cn/20200816093158354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvbGRfX19wbGF5,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />

服务注册中心：

- 服务实例在启动时注册到服务注册表，并在关闭时注销
- 服务消费者查询服务注册表，获得可用实例
- 服务注册中心需要调用服务实例的健康检查API来验证它是否能够处理请求

### Nacos心跳机制

从上述代码看,所谓心跳机制就是客户端通过schedule定时向服务端发送一个数据包 ,然后启动-个线程不断检测服务端的回应,如果在设定时间内没有收到服务端的回应,则认为服务器出现了故障。Nacos服务端会根据客户端的心跳包不断更新服务的状态。

### Feign底层原理

Feign是一个http请求调用的轻量级框架，可以以Java接口注解的方式调用Http请求。Spring Cloud引入 Feign并且集成了Ribbon实现客户端负载均衡调用。具体请求过程如下：

+ 主程序入口添加了@EnableFeignClients注解开启对FeignClient扫描加载处理。根据Feign Client的开发规范，定义接口并加@FeignClientd注解。

+ 当程序启动时，会进行包扫描，扫描所有@FeignClients的注解的类，并且将这些信息注入Spring IOC容器中，**当定义的的Feign接口中的方法被调用时，通过JDK的动态代理方式，来生成具体的RequestTemplate.**

+ 当生成代理时，Feign会为每个接口方法创建一个RequestTemplate。当生成代理时，Feign会为每个接口方法创建一个RequestTemplate对象，该对象封装了HTTP请求需要的全部信息，如请求参数名，请求方法等信息都是在这个过程中确定的。

+ 然后RequestTemplate生成Request,然后把Request交给Client去处理，这里指的是Client可以是JDK原生的URLConnection,Apache的HttpClient,也可以是OKhttp，最后Client被封装到LoadBalanceClient类，这个类结合Ribbon负载均衡发起服务之间的调用。

<img src="D:\9找工作\img\20180925130831141.png" alt="20180925130831141" style="zoom:60%;" />



### OAuth2.0协议

OAuth 代表开放授权协议。这允许通过在 HTTP 服务上启用客户端应用程序（例如第三方提供商 Facebook，GitHub 等）来访问资源所有者的资源。因此，您可以在不使用其凭据的情况下与另一个站点共享存储在一个站点上的资源。

![1096103-20170824142737402-1297004164](D:\9找工作\img\1096103-20170824142737402-1297004164.png)

### 单点登录

在任何一个微服务模块登录之后，其他模块都不需要登录

+ 三种实现机制：

  + session广播机制实现：session复制
  + 使用cookie+redies实现
    + 在项目的任何一个地方登录，登录之后数据放到redis和cookie中，redis存放（用户id，用户数据），cookie存放redis中的key，也就是用户id
    + 访问项目中的其他模块，发请求带着cookie进行发送，通过cookie获得用户id，再到redis中获取用户数据
  + 使用token实现
    + 在某个服务进行登录后，按照某个规则（JWT）生成token字符串，保存用户的信息，并将字符串返回
    + 可以通过cookie或者url进行返回给用户
    + 再次访问其他模块，根据cookie或者url中的token字符串，获得用户信息，如果获取到了就登录。

### JWT

WT生成字符串包含三部分：xxxx.yyyy.zzzzz

+ 头信息

+ 有效载荷，包含主体信息（用户信息）

+ Hash签名，防伪标志

<img src="D:\9找工作\img\v2-2d4a2985706ff9610ad1466b66ba09ad_r.jpg" alt="v2-2d4a2985706ff9610ad1466b66ba09ad_r" style="zoom:50%;" />

### 项目中支付流程

+ 免费课程：不需要支付，直接播放。课程详情页面是立即观看
+ 收费课程：需要支付后才能观看
  + 点击进入详情，变为立即购买
  + 立即购买：生成订单，然后支付
  + 生成支付二维码
  + 支付后，回到课程详情，变为立即观看

### Nginx相关

#### 什么是Nginx

Nginx ，是一个 Web 服务器和反向代理服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。
Nginx 的主要功能如下：

+ 作为 http server (代替 Apache ，对 PHP 需要 FastCGI 处理器支持)
+ FastCGI：Nginx 本身不支持 PHP 等语言，但是它可以通过 FastCGI 来将请求扔给某些语言或框架处理。
+ 反向代理服务器：反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和 Web 服务器之间的中间层。这对于安全方面来说是很好的，特别是当我们使用 Web 托管服务时。
+ 实现负载均衡
+ 虚拟主机

优点：跨平台、非阻塞高并发连接、内存消耗小

#### 反向代理和正向代理

+ 正向代理：类似一个跳板机，代理访问外部资源。比如国内访问谷歌，直接访问访问不到，我们可以通过一个正向代理服务器，请求发到代理服，代理服务器能够访问谷歌，这样由代理去谷歌取到返回数据，再返回给我们，这样我们就能访问谷歌了。
  + 访问原来无法访问的资源，如google
  + 可以做缓存，加速访问资源
  + 对客户端访问授权，上网进行认证

+ 反向代理：以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器
  + 保证内网的安全，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网
  + 负载均衡，通过反向代理服务器来优化网站的负载

#### Nginx常用命令

+ 启动 nginx 。
+ 停止 nginx -s stop 或 nginx -s quit 。
+ 重载配置 ./sbin/nginx -s reload(平滑重启) 或 service nginx reload 。
+ 重载指定配置文件 .nginx -c /usr/local/nginx/conf/nginx.conf 。
+ 查看 nginx 版本 nginx -v 。
+ 检查配置文件是否正确 nginx -t 。
+ 显示帮助信息 nginx -h 。

#### Nginx如何处理HTTP请求

+ Nginx 在启动时，会解析配置文件，得到监听的端口与 IP 地址，然后在 Nginx 的 Master 进程里面先初始化好这个监控的Socket(创建 S ocket，设置 addr、reuse 等选项，绑定到指定的 ip 地址端口，再 listen 监听)。

+ 然后，再 fork(一个现有进程可以调用 fork 函数创建一个新进程。由 fork 创建的新进程被称为子进程 )出多个子进程出来（**多进程**）。

+ 之后，子进程会竞争 accept 新的连接（**异步非阻塞的方式**）。此时，客户端就可以向 nginx 发起连接了。当客户端与nginx进行三次握手，与 nginx 建立好一个连接后。此时，某一个子进程会 accept 成功，得到这个建立好的连接的 Socket ，然后创建 nginx 对连接的封装，即 ngx_connection_t 结构体。

+ 接着，设置读写事件处理函数，并添加读写事件来与客户端进行数据的交换。
+ 最后，Nginx 或客户端来主动关掉连接，到此，一个连接就寿终正寝了。

#### Nginx如何实现高并发？

异步，非阻塞，使用了epoll 和大量的底层代码优化。

每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到什么程度呢?处理到可能发生阻塞的地方，比如向上游(后端)服务器转发request，并等待请求返回。那么，这个处理的worker很聪明，他会在发送完请求后，注册一个事件：“如果upstream返回了，告诉我一声，我再接着干”。于是他就休息去了。此时，如果再有request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。

#### Nginx为什么不用多线程？

采用单线程来异步非阻塞处理请求（管理员可以配置 Nginx 主进程的工作进程的数量）(epoll)，不会为每个请求分配 cpu 和内存资源，节省了大量资源，同时也减少了大量的 CPU 的上下文切换。所以才使得 Nginx 支持更高的并发。（Redis同理）

#### Nginx负载均衡策略

+ 轮询：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。
+ IP哈希：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 共享的问题。当然，实际场景下，一般不考虑使用 ip_hash 解决 session 共享。
+ 最少连接：下一个请求将被分派到活动连接数量最少的服务器

#### Nginx静态资源压缩

开启nginx gzip压缩后，网页、css、js等静态资源的大小会大大的减少，从而可以节约大量的带宽，提高传输效率，给用户快的体验。虽然会消耗cpu资源，但是为了给用户更好的体验是值得的。

#### Nginx常用优化策略

+ 调整worker_processes：即nginx生成的worker进程数量，和CPU核心数一样。 grep processor / proc / cpuinfo | wc -l 
+ 优化worker_connections：每秒可以服务的客户端数， 客户端数/秒=工作进程*工作者连接数，应将工作者连接设置为核心一次可以运行的允许的进程数1024。
+ 启动Gzip压缩静态资源：压缩文件大小，减少了客户端http的传输带宽，因此提高了页面加载速度
+ 为静态文件启用缓存：为静态文件启用缓存，以减少带宽并提高性能
+ Timeouts
+ 禁用access_logs：访问日志记录，它记录每个nginx请求，因此消耗了大量CPU资源，从而降低了nginx性能。
  + 完全禁用：access_log off
  + 启用访问日志缓冲：access_log /var/log/nginx/access.log主缓冲区= 16k

### Mybatis和Mybatis-plus

#### 什么是Mybatis

（1）Mybatis是一个半ORM（对象关系映射）框架，它内部封装了JDBC，加载驱动、创建连接、创建statement等繁杂的过程，开发者开发时只需要关注如何编写SQL语句，可以严格控制sql执行性能，灵活度高。

（2）作为一个半ORM框架，MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。

（3）通过xml 文件或注解的方式将要执行的各种 statement 配置起来，并通过java对象和 statement中sql的动态参数进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射为java对象并返回。（从执行sql到返回result的过程）。

（4）由于MyBatis专注于SQL本身，灵活度高，所以比较适合对性能的要求很高，或者需求变化较多的项目，如互联网项目。

#### MybatisPlus和Mybatis有什么区别？

MyBatis-plus是一款MyBatis的增强工具，在MyBatis 的基础上只做增强不做改变。主要功能如下：

+ 依赖少：仅仅依赖 Mybatis 以及 Mybatis-Spring 。
+ 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 。

+ 通用CRUD操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 。
+ 多种主键策略：支持多达4种主键策略（内含分布式唯一ID生成器），可自由配置，完美解决主键问题 。
+ 内置分页插件：基于 Mybatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通List查询。
+ 默认将实体类的类名查找数据库中的表，使用@TableName(value="table1")注解指定表名，@TableId指定表主键，若字段与表中字段名保持一致可不加注解。

#### Mybatis优缺点

优点：

+ 基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在XML里，解除sql与程序代码的耦合，便于统一管理；提供XML标签，支持编写动态SQL语句，并可重用。
+ 与JDBC相比，减少了50%以上的代码量，消除了JDBC大量冗余的代码，不需要手动开关连接；
+ 提供映射标签，支持对象与数据库的ORM字段关系映射；提供对象关系映射标签，支持对象关系组件维护。

缺点：

+ SQL语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写SQL语句的功底有一定要求。
+  SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

#### #{}和${}的区别是什么？

${}是字符串替换，#{}是预处理；

Mybatis在处\${}时，就是把${}直接替换成变量的值。而Mybatis在处理#{}时，会对sql语句进行预处理，将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值；

使用#{}可以有效的防止SQL注入，提高系统安全性。

#### Maper接口原理(mapper.xml)

Mapper 接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，根据类的全限定名+方法名，唯一定位到一个MapperStatement并调用执行器执行所代表的sql，然后将sql执行结果返回。Mapper接口里的方法，是不能重载的，因为是使用 全限名+方法名 的保存和寻找策略。

>Dao接口即Mapper接口。接口的全限名，就是映射文件中的namespace的值；接口的方法名，就是映射文件中Mapper的Statement的id值；接口方法内的参数，就是传递给sql的参数。
>
>当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MapperStatement。在Mybatis中，每一个SQL标签，比如、、、标签，都会被解析为一个MapperStatement对象。
>
>举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面 id 为 findStudentById 的 MapperStatement。

#### maper.xml映射文件id是否可以重复？

不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复；

原因就是namespace+id是作为Map的key使用的，如果没有namespace，就剩下id，那么，id重复会导致数据互相覆盖。有了namespace，自然id就可以重复，namespace不同，namespace+id自然也就不同。

#### Mybatis一级缓存和二级缓存

Mybatis顺序执行两次相同的sql，第二次不会去查询数据库，而是直接使用第一次查询的缓存。

+ 一级缓存: mybatis的一级缓存是SqlSession级别的缓存，在操作数据库的时候需要先创建SqlSession会话对象，在对象中有一个HashMap用于存储缓存数据，此HashMap是当前会话对象私有的，别的SqlSession会话对象无法访问。**当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认打开一级缓存**。	
  + 第一次执行select完毕会将查到的数据写入SqlSession内的HashMap中缓存起来
  + 第二次执行select会从缓存中查数据，如果select相同切传参数一样，那么就能从缓存中返回数据，不用去数据库了，从而提高了效率

+ 二级缓存：二级缓存是mapper级别的缓存，也就是同一个namespace的mappe.xml，当多个SqlSession使用同一个Mapper操作数据库的时候，得到的数据会缓存在同一个二级缓存区域二级缓存默认是没有开启的。需要在setting全局参数中配置开启二级缓存
  + 当一个sqlseesion执行了一次select后，在关闭此session的时候，会将查询结果缓存到二级缓存
  + 当另一个sqlsession执行select时，首先会在他自己的一级缓存中找，如果没找到，就回去二级缓存中找，找到了就返回，就不用去数据库了，从而减少了数据库压力提高了性能　

+ 对于缓存数据更新机制，当某一个作用域(一级缓存 Session/二级缓存Namespaces)的进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear 掉并重新更新，如果开启了二级缓存，则只根据配置判断是否刷新。

#### Mybatis如何将sql执行结果封装为对象？

第一种是使用标签，逐一定义数据库列名和对象属性名之间的映射关系。

第二种是使用sql列的别名功能，将列的别名书写为对象属性名。

有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。

#### Mybatis动态sql

Mybatis动态sql可以在Xml映射文件内，以标签的形式编写动态sql，执行原理是根据表达式的值 完成逻辑判断 并动态拼接sql的功能。

Mybatis提供了9种动态sql标签：trim | where | set | foreach | if | choose | when | otherwise | bind。


## RPC和Dubbo

### 什么是Dubbo

Dubbo是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案。主要功能包括：面向接口代理的高性能RPC调用、智能负载均衡、支持多种服务注册中心。

### 什么是RPC远程服务调用

在服务中像调用本地接口一样调用远程接口的方式叫RPC。

具体包括：Feign（HTTP协议）、Dubbo（TCP协议）

### RPC用到的技术

+ 动态代理：服务调用者用的服务实际是远程服务的本地代理。说白了就是通过动态代理来实现。（Feign类似）
+ 序列化：远程通信，需要将对象转化成二进制流进行传输。不同的RPC框架应用的场景不同，在序列化上也会采取不同的技术
+ NIO：同步非阻塞IO
+ 服务注册中心

### Dubbo和Feign的区别

+ 协议：Dubbo利用TCP协议传输，单一异步长连接，适合数据量小高并发。Feign基于Http协议传输，短连接，不适合高并发的访问。
+ 负载均衡：Dubbo可以精确到某个服务的某个方法。Feign是Client级别。
+ 容错机制：Dubbo支持多种容错机制。Feign利用熔断机制来实现容错。

### Dubbo的容错机制

1. 失败自动切换（FailOver），当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数
2. 快速失败（FailFast），只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。
3. 失败安全（FailSafe），出现异常时，直接忽略。通常用于写入审计日志等操作。
4. 失败自动恢复（FailBack），后台记录失败请求，定时重发。通常用于消息通知操作。
5. 并行调用多个服务器（Forking），只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。
6. 广播调用所有提供者（Brodecast），逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息

### Dubbo注册中心挂了还可以继续通信么

可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信。

### Dubbo提供的线程池

1. fixed：固定大小线程池，启动时建立线程，不关闭，一直持有。 
2. cached：缓存线程池，空闲一分钟自动删除，需要时重建。 
3. limited：可伸缩线程池，但池中的线程数只会增长不会收缩。(为避免收缩时突然来了大流量引起的性能问题)。

### Dubbo框架设计结构

1. 服务接口层：该层是与实际业务逻辑相关的，根据服务提供方和服务消费方的业务设计对应的接口和实现。
2. 配置层：对外配置接口，以ServiceConfig和ReferenceConfig为中心，可以直接new配置类，也可以通过spring解析配置生成配置类。
3. 服务代理层：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory。
4. 服务注册层：封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory、Registry和RegistryService。可能没有服务注册中心，此时服务提供方直接暴露服务。
5. 集群层：封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster、Directory、Router和LoadBalance。将多个服务提供方组合为一个服务提供方，实现对服务消费方来透明，只需要与一个服务提供方进行交互。
6. 监控层：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory、Monitor和MonitorService。
7. 远程调用层：封将RPC调用，以Invocation和Result为中心，扩展接口为Protocol、Invoker和Exporter。Protocol是服务域，它是Invoker暴露和引用的主功能入口，它负责Invoker的生命周期管理。Invoker是实体域，它是Dubbo的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起invoke调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。
8. 信息交换层：封装请求响应模式，同步转异步，以Request和Response为中心，扩展接口为Exchanger、ExchangeChannel、ExchangeClient和ExchangeServer。
9. 网络传输层：抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel、Transporter、Client、Server和Codec。
10. 数据序列化层：可复用的一些工具，扩展接口为Serialization、 ObjectInput、ObjectOutput和ThreadPool。

## 消息队列

### 消息队列应用场景及优缺点

消息队列是一种**先进先出**的数据结构，主要包含这三个应用场景：

+ 应用解耦：如用户下单后，订单系统需要通知库存系统，假如库存系统无法访问，则订单减库存将失败，从而导致订单失败。订单系统与库存系统耦合，这个时候如果使用消息队列，可以返回给用户成功，先把消息持久化，等库存系统恢复后，就可以正常消费减去库存了。

+ 削峰/限流：秒杀活动，一般会因为流量过大，从而导致流量暴增，应用挂掉，这个时候加上消息队列，服务器接收到用户的请求后，首先写入消息队列，假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。

+ 异步处理：将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快相应速度。比如，客户端负责将日志采集，然后定时写入消息队列，消息队列再统一将日志数据存储和转发。

缺点：

- 系统可用性降低：你想呀，本来其他系统只要运行好好的，那你的系统就是正常的。现在你非要加入个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性会降低
- 系统复杂性增加：加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，刺痛复杂性增大。

### RocketMQ部署架构

<img src="D:\9找工作\img\mmbizpngMnVGSgCV6PJpMicR98FicHYo1x8r9QLy8H0WlTK06tPGNJLVlxkJEa1mGia3uFWMyG1CHTMDJDCGqb5Ft4YEMbsDg640.png" alt="mmbizpngMnVGSgCV6PJpMicR98FicHYo1x8r9QLy8H0WlTK06tPGNJLVlxkJEa1mGia3uFWMyG1CHTMDJDCGqb5Ft4YEMbsDg640" style="zoom:70%;" />

+ Name Server集群：担任路由消息的提供者。生产者或消费者能够通过NameServer查找各Topic相应的Broker IP列表分别进行发送消息和消费消息。nameServer由多个无状态的节点构成，节点之间**无任何信息同步**。broker会定期向NameServer以发送心跳包的方式，轮询向所有NameServer注册以下元数据信息：
  + broker的基本信息（ip port等）
  + 主题topic的地址信息
  + broker集群信息
  + 存活的broker信息
  + filter 过滤器
  + 也就是说，每个NameServer注册的信息都是一样的，而且是当前系统中的所有broker的元数据信息

+ Producer集群：生产消息，一般由业务系统负责生产消息。一个消息生产者会把业务应用系统里产生的消息发送到broker服务器。RocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。同步和异步方式均需要Broker返回确认信息，单向发送不需要。

+ Consumer集群：负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序。从用户应用的角度而言提供了两种消费形式：拉取式push消费、推动式poll消费

+ Broker集群：消息中转角色，负责存储消息、转发消息。在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备

### RocketMQ topic逻辑存储模型

<img src="D:\9找工作\img\6302559-5693e4bec15216b5.webp" alt="6302559-5693e4bec15216b5" style="zoom:80%;" />

Topic是逻辑概念，对于RocketMQ，一个Topic可以分布在各个Broker上，把一个Topic分布在一个Broker上的子集定义为一个Topic分片，其实就是在某一broke上一个topic的部分数据

Queue 存在的意义：每个Topic分片等分的Queue的数量可以不同，由用户在创建Topic时指定, **是消费负载均衡过程中资源分配的基本单元.**

### RocketMQ部署类型（集群）

+ 单Master：单机模式, 即只有一个Broker, 如果Broker宕机了, 会导致RocketMQ服务不可用, 不推荐使用
+ 多Master：组成一个集群, 集群每个节点都是Master节点, 配置简单, 性能也是最高, 某节点宕机重启不会影响RocketMQ服务。缺点是当某个master宕机了，未被消费的信息在恢复前不能被消费。
+ 多Master多Slave，异步复制模式：每个Master配置一个Slave, 多对Master-Slave, Master与Slave消息采用**异步复制方式** 主从消息一致只会有毫秒级的延迟
  + 优点：多Master模式（无slave）下节点宕机后在恢复前不可订阅的问题。在Master宕机后, 消费者还可以从Slave节点进行消费。采用异步模式复制，提升了一定的吞吐量。
  + 缺点：如果Master宕机, 磁盘损坏的情况下, 如果没有及时将消息复制到Slave, 会导致有少量消息丢失
+ 多Master多Slave，同步双写模式：与多Master多Slave模式，异步复制方式基本一致，**唯一不同的是消息复制采用同步方式，只有master和slave都写成功以后，才会向客户端返回成功**
  + 优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高
  + 缺点：降低消息写入的效率，并影响系统的吞吐量

### RocketMQ部署过程

1. 配置rockermq安装目录下的配置文件，如主从节点、复制模式
2. 修改JVM参数，默认需要的JAVA_OPT太多可能会导致失败
3. 分别启动nameserver、broker节点
4. 查看日志

### RocketMQ工作流程

**1）首先启动NameServer**。NameServer启动后监听端口，等待Broker、Producer以及Consumer连上来

**2）启动Broker**。启动之后，会跟所有的NameServer建立并保持一个长连接，定时发送心跳包。心跳包中包含当前Broker信息(ip、port等)、Topic信息以及Borker与Topic的映射关系

**3）创建Topic**。创建时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic

**4）Producer发送消息**。启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic所在的Broker；然后从队列列表中轮询选择一个队列，与队列所在的Broker建立长连接，进行消息的发送

**5）Consumer消费消息**。跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，进行消息的消费

### RocketMQ高可用

+ 集群化部署NameServer。Broker集群会将所有的broker基本信息、topic信息以及两者之间的映射关系，轮询存储在每个NameServer中（也就是说每个NameServer存储的信息完全一样）。因此，NameServer集群化，不会因为其中的一两台服务器挂掉，而影响整个架构的消息发送与接收；
+ 集群化部署多broker。producer发送消息到broker的master，若当前的master挂掉，则会自动切换到其他的master
+ 设置同步复制。即使master节点挂了，slave上也有当前master的所有备份数据，那么不仅保证消费者消费到的消息是完整的，并且当master节点恢复之后，也容易恢复消息数据。在master的配置文件中直接配置brokerRole：SYNC_MASTER即可

### RocketMQ如何实现负载均衡？

1）producer发送消息的负载均衡：默认会**轮询**向Topic的所有queue发送消息，以达到消息平均落到不同的queue上；而由于queue可以落在不同的broker上，就可以发到不同broker上（当然也可以指定发送到某个特定的queue上）

2）consumer订阅消息的负载均衡：假设有5个队列，两个消费者，则第一个消费者消费3个队列，第二个则消费2个队列，以达到平均消费的效果。而需要注意的是，当consumer的数量大于队列的数量的话，根据rocketMq的机制，多出来的队列不会去消费数据，因此建议consumer的数量小于或者等于queue的数量，避免不必要的浪费

### RocketMQ存储机制（持久化）

+ 顺序写：直接追加数据到末尾。实际上，磁盘顺序写的性能极高，在磁盘个数一定，转数一定的情况下，基本和内存速度一致。避免了寻址过程
+ 零拷贝（读）：直接由内核缓冲区**Read Buffer**将数据复制到**网卡**，省去第二步和第三步的复制。零拷贝技术采用了MappedByteBuffer内存映射技术，采用这种技术有一些限制，其中有一条就是传输的文件不能超过2G，这也就是为什么RocketMq的存储消息的文件CommitLog的大小规定为1G的原因
  + 传统方式：1、将磁盘文件，读取到操作系统内核缓冲区**Read Buffer**  2、将内核缓冲区的数据，复制到应用程序缓冲区**Application Buffer**  3、将应用程序缓冲区**Application Buffer**中的数据，复制到socket网络发送缓冲区   4、将**Socket buffer**的数据，复制到**网卡**，由网卡进行网络传输

### RocketMQ存储结构

<img src="D:\9找工作\img\mmbizpngMnVGSgCV6PLEzXJc3dJXW4KoOEotpmgkbJAtb3fgohPUQrxrkUDrneStlibhRTR1xedPnrgOLCqCiafIRx0vUb3g640.png" alt="mmbizpngMnVGSgCV6PLEzXJc3dJXW4KoOEotpmgkbJAtb3fgohPUQrxrkUDrneStlibhRTR1xedPnrgOLCqCiafIRx0vUb3g640" style="zoom:80%;" />

+ CommitLog：存储所有的消息元数据，包括Topic、QueueId以及message。每个commitlog大小为1g。
+ ConsumerQueue：消费逻辑队列，存储消息在CommitLog的offset。
+ IndexFile：存储消息的key和时间戳等信息，使得RocketMq可以采用key和时间区间来查询消息

rocketMq将消息均存储在CommitLog中，并分别提供了CosumerQueue和IndexFile两个索引，来快速检索消息

### RocketMQ中消息被消费后会立即删除吗？

不会，每条消息都会持久化到CommitLog中，每个Consumer连接到Broker后会维持消费进度信息，当有消息消费后只是当前Consumer的消费进度（CommitLog的offset）更新了。

追问：那么**消息会堆积**吗？什么时候清理过期消息？

4.6版本默认48小时后会删除不再使用的CommitLog文件

- 检查这个文件最后访问时间
- 判断是否大于过期时间
- 指定时间删除，默认凌晨4点

### RocketMQ消息去重

消息重复问题：当consumer消费完消息后，因为网络问题未及时发送ack到broker,broker就不会删掉当前已经消费过的消息，那么，该消息将会被重复投递给消费者去消费。

RocketMq本身并不保证消息不重复，这样肯定会因为每次的判断，导致性能打折扣，所以它将去重操作直接放在了消费端：

1）消费端处理消息的业务逻辑保持**幂等性**。那么不管来多少条重复消息，可以实现处理的结果都一样

2）还可以建立一张日志表，使用消息主键作为表的主键，在处理消息前，先insert表，再做消息处理。这样可以避免消息重复消费

### RocketMQ消息不丢失

分别从Producer发送机制、Broker的持久化机制，以及消费者的offSet机制来最大程度保证消息不易丢失

从Producer的视角来看：如果消息未能正确的存储在MQ中，或者消费者未能正确的消费到这条消息，都是消息丢失。
从Broker的视角来看：如果消息已经存在Broker里面了，如何保证不会丢失呢（宕机、磁盘崩溃）
从Consumer的视角来看：如果消息已经完成持久化了，但是Consumer取了，但是未消费成功且没有反馈，就是消息丢失

+ 从Producer分析：如何确保消息正确的发送到了Broker?
  + 默认情况下，可以通过同步的方式阻塞式的发送，check SendStatus，状态是OK，表示消息一定成功的投递到了Broker，状态超时或者失败，则会触发默认的2次重试。此方法的发送结果，可能Broker存储成功了，也可能没成功
  + 采取事务消息的投递方式，并不能保证消息100%投递成功到了Broker，但是如果消息发送Ack失败的话，此消息会存储在CommitLog当中，但是对ConsumerQueue是不可见的。可以在日志中查看到这条异常的消息，严格意义上来讲，也并没有完全丢失
  + RocketMQ支持 日志的索引，如果一条消息发送之后超时，也可以通过查询日志的API，来check是否在Broker存储成功

+ 从Broker分析：如果确保接收到的消息不会丢失?
  + 消息支持持久化到Commitlog里面，即使宕机后重启，未消费的消息也是可以加载出来的
  + Broker自身支持同步刷盘、异步刷盘的策略，可以保证接收到的消息一定存储在本地的内存中
  + Broker集群支持 1主N从的策略，支持同步复制和异步复制的方式，同步复制可以保证即使Master 磁盘崩溃，消息仍然不会丢失
+ 从Cunmser分析：如何确保拉取到的消息被成功消费？
  + 消费者可以根据自身的策略批量Pull消息
  + Consumer自身维护一个持久化的offset（对应MessageQueue里面的min offset），标记已经成功消费或者已经成功发回到broker的消息下标
  + 如果Consumer消费失败，那么它会把这个消息发回给Broker，发回成功后，再更新自己的offset
  + 如果Consumer消费失败，发回给broker时，broker挂掉了，那么Consumer会定时重试这个操作
  + 如果Consumer和broker一起挂了，消息也不会丢失，因为consumer 里面的offset是定时持久化的，重启之后，继续拉取offset之前的消息到本地

### RocketMQ如何保证消息顺序？

首先多个queue只能保证单个queue里的顺序，queue是典型的FIFO，天然顺序。多个queue同时消费是无法绝对保证消息的有序性的。所以总结如下：

同一topic，同一个QUEUE，发消息的时候一个线程去发送消息，消费的时候 一个线程去消费一个queue里的消息。

**追问：怎么保证消息发到同一个queue？**

Rocket MQ给我们提供了MessageQueueSelector接口，可以自己重写里面的接口，实现自己的算法，举个最简单的例子：判断`i % 2 == 0`，那就都放到queue1里，否则放到queue2里。

### RocketMQ是push还是poll？

RocketMQ没有真正意义的push，都是pull，虽然有push类，但实际底层实现采用的是**长轮询机制**，即拉取方式

> broker端属性 longPollingEnable 标记是否开启长轮询。默认开启



### Kafka的文件存储机制

Kafka中消息是以topic进行分类的，生产者通过topic向Kafka broker发送消息，消费者通过topic读取数据。然而topic在物理层面又能以partition为分组，一个topic可以分成若干个partition。partition还可以细分为segment，一个partition物理上由多个segment组成，segment文件由两部分组成，分别为“.index”文件和“.log”文件，分别表示为segment索引文件和数据文件。这两个文件的命令规则为：partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。

### Kafka 如何保证可靠性

如果我们要往 Kafka 对应的主题发送消息，我们需要通过 Producer 完成。前面我们讲过 Kafka 主题对应了多个分区，每个分区下面又对应了多个副本；为了让用户设置数据可靠性， Kafka 在 Producer 里面提供了消息确认机制。也就是说我们可以通过配置来决定消息发送到对应分区的几个副本才算消息发送成功。可以在定义 Producer 时通过 acks 参数指定。这个参数支持以下三种值：

* acks = 0：意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入 Kafka 。在这种情况下还是有可能发生错误，比如发送的对象无能被序列化或者网卡发生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。在 acks=0 模式下的运行速度是非常快的（这就是为什么很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率，不过如果选择了这种模式， 一定会丢失一些消息。
* acks = 1：意味若 Leader 在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。在这个模式下，如果发生正常的 Leader 选举，生产者会在选举时收到一个 LeaderNotAvailableException 异常，如果生产者能恰当地处理这个错误，它会重试发送悄息，最终消息会安全到达新的 Leader 那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入 Leader，但在消息被复制到 follower 副本之前 Leader发生崩溃。
* acks = all（这个和 request.required.acks = -1 含义一样）：意味着 Leader 在返回确认或错误响应之前，会等待所有同步副本都收到悄息。如果和min.insync.replicas 参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到悄息，生产者会一直重试直到消息被成功提交。不过这也是最慢的做法，因为生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。

### Kafka消息是采用Pull模式，还是Push模式

Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。最终Kafka还是选取了传统的pull模式。Pull模式的另外一个好处是consumer可以自主决定是否批量的从broker拉取数据。Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到t达。为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达。

### Kafka是如何实现高吞吐率的

1. 顺序读写：kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能
2. 零拷贝：跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”
3. 文件分段：kafka的队列topic被分为了多个区partition，每个partition又分为多个段segment，所以一个队列中的消息实际上是保存在N多个片段文件中
4. 批量发送：Kafka允许进行批量发送消息，先将消息缓存在内存中，然后一次请求批量发送出去
5. 数据压缩：Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩

### Kafka判断一个节点还活着的两个条件

1. 节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接
2. 如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久



## 操作系统

### 什么是内核态和用户态？

为了避免操作系统和关键数据被用户程序破坏，将处理器的执行状态分为内核态和用户态。

内核态是操作系统管理程序执行时所处的状态，能够执行包含特权指令在内的一切指令，能够访问系统内所有的存储空间。

用户态是用户程序执行时处理器所处的状态，不能执行特权指令，只能访问用户地址空间。

用户程序运行在用户态,操作系统内核运行在内核态。

### 如何实现内核态和用户态的切换？

处理器从用户态切换到内核态的方法有三种：系统调用、异常和外部中断。

1. 系统调用是操作系统的最小功能单位，是操作系统提供的用户接口，系统调用本身是一种软中断。
2. 异常，也叫做内中断，是由错误引起的，如文件损坏、缺页故障等。
3. 外部中断，是通过两根信号线来通知处理器外设的状态变化，是硬中断。

### 进程、线程和协程的区别

1. 进程是操作系统资源分配的最小单位，线程是CPU任务调度的最小单位。一个进程可以包含多个线程，所以进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同。
2. 协程（Coroutines）是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程。协程不是被操作系统内核所管理的，而是完全由程序所控制，也就是在用户态执行。这样带来的好处是性能大幅度的提升，因为不会像线程切换那样消耗资源。协程的切换内容是硬件上下文，切换内存保存在用户自己的变量（用户栈或堆）中。协程的切换过程只有用户态，即没有陷入内核态，因此切换效率高。
3. 不同进程间数据很难共享，同一进程下不同线程间数据很易共享。
4. 每个进程都有独立的代码和数据空间，进程要比线程消耗更多的计算机资源。线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。
5. 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉。
6. 系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源。
7. 使用场景
   + 进程：多进程适合在**CPU 密集**型操作(cpu 操作指令比较多，计算密集型，如科学计算，位数多的浮点运算)
   + 线程：多线程适合在**IO 密集**型操作(读写数据操作较多的，比如爬虫)
   + 协程：

### 多线程和单线程

线程不是越多越好，假如你的业务逻辑全部是计算型的（CPU密集型）,不涉及到IO，并且只有一个核心。那肯定一个线程最好，多一个线程就多一点线程切换的计算，CPU不能完完全全的把计算能力放在业务计算上面，线程越多就会造成CPU利用率（用在业务计算的时间/总的时间）下降。但是在WEB场景下，业务并不是CPU密集型任务，而是IO密集型的任务，一个线程是不合适，如果一个线程在等待数据时，把CPU的计算能力交给其他线程，这样也能充分的利用CPU资源。但是线程数量也要有个限度，一般线程数有一个公式：最佳启动线程数=[任务执行时间/(任务执行时间-IO等待时间)]*CPU内核数超过这个数量，CPU要进行多余的线程切换从而浪费计算能力，低于这个数量，CPU要进行IO等待从而造成计算能力不饱和。总之就是要尽可能的榨取CPU的计算能力。如果你的CPU处于饱和状态，并且没有多余的线程切换浪费，那么此时就是你服务的完美状态，如果再加大并发量，势必会造成性能上的下降。

### 进程的组成部分及线程状态

进程由进程控制块（PCB）、程序段、数据段三部分组成。包括：

**新建态**：刚刚创建的进程，操作系统还没有把它加入到可执行进程组中，通常是进程控制块已经创建但是还没有加载到内存中的进程。

**就绪态**：也被称为“可执行状态”。线程对象被创建后，其他线程调用了该对象的start()方法，从而启动该线程。如：thread.start(); 处于就绪状态的线程随时可能被CPU调度执行。

**运行态**：该进程正在执行。

**阻塞态**（等待态）：阻塞状态是线程因为某种原因放弃CPU使用权限，暂时停止运行。直到线程进入就绪状态，才有机会进入运行状态。阻塞的三种情况：

  1）等待阻塞：通过调用线程的wait()方法，让线程等待某工作的完成。

  2）同步阻塞：线程在获取synchronized同步锁失败（因为锁被其他线程占用），它会进入同步阻塞状态。

  3）其他阻塞：通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状态超时、join()等待线程终止或超时、或者I/O处理完毕时，线程重新转入就绪状态。

**退出态**：线程执行完了或因异常退出了run()方法，该线程结束生命周期。

![20190511095933572](D:\9找工作\img\20190511095933572.png)

### 进程的通信方式

1. 无名管道：半双工的，即数据只能在一个方向上流动，只能用于具有亲缘关系的进程之间的通信，可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。
2. FIFO命名管道：FIFO是一种文件类型，可以在无关的进程之间交换数据，与无名管道不同，FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。
3. 消息队列：消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。
4. 信号量：信号量是一个计数器，信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。
5. 共享内存：共享内存指两个或多个进程共享一个给定的存储区，一般配合信号量使用。
6. Socket

### 线程间通信

1. 共享内存volatile
2. 消息传递：线程之间没有公共的状态，线程之间必须通过明确的发送信息来显示的进行通信。
   1. wait/notify等待通知方式：**wait()当前线程释放锁并进入等待(阻塞)状态**，notify()唤醒一个正在等待相应对象锁的线程
   2. join方式：在当前线程A调用线程B的join()方法后，会让当前线程A阻塞，直到线程B的逻辑执行完成，A线程才会解除阻塞，然后继续执行自己的业务逻辑

### 内存管理有哪几种方式

1. 块式管理：把主存分为一大块、一大块的，当所需的程序片断不在主存时就分配一块主存空间，把程序片断load入主存，就算所需的程序片度只有几个字节也只能把这一块分配给它。这样会造成很大的浪费，平均浪费了50％的内存空间，但是易于管理。
2. 页式管理：把主存分为一页一页的，每一页的空间要比一块一块的空间小很多，显然这种方法的空间利用率要比块式管理高很多。
3. 段式管理：把主存分为一段一段的，每一段的空间又要比一页一页的空间小很多，这种方法在空间利用率上又比页式管理高很多，但是也有另外一个缺点。一个程序片断可能会被分为几十段，这样很多时间就会被浪费在计算每一段的物理地址上。
4. 段页式管理：结合了段式管理和页式管理的优点。将程序分成若干段，每个段分成若干页。段页式管理每取一数据，要访问3次内存。

### 内存碎片

内存碎片通常分为内部碎片和外部碎片： 

内部碎片：内存中划分为若干个固定的块（这些块大小可能相等也可能不相等），当一个程序或一个程序分解后的部分程序装进这些块后，在块里面不能完全占用的内存空间成为内部碎片。 

+ **解决方法：①采用可变分区分配 ②采用分段存储管理方式（一般采用这种方式） **

 外部碎片：由于某些未分配的连续内存区域太小，以至于不能满足任意进程的内存分配请求，从而不能被进程利用的内存区域。

+ **解决方法：③采用分页存储管理方式  ④采用段页式存储管理方式（第③和第④是常用方法）**

​    现在普遍采取的内存分配方式是**段页式内存分配**。将内存分为不同的段，再将每一段分成固定大小的页。通过页表机制，使段内的页可以不必连续处于同一内存区域。

### 页面置换算法

1. 最佳置换算法OPT：只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。
2. 先进先出置换算法FIFO：简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面。
3. 最近最久未使用算法LRU：算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)。
4. 时钟算法clock(也被称为是最近未使用算法NRU)：页面设置一个访问位，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面。
5. 改进型Clock算法：在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问位和修改位都是0的页面，其次是访问位为0修改位为1的页面。
6. LFU最少使用算法LFU：设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。

### 进程调度的时机

1. 当前运行的进程运行结束。
2. 当前运行的进程由于某种原因阻塞。
3. 执行完系统调用等系统程序后返回用户进程。
4. 在使用抢占调度的系统中，具有更高优先级的进程就绪时。
5. 分时系统中，分给当前进程的时间片用完。

### 操作系统中进程调度策略有哪几种

1. 先来先服务调度算法FCFS：队列实现，非抢占，先请求CPU的进程先分配到CPU，可以作为作业调度算法也可以作为进程调度算法；按作业或者进程到达的先后顺序依次调度，对于长作业比较有利.
2. 最短作业优先调度算法SJF：作业调度算法，算法从就绪队列中选择估计时间最短的作业进行处理，直到得出结果或者无法继续执行，平均等待时间最短，但难以知道下一个CPU区间长度；缺点：不利于长作业；未考虑作业的重要性；运行时间是预估的，并不靠谱.
3. 优先级调度算法(可以是抢占的，也可以是非抢占的)：优先级越高越先分配到CPU，相同优先级先到先服务，存在的主要问题是：低优先级进程无穷等待CPU，会导致无穷阻塞或饥饿.
4. 时间片轮转调度算法(可抢占的)：按到达的先后对进程放入队列中，然后给队首进程分配CPU时间片，时间片用完之后计时器发出中断，暂停当前进程并将其放到队列尾部，循环 ;队列中没有进程被分配超过一个时间片的CPU时间，除非它是唯一可运行的进程。如果进程的CPU区间超过了一个时间片，那么该进程就被抢占并放回就绪队列。

### 死锁的4个必要条件

1. 互斥条件：一个资源每次只能被一个线程使用；
2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放；
3. 不剥夺条件：进程已经获得的资源，在未使用完之前，不能强行剥夺；
4. 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。   

### 如何避免（预防）死锁

1. 破坏“请求和保持”条件：让进程在申请资源时，一次性申请所有需要用到的资源，不要一次一次来申请，当申请的资源有一些没空，那就让线程等待。不过这个方法比较浪费资源，进程可能经常处于饥饿状态。还有一种方法是，要求进程在申请资源前，要释放自己拥有的资源。
2. 破坏“不可抢占”条件：允许进程进行抢占，方法一：如果去抢资源，被拒绝，就释放自己的资源。方法二：操作系统允许抢，只要你优先级大，可以抢到。
3. 破坏“循环等待”条件：将系统中的所有资源统一编号，进程可在任何时刻提出资源申请，但所有申请必须按照资源的编号顺序提出（指定获取锁的顺序，顺序加锁）。



## Linux

### 基本命令

1. 查看进程：ps -ef|grep pid
2. 查看线程：ps -T -p pid
3. 查看内存：free
4. 查看端口：netstat -nap | grep pid 或者  lsof -i | grep pid
5. 查询文本或其他：grep命令，如查询某个文件中字符出现的次数 grep -c 'aa' a.txt
6. 文本处理工具：awk [选项参数] 'script' var=value file(s)
7. 查看IP：ifconfig
8. 查看主机名：hostname
9. 修改权限：chmod 755。 第一个表示文件所有者权限、第二个表示同用户组权限、第三个表示其他用户组权限。每个权限由三位组成，表示读、写、执行。7表示111，表示可读可写可执行，5表示101可读可执行
10. 查找文件：find 路径 表达式 -name 

### IO多路复用

单个线程通过记录跟踪每一个Sock(I/O流)的状态来同时管理多个I/O流。**select, poll, epoll 都是I/O多路复用的具体的实现**

#### select、poll、epoll的区别

1、支持一个进程所能打开的最大连接数

select：单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。

poll：poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的。

epoll：虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接。

2、FD剧增后带来的IO效率问题

select：因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。

poll：同上

epoll：因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。

3、 消息传递方式

select：内核需要将消息传递到用户空间，都需要内核拷贝动作

poll：同上

epoll：epoll通过内核和用户空间共享一块内存来实现的。

![img](https://pic2.zhimg.com/80/v2-e177f887784cbb59f1bd1ce701f2d0d1_720w.jpg)

## 计算机网路

### Get和Post区别

1. Get是不安全的，因为在传输过程，数据被放在请求的URL中；Post的所有操作对用户来说都是不可见的。
2. Get传送的数据量较小，这主要是因为受URL长度限制；Post传送的数据量较大，一般被默认为不受限制。
3. Get限制Form表单的数据集的值必须为ASCII字符；而Post支持整个ISO10646字符集。
4. Get执行效率却比Post方法好。Get是form提交的默认方法。
5. GET产生一个TCP数据包；POST产生两个TCP数据包。（非必然，客户端可灵活决定）

### Http长连接和短连接的区别

长连接：

+ client方与server方先建立连接，连接建立后不断开，然后再进行报文发送和接收。这种方式下由于通讯连接一直存在。此种方式常用于P2P通信。
+ 长连接多用于操作频繁，点对点的通讯，而且连接数不能太多的情况。

短连接

+ Client方与server每进行一次报文收发交易时才进行通讯连接，交易完毕后立即断开连接。此方式常用于一点对多点通讯。
+ web网站的http服务一般都用短连接。因为长连接对于服务器来说要耗费一定的资源。像web网站这么频繁的成千上万甚至上亿客户端的连接用短连接更省一些资源



### Http请求的完全过程

1. 浏览器根据域名解析IP地址（DNS）,并查DNS缓存
2. 浏览器与WEB服务器建立一个TCP连接
3. 浏览器给WEB服务器发送一个HTTP请求（GET/POST）：一个HTTP请求报文由请求行（request line）、请求头部（headers）、空行（blank line）和请求数据（request body）4个部分组成。
4. 服务端响应HTTP响应报文，报文由状态行（status line）、相应头部（headers）、空行（blank line）和响应数据（response body）4个部分组成。
5. 关闭TCP连接
6. 浏览器解析HTML
7. 浏览器渲染

### https的连接过程

1. 浏览器将支持的加密算法信息发给服务器
2. 服务器选择一套浏览器支持的加密算法，以证书的形式回发给浏览器
3. 客户端(SSL/TLS)解析证书验证证书合法性，生成对称加密的密钥，我们将该密钥称之为client key，即客户端密钥，用服务器的公钥对客户端密钥进行非对称加密。
4. 客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端对称密钥发送给服务器
5. 服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。
6. 服务器将加密后的密文发送给客户端
7. 客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成

### Http和Https的区别

1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl对称加密传输协议。
3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

### Https的证书使用流程

<img src="https://img-blog.csdnimg.cn/20181107211003959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llc2hlbjQzMjg=,size_12,color_FFFFFF,t_70" alt="认证过程" style="zoom:50%;" />

+ 首先服务端会生成一对公私钥，将公钥S.pub发送给CA进行认证；
+ 认证服务器用自己的私钥C.pri对S.pub进行签名（加密），得到sig，同时将sig和S.pub绑定组成证书；
+ CA将证书返回给服务端；
+ 这时候浏览器（客户端）要访问服务端的某个网页或资源。从认证服务器那里获取了公钥C.pub，同时对服务端发起http请求；
+ 在建立连接后，服务端将证书发送给浏览器；
+ 浏览器用CA的公钥对证书中的签名sig进行解密，得到一个S.pub^，将它和证书中的S.pub进行对比，如果两者相同，说明服务端是合法的，否则是不合法的。

### Http状态码

![image-20210322194811266](C:\Users\王盛\AppData\Roaming\Typora\typora-user-images\image-20210322194811266.png)

+ 200：请求成功，一般用于get和post请求
+ 400：bad request，客户端请求的语法错误，服务器无法理解
+ 403：Forbidden，服务器拒绝执行此请求
+ 404：Not found，找不到资源
+ 500：服务器内部错误，访问数据库错误
+ 502：Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应
+ 503：Service Unavailable 由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After头
+ 504：Gateway Time-out  充当网关或代理的服务器，未及时从远端服务器获取请求

### IPV4和IPV6的区别



### cookie和session的区别

1，session 在服务器端，cookie 在客户端（浏览器）
 2，session 默认被存在在服务器的一个文件里（不是内存）
 3，session 的运行依赖 session id，而 session id 是存在 cookie 中的，也就是说，如果浏览器禁用了 cookie ，同时 session 也会失效（但是可以通过其它方式实现，比如在 url 中传递 session_id）
 4，session 可以放在 文件、数据库、或内存中都可以。
 5，用户验证这种场合一般会用 session

### cookie具体结构

cookie ={u'domain': u'.cnblogs.com', u'name': u'.CNBlogsCookie', u'value': u'xxxx', u'expiry': 1491887887, u'path': u'/', u'httpOnly': True, u'secure': False} 

name：cookie 的名称 

value：cookie 对应的值，动态生成的 

domain：服务器域名 

expiry：Cookie 有效终止日期 

path：Path 属性定义了 Web 服务器上哪些路径下的页面可获取服务器设置的 Cookie 

httpOnly：防脚本攻击 

secure:在 Cookie 中标记该变量，表明只有当浏览器和 Web Server 之间的通信协议为加密 认证协议时， 浏览器才向服务器提交相应的 Cookie。当前这种协议只有一种，即为 HTTPS。

### 重定向和转发

重定向：客户端行为，会产生2次请求，并显示新的地址，请求域中的数据会丢失

转发：服务器行为，只会产生一次请求，地址栏url不会变化，请求域中数据不会丢失。

### 什么是跨域，解决方法

什么是跨域：为了网络安全起见，浏览器设置了一个同源策略，规定只有域名，端口，协议全部相同，就叫做同源。当页面在执行一个脚本时，会检查访问的资源是否同源，如果不是，就会报错。可是在实际开发中，经常会有跨域加载资源的需求，避免不了跨域请求，所以就出现了跨域。

项目中的解决方法：

1. @CrossOrigin
2. 配置类：**这里可以通过实现 `WebMvcConfigurer` 接口中的 `addCorsMappings()` 方法来实现跨域。**
3. Ngin配置

### DNS查询流程

1. 先在本机的DNS里头查，如果有就直接返回了。
   + 先查自己内存里的DNS Cache，没有！
   + 再查本地硬盘里的host文件，也没有
2. 本机DNS里头发现没有，就去根DNS服务器（如8.8.8.8）里查。根域名服务器解析客户机请求的根域部分，它把包含的下一级的dns服务器的地址返回到客户机的dns服务器地址。
3. 客户机的dns服务器根据返回的信息接着访问下一级的dns服务器。这样递归的方法一级一级接近查询的目标，最后在有目标域名的服务器上面得到相应的IP信息。
4. 客户机的本地的dns服务器会将查询结果返回给我们的客户机。客户机根据得到的ip信息访问目标主机，完成解析过程

### 计算机网络的五层模型

1. 应用层：**报文**。为操作系统或网络应用程序提供访问网络服务的接口 ，通过应用进程间的交互完成特定网络应用。应用层定义的是应用进程间通信和交互的规则。
   + TCP：HTTP超文本传输协议80，FTP文件传输协议20，SMTP简单邮件传输协议25，TELNET网络电传23
   + UDP：DNS域名服务53，TFTP简单文件传输协议69，NTP网络时间协议
2. 传输层：**报文段**。负责向两个主机中进程之间的通信提供通用数据服务。（TCP,UDP）
3. 网络层：**数据报**。负责对数据包进行路由选择和存储转发。（IP，ICMP(ping命令)，ARP、RARP）
4. 数据链路层：两个相邻节点之间传送数据时，数据链路层将网络层交下来的IP数据报组装成**帧**，在两个相邻的链路上传送帧（frame)。每一帧包括数据和必要的控制信息。（PPP、FR、HDLC、VLAN、MAC ）
5. 物理层：物理层所传数据单位是**比特（bit)**。物理层要考虑用多大的电压代表1 或 0 ，以及接受方如何识别发送方所发送的比特。

### 计算机网络七层模型

应用层：

表示层：把所传送的数据的抽象语法变换为传送语法，即把不同计算机内部的不同表示形式转换成网络通信中的标准表示形式。此外，对传送的数据加密（或解密）、正文压缩（或还原）也是表示层的任务。

会话层：该层对传输的报文提供同步管理服务。在两个不同系统的互相通信的应用进程之间建立、组织和协调交互。例如，确定是双工还是半双工工作。

传输层

网络层

数据链路层

物理层。

### 协议

+ ARP协议：地址解析协议，其作用是在以太网环境中，数据的传输所依懒的是MAC地址而非IP地址，而将已知IP地址转换为MAC地址的工作是由ARP协议来完成的。

### tcp和udp区别

1. TCP面向连接，UDP是无连接的，即发送数据之前不需要建立连接。

2. TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付。

3. **TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流，UDP是面向报文的，UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）**

4. 每一条TCP连接只能是点到点的，UDP支持一对一，一对多，多对一和多对多的交互通信。

5. TCP首部开销20字节，UDP的首部开销小，只有8个字节。

6. TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道。

   ![img](https://pic4.zhimg.com/80/v2-0368c41e3dfd447e6eec10b3d9af74a9_720w.jpg?source=1940ef5c)

### tcp和udp的优缺点

* TCP的优点： 可靠，稳定 TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。 
* TCP的缺点： 慢，效率低，占用系统资源高，易被攻击 TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。
* UDP的优点： 快，比TCP稍安全 UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。但UDP也是无法避免攻击的，比如：UDP Flood攻击…… 
* UDP的缺点： 不可靠，不稳定 因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 基于上面的优缺点，那么： 什么时候应该使用TCP： 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 在日常生活中，常见使用TCP协议的应用如下： 浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输。什么时候应该使用UDP： 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 比如，日常生活中，常见使用UDP协议的应用如下： QQ语音 QQ视频 TFTP。

### TCP为什么可靠？

+ 确认和重传机制：建立连接时三次握手同步双方的“序列号 + 确认号 + 窗口大小信息”，是确认重传、流控的基础。传输过程中，如果Checksum校验失败、丢包或延时，发送端重传
+ 数据排序：TCP有专门的序列号SN字段，可提供数据re-order
+ 流量控制：滑动窗口和计时器的使用。TCP窗口中会指明双方能够发送接收的最大数据量
+ 拥塞控制：慢开始、拥塞控制、快重传、快恢复

### tcp粘包及处理

定义：TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

原因及解决方法：Nagle算法造成了发送方可能会出现粘包问题。通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。

UDP会粘包吗：不会，面向报文的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

### tcp拥塞控制

<img src="https://img-blog.csdnimg.cn/20190731155254165.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:70%;" />

1. 慢开始

2. 拥塞控制

3. 快重传

   ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184314574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

4. 快恢复

   ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184640178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

### 三次握手

* 第一次握手：建立连接时，客户端发送syn包（syn=x）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。

* 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；

* 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。

  ![img](https://pics1.baidu.com/feed/d8f9d72a6059252d20d93b0a6645fb3e59b5b9d2.jpeg?token=c86d4509157378798ebbccbe843486d1&s=9746F8123F5754CA48D574DA0300D0B2)

### 为什么不能两次握手

TCP是一个双向通信协议，通信双方都有能力发送信息，并接收响应。如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认

### 四次挥手

1. 客户端进程发出连接释放报文，并且停止发送数据。**释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1）**，此时，**客户端进入FIN-WAIT-1（终止等待1）状态**。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。

2. **服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态**。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。

3. 客户端收到服务器的确认请求后，此时，**客户端就进入FIN-WAIT-2（终止等待2）状态**，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。

4. 服务器将最后的数据发送完毕后，**就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）**状态，等待客户端的确认。

5. **客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态**。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。

6. 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些

   <img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy?x-oss-process=image/format,png" style="zoom:50%;" />

### 为什么要等待2**MSL？

虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

### 为什么连接的时候是三次握手，关闭的时候却是四次握手

因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

### 浏览器中输入一个网址后，具体发生了什么

1. 识别URL，包括http/https、域名、端口等。默认80端口。
2. 进行DNS解析操作，首先在本地缓存查、再在host文件查，最后才是根服务器。根据DNS解析的结果查到服务器IP地址
3. 通过ip寻址和arp地址解析协议，找到服务器，并利用三次握手建立TCP连接
4. 浏览器生成HTTP报文，发送HTTP请求，等待服务器响应
5. 服务器处理请求，并返回给浏览器
6. 根据HTTP是否开启长连接，进行TCP的挥手过程
7. 浏览器根据收到的静态资源进行页面渲染

### Socket

Socket是对TCP/IP协议的抽象，是操作系统对外开放的接口。Socket适应其他的网络协议，使得程序员更方便地使用TCP/IP协议栈。

对TCP/IP协议的抽象，从而形成了我们知道的最基本的函数接口。比如create，listen，connect，accept，send，read，write，等等。

<img src="D:\9找工作\img\1685432-20200330163815451-1565793655.png" alt="1685432-20200330163815451-1565793655" style="zoom:150%;" />



服务器首先创建通信ServerSocket，为ServerSocket绑定IP地址和端口号。紧接着服务器创建Socket监听端口号的请求，随时准备接受客户端发来的连接。

 服务器的Socket只是listen，没有打开 。此时假设客户端创建了Socket，打开了Socket，并根据服务器的IP地址和端口号尝试去连接服务器的Socket，服务器的Socket接收到客户端Socket

请求，被动地打开，开始接收客户端的请求，直到客户端返回连接信息，这时候服务器的Socket进入到阻塞状态，即accept方法需要等待客户端返回连接信息后，才返回。同时开始接收下一个客户端的连接请求。

客户端在连接成功之后呢，向服务器发送连接状态信息，服务端在接收到客户端的连接信息之后，将accpet方法返回，并提示连接成功。客户端向Socket去写入信息，服务器能收到并读取相关的信息，最 后在发送完数据后，客户端会关闭socket，服务端也会关闭Socket

## 数据结构与算法

### 排序算法

![img](https://img-blog.csdnimg.cn/20200325101708382.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RvcmVteXJhaW5ib3c=,size_16,color_FFFFFF,t_70)

#### 冒泡排序

#### 选择排序：

选择排序与冒泡排序有点像，只不过选择排序每次都是在确定了最小数的下标之后再进行交换，大大减少了交换的次数

#### 插入排序

将一个记录插入到已排序的有序表中，从而得到一个新的，记录数增1的有序表

#### 快速排序

通过一趟排序将序列分成左右两部分，其中左半部分的的值均比右半部分的值小，然后再分别对左右部分的记录进行排序，直到整个序列有序。

```java
int partition(int a[], int low, int high){
    int key = a[low];
    while( low < high ){
        while(low < high && a[high] >= key) high--;
        a[low] = a[high];
        while(low < high && a[low] <= key) low++;
        a[high] = a[low];
    }
    a[low] = key;
    return low;
}
void quick_sort(int a[], int low, int high){
    if(low >= high) return;
    int keypos = partition(a, low, high);
    quick_sort(a, low, keypos-1);
    quick_sort(a, keypos+1, high);
}
```

#### 堆排序

将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根节点。将其与末尾元素进行交换，此时末尾就为最大值。然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次小值。如此反复执行，便能得到一个有序序列了。最大值在堆顶，每一个元素都大于等于它的左右孩子，小堆反之。

```java
public class Test {

    public void sort(int[] arr) {
        for (int i = arr.length / 2 - 1; i >= 0; i--) {
            adjustHeap(arr, i, arr.length);
        }
        for (int j = arr.length - 1; j > 0; j--) {
            swap(arr, 0, j);
            adjustHeap(arr, 0, j);
        }

    }

    public void adjustHeap(int[] arr, int i, int length) {
        int temp = arr[i];
        for (int k = i * 2 + 1; k < length; k = k * 2 + 1) {
            if (k + 1 < length && arr[k] < arr[k + 1]) {
                k++;
            }
            if (arr[k] > temp) {
                arr[i] = arr[k];
                i = k;
            } else {
                break;
            }
        }
        arr[i] = temp;
    }

    public void swap(int[] arr, int a, int b) {
        int temp = arr[a];
        arr[a] = arr[b];
        arr[b] = temp;
    }

    public static void main(String[] args) {
        int[] arr = {9, 8, 7, 6, 5, 4, 3, 2, 1};
        new Test().sort(arr);
        System.out.println(Arrays.toString(arr));
    }
}
```

#### 希尔排序

先将整个待排记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录基本有序时再对全体记录进行一次直接插入排序。

#### 归并排序

把有序表划分成元素个数尽量相等的两半，把两半元素分别排序，两个有序表合并成一个



### 树相关

数据库里面使用树做索引，树中存放的都是每页的索引Key

1. 二叉搜索树：二叉查找树的特点就是任何节点的左子节点的键值都小于当前节点的键值，右子节点的键值都大于当前节点的键值。顶端的节点我们称为根节点，没有子节点的节点我们称之为叶节点。但容易变成单链表。

2. 平衡二叉树（AVL）：假如不是空树，任何一个结点的左子树与右子树都是平衡二叉树，并且高度之差的绝对值不超过 1。非叶子节点只能允许最多两个子节点存在，每一个非叶子节点数据分布规则为左边的子节点小当前节点的值，右边的子节点大于当前节点的值。当不平衡的时候需要通过**旋转**变为平衡二叉树。旋转的效率很低

3. B树（B-树）：B树和平衡二叉树稍有不同的是**B树属于多叉树又名平衡多路查找树**（查找路径不只两个），树种的每个节点最多拥有m个子节点且m>=2,空树除外，所有节点关键字是按递增次序排列，并遵循左小右大原则；数据库索引技术里大量使用者B树和B+树的数据结构。 **优点：降低了树的深度，减少磁盘的IO**

   <img src="https://upload-images.jianshu.io/upload_images/7862980-9f37abf83ae7a973.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom:33%;" />

4. B+树：B+ 树非叶子节点上是不存储数据的，仅存储键值，而 B 树节点中不仅存储键值，也会存储数据。图 B+ 树中各个页之间是通过双向链表连接的，叶子节点中的数据是通过单向链表连接的。

   之所以这么做是因为在数据库中页的大小是固定的，InnoDB 中页的默认大小是 16KB。

   如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的 IO 次数又会再次减少，数据查询的效率也会更快。

   <img src="http://www.liuzk.com/wp-content/uploads/2019/11/6.jpg" alt="6" style="zoom:50%;" />

5. 红黑树：一个自平衡(不是绝对的平衡)的二叉查找树(BST)，树上的每个节点都遵循下面的规则:

   1. 节点是红色或黑色。

   2. 根节点是黑色。

   3. 每个叶子节点都是黑色的空节点（NIL节点）。

   4. 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)

   5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

   ![img](http://5b0988e595225.cdn.sohucs.com/images/20171102/eefb5a3397ef4089b356e7c9f0938a8d.jpeg)

+ 红黑树的调整：
  + 变色：为了重新符合红黑树的规则，尝试把红色节点变为黑色，或者把黑色节点变为红色。
  + 自旋：类似于平衡二叉树
    + 左旋转：逆时针旋转红黑树的两个节点，使得父节点被自己的右孩子取代，而自己成为自己的左孩子。
    + 右旋转：顺时针旋转红黑树的两个节点，使得父节点被自己的左孩子取代，而自己成为自己的右孩子

### 堆

### 跳表

在链表的基础上，选取一半的节点来建立索引

![再看下这张图](https://img-blog.csdn.net/2018072721393750?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTQ2MjA0Nw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### Hash表

是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。

哈希冲突：即不同key值产生相同的地址，即发生了哈希冲突。一般来说，哈希冲突是无法避免的，所以就有了解决方案。

+ 链地址法（拉链法）：采用链表存储发生哈希冲突的key值
+ 开发地址法：使用某种探测算法在散列表中寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到。按照探测序列的方法，一般将开放地址法区分为线性探查法、二次探查法、双重散列法等

### 手写LRU算法

LRU：最近最少使用。使用一个HashMap和双向链表

```java
public class LRUCache {
    class DLinkedNode {
        int key;
        int value;
        DLinkedNode prev;
        DLinkedNode next;
        public DLinkedNode() {}
        public DLinkedNode(int _key, int _value) {key = _key; value = _value;}
    }

    private Map<Integer, DLinkedNode> cache = new HashMap<Integer, DLinkedNode>();
    private int size;
    private int capacity;
    private DLinkedNode head, tail;

    public LRUCache(int capacity) {
        this.size = 0;
        this.capacity = capacity;
        // 使用伪头部和伪尾部节点
        head = new DLinkedNode();
        tail = new DLinkedNode();
        head.next = tail;
        tail.prev = head;
    }

    public int get(int key) {
        DLinkedNode node = cache.get(key);
        if (node == null) {
            return -1;
        }
        // 如果 key 存在，先通过哈希表定位，再移到头部
        moveToHead(node);
        return node.value;
    }

    public void put(int key, int value) {
        DLinkedNode node = cache.get(key);
        if (node == null) {
            // 如果 key 不存在，创建一个新的节点
            DLinkedNode newNode = new DLinkedNode(key, value);
            // 添加进哈希表
            cache.put(key, newNode);
            // 添加至双向链表的头部
            addToHead(newNode);
            ++size;
            if (size > capacity) {
                // 如果超出容量，删除双向链表的尾部节点
                DLinkedNode tail = removeTail();
                // 删除哈希表中对应的项
                cache.remove(tail.key);
                --size;
            }
        }
        else {
            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部
            node.value = value;
            moveToHead(node);
        }
    }

    private void addToHead(DLinkedNode node) {
        node.prev = head;
        node.next = head.next;
        head.next.prev = node;
        head.next = node;
    }

    private void removeNode(DLinkedNode node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }

    private void moveToHead(DLinkedNode node) {
        removeNode(node);
        addToHead(node);
    }

    private DLinkedNode removeTail() {
        DLinkedNode res = tail.prev;
        removeNode(res);
        return res;
    }
}
```



### 算法

#### 两数交换，不用额外空间

使用位运算中的异或运算，a^a=0，a^0=a



## 设计模式

### 设计模式，你都知道哪些？

+ 创建型模式：工厂模式、抽象工厂模式、单例模式、建造者模式、原型模式（关注于对象的创建，同时隐藏创建逻辑）
+ 结构型模式：适配器模式、过滤器模式、装饰模式、享元模式、代理模式、外观模式、组合模式、桥接模式（关注类和对象之间的组合
+ 行为型模式：责任链模式、命令模式、中介者模式、观察者模式、状态模式、策略模式、模板模式、空对象模式、备忘录模式、迭代器模式、解释器模式、访问者模式（关注对象之间的通信）

### 设计模式原则

+ 单一职责原则：一个类应该只负责一项职责。提高类的可读性和可维护性，降低变更引起的风险。
+ 接口隔离原则：客户端不应该依赖他不需要的接口，即一个类对另一个类的依赖应该建立在最小的接口上
+ 依赖倒转原则
+ 里式替换原则
+ 开闭原则
+ 迪米特法则
+ 合成复用原则

### 单例模式

 单例模式是一种常用的软件设计模式，在应用这个模式时，单例对象的类必须保证只有一个实例存在，整个系统只能使用一个对象实例。

优点：不会频繁地创建和销毁对象，浪费系统资源。使用场景：IO 、数据库连接、Redis 连接等。

实现方法：饿汉模式（创建对象就创建）、懒汉模式（线程安全和线程不安全）、双重检查模式（DCL）、静态内部类

```java
// 饿汉模式：线程安全、不是懒加载、性能较好
public class BadmashSingleton {
    // 在类加载的时候即被实例化
    private static BadmashSingleton instance = new BadmashSingleton();
    private BadmashSingleton() {
    }

    public static BadmashSingleton getInstance() {
        return instance;
    }
}

// 懒汉模式：线程不安全、懒加载、性能较好
public class IdlerSingleton {
    private static IdlerSingleton instance = null;
    private IdlerSingleton() {
    }
	// 在使用时才进行加载
    public static IdlerSingleton getInstance() {
        if (null == instance) {
            instance = new IdlerSingleton();
        }
        return instance;
    }
}

// 线程安全的懒汉模式：线程安全、懒加载（加synchronized关键字）
public class IdlerSynSingleton {
    private static IdlerSynSingleton instance = null;
    private IdlerSynSingleton() {
    }

    public static synchronized IdlerSynSingleton getInstance() {
        if (null == instance) {
        	instance = new IdlerSynSingleton();
        }
        return instance;
    }
}

// 双重检查模式（DCL）：线程安全、懒加载
// 引入volatile关键字修饰实例对象，这是为了避免因JVM指令重排序可能导致的空指针异常
public class DCLSingleton {
    private static volatile DCLSingleton instance = null;
    private DCLSingleton() {
    }

    public static DCLSingleton getInstance() {
        if (null == instance) {
            synchronized (DCLSingleton.class) {
                if (null == instance) {
                    instance = new DCLSingleton();
                }
            }
        }
        return instance;
    }
}

// 静态内部类（holder）：线程安全、懒加载
public class HolderSingleton {
    private HolderSingleton() {
    }

    public static HolderSingleton getInstance() {
        return Holder.instance;
    }

    private static class Holder {
        private static HolderSingleton instance = new HolderSingleton();
    }
}
```

### 简单工厂模式

简单工厂模式又叫静态工厂方法模式，就是建立一个工厂类，对实现了同一接口的一些类进行实例的创建。比如，一台咖啡机就可以理解为一个工厂模式，你只需要按下想喝的咖啡品类的按钮（摩卡或拿铁），它就会给你生产一杯相应的咖啡，你不需要管它内部的具体实现，只要告诉它你的需求即可。

+ 优点：实现类创建过程对客户端是透明的，客户端不决定具体实例化哪一个类，而是交由“工厂”来实例化。
+ 缺点：不易拓展，一旦添加新的产品类型，就不得不修改工厂的创建逻辑；

```java
class Factory {
    public static String createProduct(String product) {
        String result = null;
        switch (product) {
            case "Mocca":
                result = "摩卡";
                break;
            case "Latte":
                result = "拿铁";
                break;
            default:
                result = "其他";
                break;
        }
        return result;
    }
}
```

### 抽象工厂模式

抽象工厂模式是在简单工厂的基础上将未来可能需要修改的代码抽象出来，通过继承的方式让子类去做决定。比如，以上面的咖啡工厂为例，某天我的口味突然变了，不想喝咖啡了想喝啤酒，这个时候如果直接修改简单工厂里面的代码，这种做法不但不够优雅，也不符合软件设计的“开闭原则”，因为每次新增品类都要修改原来的代码。这个时候就可以使用抽象工厂类了，抽象工厂里只声明方法，具体的实现交给子类（子工厂）去实现，这个时候再有新增品类的需求，只需要新创建代码即可。

```java
public class AbstractFactoryTest {
   public static void main(String[] args) {
       // 抽象工厂
       String result = (new CoffeeFactory()).createProduct("Latte");
       System.out.println(result); // output:拿铁
   }
}
// 抽象工厂
abstract class AbstractFactory{
   public abstract String createProduct(String product);
}
// 啤酒工厂
class BeerFactory extends AbstractFactory{
   @Override
   public String createProduct(String product) {
       String result = null;
       switch (product) {
           case "Hans":
               result = "汉斯";
               break;
           case "Yanjing":
               result = "燕京";
               break;
           default:
               result = "其他啤酒";
               break;
       }
       return result;
   }
}
// 咖啡工厂 
class CoffeeFactory extends AbstractFactory{
   @Override
   public String createProduct(String product) {
       String result = null;
       switch (product) {
           case "Mocca":
               result = "摩卡";
               break;
           case "Latte":
               result = "拿铁";
               break;
           default:
               result = "其他咖啡";
               break;
       }
       return result;
   }
}

```

### 观察者模式

观察者模式是定义对象间的一种一对多依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象皆得到通知并被自动更新。角色包括：抽象主题（接口）、抽象观察值（接口）、具体主题和具体观察者

+ 优点：
  + 观察者模式可以实现表示层和数据逻辑层的分离，并定义了稳定的消息更新传递机制，抽象了更新接口，使得可以有各种各样不同的表示层作为具体观察者角色；
  + 观察者模式在观察目标和观察者之间建立一个抽象的耦合；
  + 观察者模式支持广播通信；观察者模式符合开闭原则（对拓展开放，对修改关闭）的要求
+ 缺点：
  + 如果一个观察目标对象有很多直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间；

```java
// 观察者 接口+具体观察者
interface Observer {
    public void update(String message);
}
//\* \* 具体的观察者（消息接收方） \*/
class ConcrereObserver implements Observer {
    private String name;

    public ConcrereObserver(String name) {
        this.name = name;
    }

    @Override
    public void update(String message) {
        System.out.println(name + "：" + message);
    }
}

// 主题 接口+具体主题
interface Subject {
    // 增加订阅者
    public void attach(Observer observer);
    // 删除订阅者
    public void detach(Observer observer);
    // 通知订阅者更新消息
    public void notify(String message);
}
//\* \* 具体被观察者（消息发布方） \*/
class ConcreteSubject implements Subject {
    // 订阅者列表（存储信息）
    private List<Observer> list = new ArrayList<Observer>();
    @Override
    public void attach(Observer observer) {
        list.add(observer);
    }
    @Override
    public void detach(Observer observer) {
        list.remove(observer);
    }
    @Override
    public void notify(String message) {
        for (Observer observer : list) {
            observer.update(message);
        }
    }
}

// 调用
public class ObserverTest {
    public static void main(String[] args) {
        // 定义发布者
        ConcreteSubject concreteSubject = new ConcreteSubject();
        // 定义订阅者
        ConcrereObserver concrereObserver = new ConcrereObserver("老王");
        ConcrereObserver concrereObserver2 = new ConcrereObserver("Java");
        // 添加订阅
        concreteSubject.attach(concrereObserver);
        concreteSubject.attach(concrereObserver2);
        // 发布信息
        concreteSubject.notify("更新了");
    }
}
```

### 装饰器模式

装饰器模式是指动态地给一个对象增加一些额外的功能，同时又不改变其结构。装饰器模式的关键：**装饰器中使用了被装饰的对象。**

+ 优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。

比如，创建一个对象“laowang”，给对象添加不同的装饰，穿上夹克、戴上帽子......，这个执行过程就是装饰者模式，实现代码如下。 **包括装饰器超类和装饰器具体实现类(extends)**

```java
public class test {
    public static void main(String[] args) {
        // 定义被装饰对象
        laowang laowang = new laowang();
        laowang.show();
        // 使用装饰器装饰
        JackDecorator jackDecorator = new JackDecorator(laowang);
        jackDecorator.show();
    }
}


// 对象接口
interface Person{
    void show();
}

// 装饰器超类
class DecoratorBase implements Person{
    Person person; // 定义被装饰的对象
    public DecoratorBase(Person person){
        this.person = person; // 构造方法
    }
    @Override
    public void show() {
        person.show();
    }
}

// 具体装饰器
class JackDecorator extends DecoratorBase{

    public JackDecorator(Person person) {
        super(person);
    }
    @Override
    public void show(){
        // 执行已有功能
        person.show();
        // 装饰功能
        System.out.println("穿上了jack");
    }
}

// 定义具体对象
class laowang implements Person{

    @Override
    public void show() {
        System.out.println("什么也没穿。。。");
    }
}
```

### 模板方法模式

模板方法模式是指定义一个模板结构，将具体内容延迟到子类去实现。

**优点**：

- 提高代码复用性：将相同部分的代码放在**抽象的父类**中，而将不同的代码放入不同的子类中；
- 实现了反向控制：通过一个父类调用其子类的操作，通过对子类的具体实现扩展不同的行为，实现了反向控制并且符合开闭原则。

以给冰箱中放水果为例，比如，我要放一个香蕉：开冰箱门 → 放香蕉 → 关冰箱门；如果我再要放一个苹果：开冰箱门 → 放苹果 → 关冰箱门。可以看出它们之间的行为模式都是一样的，只是存放的水果品类不同而已，这个时候就非常适用模板方法模式来解决这个问题，实现代码如下：

```java
public class 模板方法 {
    public static void main(String[] args) {
        Banana banana = new Banana();
        banana.open();
        banana.put();
        banana.close();
    }
}

// 定义抽象的模板方法类
abstract class Refrigerator{
    public void open(){
        System.out.println("打开冰箱门....");
    }
    public abstract void put();
    public void close(){
        System.out.println("关上冰箱门....");
    }
}

// 使用模板方法类 放水果
class Apple extends Refrigerator{
    @Override
    public void put() {
        System.out.println("冰箱里放了苹果...");
    }
}
class Banana extends Refrigerator{
    @Override
    public void put() {
        System.out.println("冰箱里放了香蕉...");
    }
}

```

### 代理模式

代理模式是给某一个对象提供一个代理，并由代理对象控制对原对象的引用。

**优点**：

- 代理模式能够协调调用者和被调用者，在一定程度上降低了系统的耦合度；
- 可以灵活地隐藏被代理对象的部分功能和服务，也增加额外的功能和服务。

**缺点**：

- 由于使用了代理模式，因此程序的性能没有直接调用性能高；
- 使用代理模式提高了代码的复杂度。

举一个生活中的例子：比如买飞机票，由于离飞机场太远，直接去飞机场买票不太现实，这个时候我们就可以上携程 App 上购买飞机票，这个时候携程 App 就相当于是飞机票的代理商。

```java
public class 代理模式 {
    public static void main(String[] args) {
        ProxyTicket ticket = new ProxyTicket();
        ticket.buy();
    }
}

// 飞机场买票窗口
class AirTricket {
    public void buy(){
        System.out.println("卖票。。");
    }
}

// 代理卖票机构 如协程app等
class ProxyTicket{
    private AirTricket airTricket;
    public ProxyTicket(){
        airTricket = new AirTricket();
    }
    // 代理操作对象
    public void buy(){
        airTricket.buy();
    }
}
```

### 策略模式

策略模式是指定义一系列算法，将每个算法都封装起来，并且使他们之间可以相互替换。

**优点**：遵循了开闭原则，扩展性良好。

**缺点**：随着策略的增加，对外暴露越来越多。

以生活中的例子来说，比如我们要出去旅游，选择性很多，可以选择骑车、开车、坐飞机、坐火车等，就可以使用策略模式，把每种出行作为一种策略封装起来，后面增加了新的交通方式了，如超级高铁、火箭等，就可以不需要改动原有的类，新增交通方式即可，这样也符合软件开发的开闭原则。 策略模式实现代码如下：

```java
// 将一系列的策略封装起来，调用封装好的策略类
public class 策略模式 {
    public static void main(String[] args) {
        Bike bike = new Bike();
        Drive drive = new Drive();
        Bus bus = new Bus();
        // 策略类
        Trip trip = new Trip(bus);
        trip.going();
    }
}

// 出行接口
interface ITrip{
    public void going();
}

// 出行策略
class Bike implements ITrip{
    public void going(){
        System.out.println("骑自行车出行。。。");
    }
}
class Drive implements ITrip{
    public void going(){
        System.out.println("自驾出行。。。");
    }
}
class Bus implements ITrip{
    public void going(){
        System.out.println("坐巴士出行。。。");
    }
}

// 策略类
class Trip{
    private ITrip iTrip;
    public Trip(ITrip iTrip){
        this.iTrip = iTrip;
    }
    public void going(){
        this.iTrip.going();
    }
}
```

### 适配器模式

适配器模式是将一个类的接口变成客户端所期望的另一种接口，从而使原本因接口不匹配而无法一起工作的两个类能够在一起工作。

**优点**：

- 可以让两个没有关联的类一起运行，起着中间转换的作用；
- 灵活性好，不会破坏原有的系统。

**缺点**：过多地使用适配器，容易使代码结构混乱，如明明看到调用的是 A 接口，内部调用的却是 B 接口的实现。

以生活中的例子来说，比如有一个充电器是 MicroUSB 接口，而手机充电口却是 TypeC 的，这个时候就需要一个把 MicroUSB 转换成 TypeC 的适配器，如下图所示：

```java
public class 适配器模式 {
    public static void main(String[] args) {
        AdapterUsb usb = new AdapterUsb(new TypeC());
        usb.charger();
    }
}

interface MicroUsb{
    void charger();
}

interface ITypeC{
    void charger();
}

class TypeC implements ITypeC{

    @Override
    public void charger() {
        System.out.println("typeC充电");
    }
}

// usb充电适配器，让他能够使用typec充电
class AdapterUsb implements MicroUsb{
    private TypeC typeC;
    public AdapterUsb(TypeC typeC){
        this.typeC = typeC;
    }

    @Override
    public void charger() {
        this.typeC.charger();
    }
}
```

### JDK类库中常用的设计模式

+ 工厂模式：java.text.DateFormat 工具类，它用于格式化一个本地日期或者时间。
+ 代理模式：JDK 本身的动态代理。java.lang.reflect.Proxy类
+ 单例模式：Runtime.getRuntime();
+ 装饰器模式：java.io.DataInputStream(InputStream);  

### IO使用了什么设计模式

- 适配器模式：由于 InputStream 是字节流不能享受到字符流读取字符那么便捷的功能，借助 InputStreamReader 将其转为 Reader 子类，因而可以拥有便捷操作文本文件方法；
- 装饰器模式：将 InputStream 字节流包装为其他流的过程就是装饰器模式，比如，包装为 FileInputStream、ByteArrayInputStream、PipedInputStream 等。

### Spring中使用哪些设计模式

- 代理模式：在 AOP 面向切面编程中有使用
- 单例模式：bean 默认是单例模式
- 模板方法模式：jdbcTemplate
- 工厂模式：BeanFactory
- 观察者模式：Spring 事件驱动模型就是观察者模式很经典的一个应用，比如，ContextStartedEvent 就是 ApplicationContext 启动后触发的事件
- 适配器模式：Spring MVC 中也是用到了适配器模式适配 Controller

## 其他

### 高并发系统的设计与实现

在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流。

* 缓存：缓存比较好理解，在大型高并发系统中，如果没有缓存数据库将分分钟被爆，系统也会瞬间瘫痪。使用缓存不单单能够提升系统访问速度、提高并发访问量，也是保护数据库、保护系统的有效方式。大型网站一般主要是“读”，缓存的使用很容易被想到。在大型“写”系统中，缓存也常常扮演者非常重要的角色。比如累积一些数据批量写入，内存里面的缓存队列（生产消费），以及HBase写数据的机制等等也都是通过缓存提升系统的吞吐量或者实现系统的保护措施。甚至消息中间件，你也可以认为是一种分布式的数据缓存。
* 降级：服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。降级往往会指定不同的级别，面临不同的异常等级执行不同的处理。根据服务方式：可以拒接服务，可以延迟服务，也有时候可以随机服务。根据服务范围：可以砍掉某个功能，也可以砍掉某些模块。总之服务降级需要根据不同的业务需求采用不同的降级策略。主要的目的就是服务虽然有损但是总比没有好。
* 限流：限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。

### 负载均衡算法：

1. 轮询
2. 加权轮询
3. 随机算法
4. 一致性Hash

### 常见的限流算法：

常见的限流算法有计数器、漏桶和令牌桶算法。漏桶算法在分布式环境中消息中间件或者Redis都是可选的方案。发放令牌的频率增加可以提升整体数据处理的速度，而通过每次获取令牌的个数增加或者放慢令牌的发放速度和降低整体数据处理速度。而漏桶不行，因为它的流出速率是固定的，程序处理速度也是固定的。

### 秒杀并发情况下库存为负数问题

1. for update显示加锁
2. 把update语句写在前边，先把数量-1，之后select出库存如果>-1就commit,否则rollback。
```
update products set quantity = quantity-1 WHERE id=3;
select quantity from products WHERE id=3 for update;
```
3. update语句在更新的同时加上一个条件
```
quantity = select quantity from products WHERE id=3;
update products set quantity = ($quantity-1) WHERE id=3 and queantity = $quantity;
```

### 常见的中间件

中间件：中间件是一种独立的系统软件服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源，中间件位于客户机服务器的操作系统之上，管理计算资源和网络通信。

\- 路由与web服务器：处理和转发其他服务器通信数据的服务器。 如被业界广泛使用的阿里基于 Nginx 研发的 Tengine、阿里内部的集中式路由服务 VipServer

\- RPC框架：微服务时代的远程服务调用框架。如grpc, Thrift, 阿里的 HSF, Dubbo, SOFA-RPC

\- 消息中间件：支持在分布式系统之间发送和接收消息的软件。 如 Apache kafka, Apache RabbitMQ, NSQ, 阿里孵化开源的 Apache RocketMQ

\- 缓存服务: 分布式的高速数据存储层，一般是内存存储。如 阿里 Tair，业界的 Redis, Memcached, Ehcache

\- 配置中心：用来统一管理各个项目中所有配置的系统。如 阿里 Nacos、携程 Apollo、百度 Disconf

\- 分布式事务：事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。 如 阿里 seata、腾讯 DTF

\- 任务调度：分布式环境下提供定时、任务编排、分布式跑批等功能的系统。如 阿里 SchedulerX、业界 xxl-job、当当 elastic-job、有赞 TSP

\- 数据库层 用于支持弹性扩容和分库分表的 TDDL，数据库连接池 Driud, Binlog 同步的 Canal 等。